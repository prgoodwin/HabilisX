@inproceedings{Accot:2002:MDF:503376.503390,
 author = {Accot, Johnny and Zhai, Shumin},
 title = {More than dotting the i's --- foundations for crossing-based interfaces},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '02},
 year = {2002},
 isbn = {1-58113-453-3},
 location = {Minneapolis, Minnesota, USA},
 pages = {73--80},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/503376.503390},
 doi = {10.1145/503376.503390},
 acmid = {503390},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Fitts' law, events, goal crossing, goal passing, graphical user interfaces, input, input performance, interaction techniques, pointing, widgets},
 abstract = {Today's graphical interactive systems largely depend upon pointing actions, i.e. entering an object and selecting it. In this paper we explore whether an alternate paradigm --- crossing boundaries --- may substitute or complement pointing as another fundamental interaction method. We describe an experiment in which we systematically evaluate two target-pointing tasks and four goal-crossing tasks, which differ by the direction of the movement variability constraint (collinear vs. orthogonal) and by the nature of the action (pointing vs. crossing, discrete vs. continuous). We found that participants' temporal performance in each of the six tasks was dependent on the index of difficulty formulated in the same way as in Fitts' law, but that the parameters differ by task. We also found that goal crossing completion time was shorter or no longer than pointing performance under the same index of difficulty. These regularities, as well as qualitative characterizations of crossing actions and their application in HCI, lay the foundation for designing crossing-based user interfaces.}
} 

@inproceedings{Apitz:2004:CCD:1029632.1029635,
 author = {Apitz, Georg and Guimbreti\`{e}re, Fran\c{c}ois},
 title = {CrossY: a crossing-based drawing application},
 booktitle = {Proceedings of the 17th annual ACM symposium on User interface software and technology},
 series = {UIST '04},
 year = {2004},
 isbn = {1-58113-957-8},
 location = {Santa Fe, NM, USA},
 pages = {3--12},
 numpages = {10},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1029632.1029635},
 doi = {10.1145/1029632.1029635},
 acmid = {1029635},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {command composition, crossing based interfaces, fluid interaction, pen-computing},
 abstract = {We introduce CrossY, a simple drawing application developed as a benchmark to demonstrate the feasibility of goal-crossing as the basis for a graphical user interface. While crossing was previously identified as a potential substitute for the classic point-and-click interaction, this work is the first to report on the practical aspects of implementing an interface solely based on goal-crossing.}
} 
@inproceedings{Bauer:2004:CPM:1032665.1034569,
 author = {Bauer, Dan and Fastrez, Pierre and Hollan, Jim},
 title = {Computationally-Enriched 'Piles' for Managing Digital Photo Collections},
 booktitle = {Proceedings of the 2004 IEEE Symposium on Visual Languages - Human Centric Computing},
 series = {VLHCC '04},
 year = {2004},
 isbn = {0-7803-8696-5},
 pages = {193--195},
 numpages = {3},
 url = {http://dx.doi.org.prox.lib.ncsu.edu/10.1109/VLHCC.2004.13},
 doi = {10.1109/VLHCC.2004.13},
 acmid = {1034569},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 abstract = {We explore and extend the metaphor of "piles" to include computationally-enriched piles, portable regions of automation in Dynapad, a multiscale workspace. We describe these collection-management tools and how their design was informed by observing people organizing collections of personal digital photographs.}
} 

@inproceedings{Bederson:1994:PZG:192426.192435,
 author = {Bederson, Benjamin B. and Hollan, James D.},
 title = {Pad++: a zooming graphical interface for exploring alternate interface physics},
 booktitle = {Proceedings of the 7th annual ACM symposium on User interface software and technology},
 series = {UIST '94},
 year = {1994},
 isbn = {0-89791-657-3},
 location = {Marina del Rey, California, USA},
 pages = {17--26},
 numpages = {10},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/192426.192435},
 doi = {10.1145/192426.192435},
 acmid = {192435},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {authoring, hypertext, information navigation, information physics, information visualization, interactive user interfaces, multiscale interfaces, zooming interfaces},
 abstract = {We describe the current status of Pad++, a zooming graphical interface that we are exploring as an alternative to traditional window and icon-based approaches to interface design. We discuss the motivation for Pad++, describe the implementation, and present prototype applications. In addition, we introduce an informational physics strategy for interface design and briefly compare it with metaphor-based design strategies.}
} 

@inproceedings{Bell:2001:VMV:502348.502363,
 author = {Bell, Blaine and Feiner, Steven and H\"{o}llerer, Tobias},
 title = {View management for virtual and augmented reality},
 booktitle = {Proceedings of the 14th annual ACM symposium on User interface software and technology},
 series = {UIST '01},
 year = {2001},
 isbn = {1-58113-438-X},
 location = {Orlando, Florida},
 pages = {101--110},
 numpages = {10},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/502348.502363},
 doi = {10.1145/502348.502363},
 acmid = {502363},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {annotation, augmented reality, environment management, labeling, view management, virtual environments, wearable computing},
 abstract = {We describe a view-management component for interactive 3D user interfaces. By view management, we mean maintaining visual constraints on the projections of objects on the view plane, such as locating related objects near each other, or preventing objects from occluding each other. Our view-management component accomplishes this by modifying selected object properties, including position, size, and transparency, which are tagged to indicate their constraints. For example, some objects may have geometric properties that are determined entirely by a physical simulation and which cannot be modified, while other objects may be annotations whose position and size are flexible.We introduce algorithms that use upright rectangular extents to represent on the view plane a dynamic and efficient approximation of the occupied space containing the projections of visible portions of 3D objects, as well as the unoccupied space in which objects can be placed to avoid occlusion. Layout decisions from previous frames are taken into account to reduce visual discontinuities. We present augmented reality and virtual reality examples to which we have applied our approach, including a dynamically labeled and annotated environment.}
} 

@INPROCEEDINGS{Maarten99thecontribution,
    author = {Czerwinski, Mary P.;  Van Dantzich,Maarten; Robertson,George; Hoffman,Hunter },
    title = {The Contribution of Thumbnail Image, Mouse-over Text and Spatial Location Memory to Web Page Retrieval in 3D},
    booktitle = {},
    year = {1999},
    pages = {163--170},
    publisher = {Press}
	abstract = {We present an empirical evaluation of the contribution of pictorial image and spatial location information on the retrieval of previously stored web pages. Subjects were given 100 snapshots of web pages that they stored in spatial locations on an inclined plane in a desktop 3D environment (Data Mountain). We had them return and try to retrieve their pages again, using a variety of retrieval cues. Even though users had not seen their web page layout for several months, their retrieval times were not significantly slower. In addition, on half of the trials, stored pages were not presented as thumbnail images of the web pages but as blank icons. Taking the pictorial thumbnail images away initially led to a significant drop in subjects’ ability to find the pages, although within a short period of time subjects were able to find the pages equally fast without the thumbnail information. These results indicate that the use of 3D visualization techniques such as those described in this paper can lead to improved user memory for where favorite or frequently used information is stored in an electronic environment.}
}

@inproceedings{DiGioia:2005:SNM:1073001.1073011,
 author = {DiGioia, Paul and Dourish, Paul},
 title = {Social navigation as a model for usable security},
 booktitle = {Proceedings of the 2005 symposium on Usable privacy and security},
 series = {SOUPS '05},
 year = {2005},
 isbn = {1-59593-178-3},
 location = {Pittsburgh, Pennsylvania},
 pages = {101--108},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1073001.1073011},
 doi = {10.1145/1073001.1073011},
 acmid = {1073011},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collaborative interfaces, peer-to-peer filesharing, social navigation, visualization},
 abstract = {As interest in usable security spreads, the use of visual approaches in which the functioning of a distributed system is made visually available to end users is an approach that a number of researchers have examined. In this paper, we discuss the use of the social navigation paradigm as a way of organizing visual displays of system action. Drawing on a previous study of security in the Kazaa peer to peer system, we present some examples of the ways in which social navigation can be incorporated in support of usable security.}
}

@inproceedings{Fitzmaurice:2003:TM:964696.964704,
 author = {Fitzmaurice, George and Khan, Azam and Piek{\'e}, Robert and Buxton, Bill and Kurtenbach, Gordon},
 title = {Tracking menus},
 booktitle = {Proceedings of the 16th annual ACM symposium on User interface software and technology},
 series = {UIST '03},
 year = {2003},
 isbn = {1-58113-636-6},
 location = {Vancouver, Canada},
 pages = {71--79},
 numpages = {9},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/964696.964704},
 doi = {10.1145/964696.964704},
 acmid = {964704},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {floating palette, graphical user interface, menu system, pen based user interfaces, tablet PC},
 abstract = {We describe a new type of graphical user interface widget, known as a "tracking menu." A tracking menu consists of a cluster of graphical buttons, and as with traditional menus, the cursor can be moved within the menu to select and interact with items. However, unlike traditional menus, when the cursor hits the edge of the menu, the menu moves to continue tracking the cursor. Thus, the menu always stays under the cursor and close at hand.In this paper we define the behavior of tracking menus, show unique affordances of the widget, present a variety of examples, and discuss design characteristics. We examine one tracking menu design in detail, reporting on usability studies and our experience integrating the technique into a commercial application for the Tablet PC. While user interface issues on the Tablet PC, such as preventing round trips to tool palettes with the pen, inspired tracking menus, the design also works well with a standard mouse and keyboard configuration.}
} 

@inproceedings{Forlines:2005:GNI:1056808.1056920,
 author = {Forlines, Clifton and Shen, Chia and Buxton, Bill},
 title = {Glimpse: a novel input model for multi-level devices},
 booktitle = {CHI '05 Extended Abstracts on Human Factors in Computing Systems},
 series = {CHI EA '05},
 year = {2005},
 isbn = {1-59593-002-7},
 location = {Portland, OR, USA},
 pages = {1375--1378},
 numpages = {4},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1056808.1056920},
 doi = {10.1145/1056808.1056920},
 acmid = {1056920},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {direct manipulation, navigation, pressure sensitive input, stylus, three-state input, touch screens, undo},
 abstract = {We describe a technique that supports the previewing of navigation, exploration, and editing operations by providing convenient Undo for unsuccessful and/or undesirable actions on multi-level input devices such as touch screens and pen-based computers. By adding a Glimpse state to traditional three-state pressure sensitive input devices, users are able to preview the effects of their editing without committing to them. From this Glimpse state, users can undo their action as easily as they can commit to it, making Glimpse most appropriate for systems in which the user is likely to try out many variations of an edit before finding the right one. Exploration is encouraged as the cumbersome returning to a menu or keyboard to issue an Undo command is eliminated. Glimpse has the added benefits that the negative effects of inconsistencies in the Undo feature within an application are reduced.}
}

@inproceedings{Herndon:1992:IS:142621.142622,
 author = {Herndon, Kenneth P. and Zeleznik, Robert C. and Robbins, Daniel C. and Conner, D. Brookshire and Snibbe, Scott S. and van Dam, Andries},
 title = {Interactive shadows},
 booktitle = {Proceedings of the 5th annual ACM symposium on User interface software and technology},
 series = {UIST '92},
 year = {1992},
 isbn = {0-89791-549-6},
 location = {Monteray, California, USA},
 pages = {1--6},
 numpages = {6},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/142621.142622},
 doi = {10.1145/142621.142622},
 acmid = {142622},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3D widgets, direct manipulation, interactive systems},
 abstract = {It is often difficult in computer graphics applications to understand spatial relationships between objects in a 3D scene or effect changes to those objects without specialized visualization and manipulation techniques. We present a set of three-dimensional tools (widgets) called “shadows” that not only provide valuable perceptual cues about the spatial relationships between objects, but also provide a direct manipulation interface to constrained transformation techniques. These shadow widgets provide two advances over previous techniques. First, they provide high correlation between their own geometric feedback and their effects on the objects they control. Second, unlike some other 3D widgets, they do not obscure the objects they control.}
} 

@inproceedings{Hinckley:2005:DAD:1054972.1055035,
 author = {Hinckley, Ken and Baudisch, Patrick and Ramos, Gonzalo and Guimbretiere, Francois},
 title = {Design and analysis of delimiters for selection-action pen gesture phrases in scriboli},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '05},
 year = {2005},
 isbn = {1-58113-998-5},
 location = {Portland, Oregon, USA},
 pages = {451--460},
 numpages = {10},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1054972.1055035},
 doi = {10.1145/1054972.1055035},
 acmid = {1055035},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {delimiters, gestures, marking, pen input, tablets},
 abstract = {We present a quantitative analysis of delimiters for pen gestures. A delimiter is "something different" in the input stream that a computer can use to determine the structure of input phrases. We study four techniques for delimiting a selection-action gesture phrase consisting of lasso selection plus marking-menu-based command activation. Pigtail is a new technique that uses a small loop to delimit lasso selection from marking (Fig. 1). Handle adds a box to the end of the lasso, from which the user makes a second stroke for marking. Timeout uses dwelling with the pen to delimit the lasso from the mark. Button uses a button press to signal when to delimit the gesture. We describe the role of delimiters in our Scriboli pen interaction testbed, and show how Pigtail supports scope selection, command activation, and direct manipulation all in a single fluid pen gesture.}
} 

@inproceedings{Kurtenbach:1991:ICM:120782.120797,
 author = {Kurtenbach, Gordon and Buxton, William},
 title = {Issues in combining marking and direct manipulation techniques},
 booktitle = {Proceedings of the 4th annual ACM symposium on User interface software and technology},
 series = {UIST '91},
 year = {1991},
 isbn = {0-89791-451-1},
 location = {Hilton Head, South Carolina, USA},
 pages = {137--144},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/120782.120797},
 doi = {10.1145/120782.120797},
 acmid = {120797},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract = {The direct manipulation paradigm has been effective in helping designers create easy to use mouse and keyboard based interfaces. The development of flat display surfaces and transparent tablets are now making possible interfaces where a user can write directly on the screen using a special stylus. The intention of these types of interfaces is to exploit user’s existing handwriting, mark-up and drawing skills while also providing the benefits of direct manipulation. This paper reports on a test bed program which we are using for exploring hand-marking types of interactions and their integration with direct manipulation interactions. } 
} 

@article{Malone:1983:POD:357423.357430,
 author = {Malone, Thomas W.},
 title = {How do people organize their desks?: Implications for the design of office information systems},
 journal = {ACM Trans. Inf. Syst.},
 issue_date = {Jan. 1983},
 volume = {1},
 number = {1},
 month = jan,
 year = {1983},
 issn = {1046-8188},
 pages = {99--112},
 numpages = {14},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/357423.357430},
 doi = {10.1145/357423.357430},
 acmid = {357430},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract = {This paper describes a series of interviews focusing on the way professional and clerical office workers organize the information in their desks and offices. A number of implications for designing &quot;natural&quot; and convenient computer-based information systems are discussed. Two principal claims are made: (1) A very important function of desk organization is to remind the user of things to do, not just to help the user find desired information. Failing to support this function may seriously impair the usefulness of electronic office systems, and explicitly facilitating it may provide an important advantage for automated office systems over their nonautomated predecessors. (2) The cognitive difficulty of categorizing information is an important factor in explaining how people organize their desks. Computer-based systems may help with this difficulty by (a) doing as much automatic classification as possible (e.g., based on access dates}, and (b) including untitled &quot;piles &quot; of information arranged by physical location as well as explicitly titled and logically arranged &quot;files.&quot; Several other implications for the design of electronic office systems are discussed, and some differences in how people organize their desks are described. Categories and Subject Descriptors: H.1.2 [Models and Principles]: User/Machine Systems--}
} 


@inproceedings{Mander:1992:LMS:142750.143055,
 author = {Mander, Richard and Salomon, Gitta and Wong, Yin Yin},
 title = {A “pile” metaphor for supporting casual organization of information},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '92},
 year = {1992},
 isbn = {0-89791-513-5},
 location = {Monterey, California, USA},
 pages = {627--634},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/142750.143055},
 doi = {10.1145/142750.143055},
 acmid = {143055},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {design process, desktop metaphor, end-user programming, information organization, information visualization, interactive systems, interface design, interface metaphors, pile metaphor, user observation},
 abstract = {A user study was conducted to investigate how people deal with the flow of information in their workspaces. Subjects reported that, in an attempt to quickly and informally manage their information, they created piles of documents. Piles were seen as complementary to the folder filing system, which was used for more formal archiving. A new desktop interface element–the pile– was developed and prototyped through an iterative process. The design includes direct manipulation techniques and support for browsing, and goes beyond physical world functionality by providing system assistance for automatic pile construction and reorganization. Preliminary user tests indicate the design is promising and raise issues that will be addressed in future work.}
} 


@inproceedings{Miller:2005:CSC:1121987.1122115,
 author = {Miller, Lynn},
 title = {Case Study of Customer Input For a Successful Product},
 booktitle = {Proceedings of the Agile Development Conference},
 series = {ADC '05},
 year = {2005},
 isbn = {0-7695-2487-7},
 pages = {225--234},
 numpages = {10},
 url = {http://dx.doi.org.prox.lib.ncsu.edu/10.1109/ADC.2005.16},
 doi = {10.1109/ADC.2005.16},
 acmid = {1122115},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 abstract = {Both agile development and User Centered Design stress collaboration between customers and product teams, but getting these methodologies to work well together is not easy. This paper describes one company's efforts to merge these processes by creating interconnected parallel design and development tracks. The benefits of this approach are demonstrated by showing how, when and why customer input was incorporated during the release of a successful software product.}
} 
@

@inproceedings{Ramos:2004:PW:985692.985754,
 author = {Ramos, Gonzalo and Boulos, Matthew and Balakrishnan, Ravin},
 title = {Pressure widgets},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '04},
 year = {2004},
 isbn = {1-58113-702-8},
 location = {Vienna, Austria},
 pages = {487--494},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/985692.985754},
 doi = {10.1145/985692.985754},
 acmid = {985754},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {isometric input, pen-based interfaces, pressure input, pressure widgets},
 abstract = {Current user interface widgets typically assume that the input device can only provide x-y position and binary button press information. Other inputs such as the continuous pressure data provided by styluses on tablets are rarely used. We explore the design space of using the continuous pressure sensing capabilities of styluses to operate multi-state widgets. We present the results of a controlled experiment that investigates human ability to perform discrete target selection tasks by varying a stylus' pressure, with full or partial visual feedback. The experiment also considers different techniques for confirming selection once the target is acquired. Based on the experimental results, we discuss implications for the design of pressure sensitive widgets. A taxonomy of pressure widgets is presented, along with a set of initial concept sketches of various pressure widget designs.}
} 

@inproceedings{Robertson:1998:DMU:288392.288596,
 author = {Robertson, George and Czerwinski, Mary and Larson, Kevin and Robbins, Daniel C. and Thiel, David and van Dantzich, Maarten},
 title = {Data mountain: using spatial memory for document management},
 booktitle = {Proceedings of the 11th annual ACM symposium on User interface software and technology},
 series = {UIST '98},
 year = {1998},
 isbn = {1-58113-034-1},
 location = {San Francisco, California, USA},
 pages = {153--162},
 numpages = {10},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/288392.288596},
 doi = {10.1145/288392.288596},
 acmid = {288596},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3D user interfaces, desktop VR, document mangement, information visualization, spatial cognition, spatial memory},
 abstract = {Effective management of documents on computers has been a central user interface problem for many years.  One common approach involves using 2D spatial layouts of icons representing the documents, particularly for information workspace tasks. This approach takes advantage of human 2D spatial cognition. More recently, several 3D spatial layouts have engaged 3D spatial cognition capabilities. Some have attempted to use spatial memory in 3D virtual environments. However, there has been no proof to date that spatial memory works the same way in 3D virtual environments as it does in the real world. We describe a new technique for document management called the Data Mountain, which allows users to place documents at arbitrary positions on an inclined plane in a 3D desktop virtual environment using a simple 2D interaction technique. We discuss how the design evolved in response to user feedback. We also describe a user study that shows that the Data Mountain does take advantage of spatial memory. Our study shows that the Data Mountain has statistically reliable advantages over the Microsoft Internet Explorer Favorites mechanism for managing documents of interest in an information workspace.}
} 

@inproceedings{Robertson:2000:TGW:332040.332482,
 author = {Robertson, George and van Dantzich, Maarten and Robbins, Daniel and Czerwinski, Mary and Hinckley, Ken and Risden, Kirsten and Thiel, David and Gorokhovsky, Vadim},
 title = {The Task Gallery: a 3D window manager},
 booktitle = {Proceedings of the SIGCHI conference on Human Factors in Computing Systems},
 series = {CHI '00},
 year = {2000},
 isbn = {1-58113-216-6},
 location = {The Hague, The Netherlands},
 pages = {494--501},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/332040.332482},
 doi = {10.1145/332040.332482},
 acmid = {332482},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3D user interfaces, spatial cognition, spatial memory, window managers},
 abstract = {The Task Gallery is a window manager that uses interactive 3D graphics to provide direct support for task management and document comparison, lacking from many systems implementing the desktop metaphor. User tasks appear as artwork hung on the walls of a virtual art gallery, with the selected task on a stage. Multiple documents can be selected and displayed side-by-side using 3D space to provide uniform and intuitive scaling. The Task Gallery hosts any Windows application, using a novel redirection mechanism that routes input and output between the 3D environment and unmodified 2D Windows applications. User studies suggest that the Task Gallery helps with task management, is enjoyable to use, and that the 3D metaphor evokes spatial memory and cognition.}
} 

@book{Sellen:2003:MPO:778158,
 author = {Sellen, Abigail J. and Harper, Richard H.R.},
 title = {The Myth of the Paperless Office},
 year = {2003},
 isbn = {026269283X},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 
@inproceedings{Thorne:2004:MDI:1186562.1015740,
 author = {Thorne, Matthew and Burke, David and van de Panne, Michiel},
 title = {Motion doodles: an interface for sketching character motion},
 booktitle = {ACM SIGGRAPH 2004 Papers},
 series = {SIGGRAPH '04},
 year = {2004},
 location = {Los Angeles, California},
 pages = {424--431},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1186562.1015740},
 doi = {10.1145/1186562.1015740},
 acmid = {1015740},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Animation, Computer Puppetry, Gestural Interfaces, Sketching},
 abstract = {In this paper we present a novel system for sketching the motion of a character. The process begins by sketching a character to be animated. An animated motion is then created for the character by drawing a continuous sequence of lines, arcs, and loops. These are parsed and mapped to a parameterized set of output motions that further reflect the location and timing of the input sketch. The current system supports a repertoire of 18 different types of motions in 2D and a subset of these in 3D. The system is unique in its use of a cursive motion specification, its ability to allow for fast experimentation, and its ease of use for non-experts.}
} 

@article{Whittaker:2001:CVM:376929.376932,
 author = {Whittaker, Steve and Hirschberg, Julia},
 title = {The character, value, and management of personal paper archives},
 journal = {ACM Trans. Comput.-Hum. Interact.},
 issue_date = {June 2001},
 volume = {8},
 number = {2},
 month = jun,
 year = {2001},
 issn = {1073-0516},
 pages = {150--170},
 numpages = {21},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/376929.376932},
 doi = {10.1145/376929.376932},
 acmid = {376932},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {archiving, document management, filing, information retrieval, paper, personal information management},
 abstract = {We explored general issues concerning personal information management by investigating the characteristics of office workers' paper-based information, in an industrial research environment. we examined the reasons people collect paper, types of data they collect, problems encountered in handling paper, and strategies used for processing it. We tested three specific hypotheses in the course of an office move. The greater availability of public digital data along with changes in people's jobs or interests should lead to wholescale discarding of paper data, while preparing for the move. Instead we found workers kept large, highly valued papar archives. We also expected that the major part of people's personal archives would be unique documents. However, only 49% of people's archives were unique documents, the remainder being copies of publicly available data and unread information, and we explore reasons for this. We examined the effects of paper-processing strategies on archive structure. We discovered different paper-processing strategies (filing and piling)that were relatively independent of job type. We predicated that filers' attempted to evaluate and catergorize incoming documents would produce smaller archives that were accessed frequently. Contrary to our predictions, filers amassed more information, and accessed it less frequently than pilers. We argue that filers may engage in premature filing: to clear their workspace, they archives information that later turns out to be of low value. Given the effort involved in organzing data, they are also loath to discard filed information, even when its value is uncertain. We discuss the implications of this research for digital personal information management.}
}
















@inproceedings{Nacenta:2006:PCP:1124772.1124817,
 author = {Nacenta, Miguel A. and Sallam, Samer and Champoux, Bernard and Subramanian, Sriram and Gutwin, Carl},
 title = {Perspective cursor: perspective-based interaction for multi-display environments},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '06},
 year = {2006},
 isbn = {1-59593-372-7},
 location = {Montr\&\#233;al, Qu\&\#233;bec, Canada},
 pages = {289--298},
 numpages = {10},
 doi = {10.1145/1124772.1124817},
 acmid = {1124817},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {direct-manipulation interfaces, laser pointing, multi-display interaction techniques, multi-monitor environments},
 abstract = {Multi-display environments and smart meeting rooms are now becoming more common. These environments build a shared display space from variety of devices: tablets, projected surfaces, tabletops, and traditional monitors. Since the different display surfaces are usually not organized in a single plane, traditional schemes for stitching the displays together can cause problems for interaction. However, there is a more natural way to compose display space -- using perspective. In this paper, we develop interaction techniques for multi-display environments that are based on the user's perspective on the room. We designed the Perspective Cursor, a mapping of cursor to display space that appears natural and logical from wherever the user is located. We conducted an experiment to compare two perspective-based techniques, the Perspective Cursor and a beam-based technique, with traditional stitched displays. We found that both perspective techniques were significantly faster for targeting tasks than the traditional technique, and that Perspective Cursor was the most preferred method. Our results show that integrating perspective into the design of multi-display environments can substantially improve performance.}
}

@inproceedings{Findlater:2008:ISS:1357054.1357249,
 author = {Findlater, Leah and McGrenere, Joanna},
 title = {Impact of screen size on performance, awareness, and user satisfaction with adaptive graphical user interfaces},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '08},
 year = {2008},
 isbn = {978-1-60558-011-1},
 location = {Florence, Italy},
 pages = {1247--1256},
 numpages = {10},
 doi = {10.1145/1357054.1357249},
 acmid = {1357249},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {adaptive interfaces, interaction techniques, menu design, personalization, small screen devices, user study},
 abstract = {Adaptive personalization, where the system adapts the interface to a user's needs, has the potential for significant performance benefits on small screen devices. However, research on adaptive interfaces has almost exclusively focused on desktop displays. To explore how well previous findings generalize to small screen devices, we conducted a study with 36 subjects to compare adaptive interfaces for small and desktop-sized screens. Results show that high accuracy adaptive menus have an even larger positive impact on performance and satisfaction when screen real estate is constrained. The drawback of the high accuracy menus, however, is that they reduce the user's awareness of the full set of items in the interface, potentially making it more difficult for users to learn about new features.}
}

@article{Kuhn:1998:SDS:624624.625838,
 author = {Kuhn, Sarah},
 title = {The Software Design Studio: An Exploration},
 journal = {IEEE Softw.},
 issue_date = {March 1998},
 volume = {15},
 number = {2},
 month = mar,
 year = {1998},
 issn = {0740-7459},
 pages = {65--71},
 numpages = {7},
 doi = {10.1109/52.663788},
 acmid = {625838},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
 abstract = {Some software designers have recently turned to building architecture for inspiration in their efforts to improve professional practice. An attempt to apply the studio method of architectural training to software design education, reported in this article, reveals much about education and practice in both professions. Studio courses provoke creative reflection on how to improve current training practices and could provide a new way to develop software design expertise.}
}

@article{Piattini:1997:ALM:263244.263268,
 author = {Piattini, Mario G. and Tigr{\'e}at, Herv{\'e}},
 title = {Applying the \“STUDIO\” method to the interface design of an environmental software system},
 journal = {SIGSOFT Softw. Eng. Notes},
 issue_date = {July 1997},
 volume = {22},
 number = {4},
 month = jul,
 year = {1997},
 issn = {0163-5948},
 pages = {81--83},
 numpages = {3},
 doi = {10.1145/263244.263268},
 acmid = {263268},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {STUDIO, design method, interface-design},
 abstract = {This paper addresses the application of the STUDIO (STructured User-interface Design for Interaction Optimization) method to the user-interface development of an information system (called "HIMPPA") that allows the simulation of heavy-particle dispersion. This method has been proposed in 1994 by D.P. Browne. We have adapted and integrated it with an object-oriented design technique for the HIMPPA project (an ESPRIT-PASO Special Action).}
}

@article{Hazzan:2002:RPP:771439.771440,
 author = {Hazzan, Orit},
 title = {The reflective practitioner perspective in software engineering education},
 journal = {J. Syst. Softw.},
 issue_date = {15 September 2002},
 volume = {63},
 number = {3},
 month = sep,
 year = {2002},
 issn = {0164-1212},
 pages = {161--171},
 numpages = {11},
 doi = {10.1016/S0164-1212(02)00012-2},
 acmid = {771440},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
 abstract = {This paper focuses on the application of the reflective practitioner (RP) perspective to the profession of software engineering (SE). The RP perspective guides professional people to rethink their professional creations during and after the accomplishment of the creation process. Analysis of the field of SE supports the adoption of the RP perspective to SE in general and to SE education in particular. The RP perspective emphasizes the studio--the basic training method in architecture schools--as the educational environment for design studies. In such studios students develop projects with a close guidance of a tutor. Analysis of the kind of tasks that architecture students are working on and a comparison of these tasks to the problems that SE students are facing, suggest that the studio may be an appropriate teaching method in SE as well. The paper presents the main ideas of the RP perspective and examines its fitness to SE in general and to SE education in particular. The discussion is based on analysis of the RP perspective and of the SE profession, visits to architecture studios, and conversations with tutors in architecture studios and with computing science practitioners.}
}
@inproceedings{Yamazaki:2007:DTU:1772490.1772524,
 author = {Yamazaki, Kazuhiko and Furuta, Kazuo},
 title = {Design tools for user experience design},
 booktitle = {Proceedings of the 12th international conference on Human-computer interaction: interaction design and usability},
 series = {HCI'07},
 year = {2007},
 isbn = {978-3-540-73104-7},
 location = {Beijing, China},
 pages = {298--307},
 numpages = {10},
 acmid = {1772524},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 abstract = {The purpose of this study is to develop an approach to artifacts design based on information technology. To make interactive system easy to use, user centered design approach is utilized by many systems. For user centered design, it is important to consider total user experience. But it is not easy to consider total user experience because user experience is including many aspects. To approach total user experience, the author proposes the method of designing for user experience that consist of "User viewpoint", "Environment viewpoint" and "Lifecycle viewpoint". "User viewpoint" is including several user groups from universal design viewpoint, several user characters and several user emotions. "Environment viewpoint" is including hardware product, software, application, space, people who is communicating. "Lifecycle viewpoint" is including pre sales, after sales, support, upgrade, setup product and application.  To help this design approach, user experience design tool named "UED (User Experience Design) Studio" was proposed. Based on proposed three approaches, design tools were developed such as "The definition tool", "The evaluation tool" and "The visualization tool" for user experience design. To define user experience situation easily, "The definition tool" helps designer such selecting user group, selecting environment and input user tasks based on life cycle state. "The evaluation tool" is to evaluate defined user experience easily. And "The visualization tool" is to show the result of evaluation by 3 D graphics easy to understand complicated information.  To evaluate proposed tools, experiment to make prototype was conducted and the results indicate that the proposed approach has possibility to help designer and multi-disciplinary team to consider user experience for user centered design.}
}

@article{Bobick:1999:KPI:1246829.1246830,
 author = {Bobick, Aaron F. and Intille, Stephen S. and Davis, James W. and Baird, Freedom and Pinhanez, Claudio S. and Campbell, Lee W. and Ivanov, Yuri A. and Sch\"{u}tte, Arjan and Wilson, Andrew},
 title = {The KidsRoom: A Perceptually-Based Interactive and Immersive Story Environment},
 journal = {Presence: Teleoper. Virtual Environ.},
 issue_date = {August 1999},
 volume = {8},
 number = {4},
 month = aug,
 year = {1999},
 issn = {1054-7460},
 pages = {369--393},
 numpages = {25},
 doi = {10.1162/105474699566297},
 acmid = {1246830},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA}, 
 abstract = {The KidsRoom is a perceptually-based, interactive, narrative playspace for children. Images, music, narration, light, and sound effects are used to transform a normal child's bedroom into a fantasy land where children are guided through a reactive adventure story. The fully automated system was designed with the following goals: (1) to keep the focus of user action and interaction in the physical and not virtual space; (2) to permit multiple, collaborating people to simultaneously engage in an interactive experience combining both real and virtual objects; (3) to use computer-vision algorithms to identify activity in the space without requiring the participants to wear any special clothing or devices; (4) to use narrative to constrain the perceptual recognition, and to use perceptual recognition to allow participants to drive the narrative; and (5) to create a truly immersive and interactive room environment.  We believe the KidsRoom is the first multi-person, fully-automated, interactive, narrative environment ever constructed using non-encumbering sensors. This paper describes the KidsRoom, the technology that makes it work, and the issues that were raised during the system's development.<xref ref-type="fn" rid="fn1">1</xref>  A demonstration of the project, which complements the material presented here and includes videos, images, and sounds from each part of the story is available at somewhere.}
}

@inproceedings{Poupyrev:2002:ATD:571985.571993,
 author = {Poupyrev, Ivan and Maruyama, Shigeaki and Rekimoto, Jun},
 title = {Ambient touch: designing tactile interfaces for handheld devices},
 booktitle = {Proceedings of the 15th annual ACM symposium on User interface software and technology},
 series = {UIST '02},
 year = {2002},
 isbn = {1-58113-488-6},
 location = {Paris, France},
 pages = {51--60},
 numpages = {10},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/571985.571993},
 doi = {10.1145/571985.571993},
 acmid = {571993},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {mobile devices and interfaces, tactile feedback},
 abstract = {This paper investigates the sense of touch as a channel for communicating with miniature handheld devices. We embedded a PDA with a TouchEngineTM --- a thin, miniature lower-power tactile actuator that we have designed specifically to use in mobile interfaces (Figure 1). Unlike previous tactile actuators, the TouchEngine is a universal tactile display that can produce a wide variety of tactile feelings from simple clicks to complex vibrotactile patterns. Using the TouchEngine, we began exploring the design space of interactive tactile feedback for handheld computers. Here, we investigated only a subset of this space: using touch as the ambient, background channel of interaction. We proposed a general approach to design such tactile interfaces and described several implemented prototypes. Finally, our user studies demonstrated 22% faster task completion when we enhanced handheld tilting interfaces with tactile feedback.}
} 

@inproceedings{Oehl:2007:CET:1766451.1766469,
 author = {Oehl, Michael and Sutter, Christine and Ziefle, Martina},
 title = {Considerations on efficient touch interfaces: how display size influences the performance in an applied pointing task},
 booktitle = {Proceedings of the 2007 conference on Human interface: Part I},
 year = {2007},
 isbn = {978-3-540-73344-7},
 location = {Beijing, China},
 pages = {136--143},
 numpages = {8},
 url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1766451.1766469},
 acmid = {1766469},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {display size, pointing performance, small screen device, task difficulty, touch input},
 abstract = {The limited screen space in small technical devices imposes considerable usability challenges. On the one hand objects displayed on small screens should be big enough to be hit successfully, but also small enough to house several objects on the screen at the same time. However, findings up to now show that single pointing is more effective in a large display compared to a smaller display. In the present experiment this was also confirmed for an applied multidirectional serial pointing task. Especially in more difficult tasks, results point at a shift of the speed-accuracy tradeoff. In large displays a fast and comparably accurate execution is chosen in contrast to a very inaccurate and time-consuming style in small displays. From an ergonomic point of view the outcomes recommend an optimized balance of task difficulty and display size in small screen devices.}
}  

  @inproceedings{Jin:2007:TSU:1766311.1766419,
 author = {Jin, Zhao Xia and Plocher, Tom and Kiff, Liana},
 title = {Touch screen user interfaces for older adults: button size and spacing},
 booktitle = {Proceedings of the 4th international conference on Universal access in human computer interaction: coping with diversity},
 series = {UAHCI'07},
 year = {2007},
 isbn = {978-3-540-73278-5},
 location = {Beijing, China},
 pages = {933--941},
 numpages = {9},
 url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1766311.1766419},
 acmid = {1766419},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {older adults, touch screen, usability, user interface design},
 abstract = {This study investigated the optimal button size and spacing for touch screen user interfaces intended for use by older adults. Current recommendations in the literature are aimed at general audiences and fail to consider the specific needs of older adults. Three independent variables, button size, button spacing, and manual dexterity were studied in two experiments that measured reaction time, accuracy and user preferences. Design recommendations for touch screen button size and spacing for older adults are stated based on these experiments. The paper also discusses the role of manual dexterity in designing appropriate touch screen interfaces for older adults.}
} 

@inproceedings{Matulic:2007:TST:1284420.1284448,
 author = {Matulic, Fabrice},
 title = {Touch scan-n-search: a touchscreen interface to retrieve online versions of scanned documents},
 booktitle = {Proceedings of the 2007 ACM symposium on Document engineering},
 series = {DocEng '07},
 year = {2007},
 isbn = {978-1-59593-776-6},
 location = {Winnipeg, Manitoba, Canada},
 pages = {97--98},
 numpages = {2},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1284420.1284448},
 doi = {10.1145/1284420.1284448},
 acmid = {1284448},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {GUI, keyword extraction, online news retrieval, scanned document},
 abstract = {The system described in this paper attempts to tackle the problem of finding online content based on paper documents through an intuitive touchscreen interface designed for modern scanners and multifunction printers. Touch Scan-n-Search allows the user to select elements of a scanned document (e.g. a newspaper article) and to seamlessly connect to common web search services in order to retrieve the online version of the document along with related content. This is achieved by automatically extracting keyphrases from text elements in the document (obtained by OCR) and creating "tappable" GUI widgets to allow the user to control and fine-tune the search requests. The retrieved content can then be printed, sent, or used to compose new documents.}
}

@inproceedings{Motamedi:2007:KTT:1226969.1226974,
 author = {Motamedi, Nima},
 title = {Keep in touch: a tactile-vision intimate interface},
 booktitle = {Proceedings of the 1st international conference on Tangible and embedded interaction},
 series = {TEI '07},
 year = {2007},
 isbn = {978-1-59593-619-6},
 location = {Baton Rouge, Louisiana},
 pages = {21--22},
 numpages = {2},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1226969.1226974},
 doi = {10.1145/1226969.1226974},
 acmid = {1226974},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {intimacy, sensorial interfaces, sensory mapping, tactile},
 abstract = {We present an overview of Keep in Touch, a networked fabric touchscreen designed to support and maintain intimacy for couples in long distance relationships. To achieve this, a novel sensorial interface was created by combining the visual and tactile senses together. Each partner is presented with a blurred digital projection of their lover. When they touch their partner's body, the image comes into focus revealing their features. We describe how this sensory mapping creates an expressive and emotional interface allowing couples to communicate through touch, gestures, and body language.}
} 

@inproceedings{Kristensson:2008:IEM:1463160.1463227,
 author = {Kristensson, Per Ola and Arnell, Olof and Bj\"{o}rk, Annelie and Dahlb\"{a}ck, Nils and Pennerup, Joackim and Prytz, Erik and Wikman, Johan and \AAstr\"{o}m, Niclas},
 title = {InfoTouch: an explorative multi-touch visualization interface for tagged photo collections},
 booktitle = {Proceedings of the 5th Nordic conference on Human-computer interaction: building bridges},
 series = {NordiCHI '08},
 year = {2008},
 isbn = {978-1-59593-704-9},
 location = {Lund, Sweden},
 pages = {491--494},
 numpages = {4},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1463160.1463227},
 doi = {10.1145/1463160.1463227},
 acmid = {1463227},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {information visualization, interaction surfaces, multi-touch, photo browsing, photo collections, tag clouds, tagging, tags, visualization},
 abstract = {We report on a design exploration into how a large multi-touch tabletop display can be used for information visualization. We designed an interface where users explored a tagged photo collection by bi-manual manipulation of the collections' tag cloud. User feedback showed that despite the availability of multi-touch most of the actual interactions were single-touch. However, some particular natural actions, such as grabbing the tag cloud and partitioning it into two parts, were often carried with both hands. Thus our user study indicates that multi-touch can act as a useful complementary interaction method in information visualization interfaces.}
} 

@inproceedings{Shen:2007:CTE:1784297.1784317,
 author = {Shen, Chia},
 title = {From clicks to touches: enabling face-to-face shared social interface on multi-touch tabletops},
 booktitle = {Proceedings of the 2nd international conference on Online communities and social computing},
 series = {OCSC'07},
 year = {2007},
 isbn = {978-3-540-73256-3},
 location = {Beijing, China},
 pages = {169--175},
 numpages = {7},
 url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1784297.1784317},
 acmid = {1784317},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 abstract = {Making the interactions with a digital user interface disappears into and becomes a part of the human to human interaction and conversation is a challenge. Conventional metaphor and underlying interface infrastructure for single-user desktop systems have been traditionally geared towards single mouse and keyboard, click-and-type based, WIMP interface design. On the other hand, people usually meet in social context around a table, facing each other. A table setting provides a large interactive visual and tangible surface. It affords and encourages collaboration, coordination, serendipity, as well as simultaneous and parallel interaction among multiple people. In this paper, we examine and explore the opportunities, challenges, research issues, pitfalls, and plausible approaches for enabling direct touchable, shared social interactions on multi-touch multi-user tabletops.}
} 
 
 
@inproceedings{Vogt:2004:MST:1186223.1186268,
 author = {Vogt, Florian and Chen, Timothy and Hoskinson, Reynald and Fels, Sidney},
 title = {A malleable surface touch interface},
 booktitle = {ACM SIGGRAPH 2004 Sketches},
 series = {SIGGRAPH '04},
 year = {2004},
 isbn = {1-58113-896-2},
 location = {Los Angeles, California},
 pages = {36--},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1186223.1186268},
 doi = {10.1145/1186223.1186268},
 acmid = {1186268},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract = {Many conventional whole-hand input devices capture interaction by means of non-contact methods or through some physical medium. Such physical interfaces often involve contact of the hands and fingers with a hard, unyielding surface. In this sketch, we propose an input device that captures whole-hand input through a malleable medium. Its deformability and inherent feedback characteristics make it suitable for sculpting and molding applications.} 
}

@inproceedings{Bharath:2008:FNH:1378773.1378814,
 author = {Bharath, A. and Madhvanath, Sriganesh},
 title = {FreePad: a novel handwriting-based text input for pen and touch interfaces},
 booktitle = {Proceedings of the 13th international conference on Intelligent user interfaces},
 series = {IUI '08},
 year = {2008},
 isbn = {978-1-59593-987-6},
 location = {Gran Canaria, Spain},
 pages = {297--300},
 numpages = {4},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1378773.1378814},
 doi = {10.1145/1378773.1378814},
 acmid = {1378814},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {handwriting recognition, pen and touch interfaces, text input},
 abstract = {The last decade has seen tremendous growth in mobile devices such as Pocket PCs, mobile phones, Tablet PCs and notebooks. Most of these devices enable interaction through a stylus or touch interface, powered by handwriting recognition (HWR) capability. In this paper, we propose a novel input method that addresses some of the issues that arise due to the constraints posed by these devices in accepting handwriting input. For instance, many of the devices have a small writing area making "continuous" input difficult if not impossible, and the process of handwriting input demands significant user attention. The proposed solution is inspired by touch-typing, and appreciably reduces user's effort in the interaction, and it is especially suited for very small writing areas. The approach has been demonstrated using a prototype system that recognizes handwritten English words, and its accuracy has been evaluated using a standard dataset of handwritten words. A preliminary user study has also been carried out to understand user acceptance of the proposed technique.}
}
