@inproceedings{Qiao:2008:IPM:1791734.1791781,
 author = {Qiao, Lin and Feng, Ling and Zhou, Lizhu},
 title = {Information presentation on mobile devices: techniques and practices},
 booktitle = {Proceedings of the 10th Asia-Pacific web conference on Progress in WWW research and development},
 series = {APWeb'08},
 year = {2008},
 isbn = {3-540-78848-4, 978-3-540-78848-5},
 location = {Shenyang, China},
 pages = {395--406},
 numpages = {12},
 acmid = {1791781},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 abstract = {The popularity of hand-held mobile devices, such as personal digital assistants (PDA) and smart cell phones, is growing. Compared with traditional desktop computers, these mobile devices have distinct limitations, including tiny displays, scarce computing hardware resources, bandwidth fluctuations, ad-hoc communications, voluntary, and involuntary disconnections, etc., presenting new challenges to human-computer interaction on mobile devices. In this paper, we survey research efforts done on mobile device user interface design. Some recently developed techniques for diverse information presentation via visual, audio, and tactile channels are reported. We also brief on our experiences in virtually presenting database query results on PDAs, including both presentation style and presentation content.}
} 

@inproceedings{Jumisko-Pyykko:2008:DUE:1453805.1453841,
 author = {Jumisko-Pyykk\"{o}, Satu and Weitzel, Mandy and Strohmeier, Dominik},
 title = {Designing for user experience: what to expect from mobile 3d tv and video?},
 booktitle = {Proceedings of the 1st international conference on Designing interactive user experiences for TV and video},
 series = {UXTV '08},
 year = {2008},
 isbn = {978-1-60558-100-2},
 location = {Silicon Valley, California, USA},
 pages = {183--192},
 numpages = {10},
 doi = {10.1145/1453805.1453841},
 acmid = {1453841},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3d tv, methods, mobile 3d tv, mobile tv, user experience, user requirements},
 abstract = {A long process has been undertaken to develop the technology of 3D video for consumer products, but studies to determine the needs and expectations of actual users have been disregarded. The object of this study is to examine users' needs, expectations and requirements for mobile 3D television and video. We conducted three user studies applying triangulation methodology of the extensive survey, focus groups and probe studies to identify the requirements. The results are presented in the form of guidelines which highlight the characteristics of users, the system and service required including what content is interesting and the context in which it will be used. Both academia and industry can benefit from knowledge of these requirements when designing the further studies and development work concerning the user experience of 3D television and video.}
} 
@inproceedings{Zhang:2006:PVH:1141277.1141517,
 author = {Zhang, Dongsong and Karabatis, George and Chen, Zhiyuan and Adipat, Boonlit and Dai, Liwei and Zhang, Zhenxue and Wang, Yu},
 title = {Personalization and visualization on handheld devices},
 booktitle = {Proceedings of the 2006 ACM symposium on Applied computing},
 series = {SAC '06},
 year = {2006},
 isbn = {1-59593-108-2},
 location = {Dijon, France},
 pages = {1008--1012},
 numpages = {5},
 doi = {10.1145/1141277.1141517},
 acmid = {1141517},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {PDA, clustering, mobile devices, user profiles, visualization},
 abstract = {The small screen size of handheld mobile devices poses an inherent problem in visualizing data: very often it is too difficult and unpleasant to navigate through the plethora of presented information. This paper presents a novel approach to personalized and adaptive content presentation for handheld devices, which has been implemented in a mobile financial application system based on a 3-tier architecture. The approach is independent of wireless networks and mobile devices. It utilizes a combination of user profiling, data clustering, and visualization techniques (fisheye and semantic zooming), enhancing the understandability of the data and improving the usability of the device.}
} 


 @article{Stock:2007:AIP:1265316.1265324,
 author = {Stock, Oliviero and Zancanaro, Massimo and Busetta, Paolo and Callaway, Charles and Kr\"{u}ger, Antonio and Kruppa, Michael and Kuflik, Tsvi and Not, Elena and Rocchi, Cesare},
 title = {Adaptive, intelligent presentation of information for the museum visitor in PEACH},
 journal = {User Modeling and User-Adapted Interaction},
 issue_date = {July      2007},
 volume = {17},
 number = {3},
 month = jul,
 year = {2007},
 issn = {0924-1868},
 pages = {257--304},
 numpages = {48},
 doi = {10.1007/s11257-007-9029-6},
 acmid = {1265324},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Adaptive mobile guides, Multimodal user interfaces, Personal visit report, Personalized information presentation},
 abstract = {The study of intelligent user interfaces and user modeling and adaptation is well suited for augmenting educational visits to museums. We have defined a novel integrated framework for museum visits and claim that such a framework is essential in such a vast domain that inherently implies complex interactivity. We found that it requires a significant investment in software and hardware infrastructure, design and implementation of intelligent interfaces, and a systematic and iterative evaluation of the design and functionality of user interfaces, involving actual visitors at every stage. We defined and built a suite of interactive and user-adaptive technologies for museum visitors, which was then evaluated at the Buonconsiglio Castle in Trento, Italy: (1) animated agents that help motivate visitors and focus their attention when necessary, (2) automatically generated, adaptive video documentaries on mobile devices, and (3) automatically generated post-visit summaries that reflect the individual interests of visitors as determined by their behavior and choices during their visit. These components are supported by underlying user modeling and inference mechanisms that allow for adaptivity and personalization. Novel software infrastructure allows for agent connectivity and fusion of multiple positioning data streams in the museum space. We conducted several experiments, focusing on various aspects of PEACH. In one, conducted with 110 visitors, we found evidence that even older users are comfortable interacting with a major component of the system.}
}
@article{Krishnan:2005:TAT:1045117.1045122,
 author = {Krishnan, Aparna and Jones, Steve},
 title = {TimeSpace: activity-based temporal visualisation of personal information spaces},
 journal = {Personal Ubiquitous Comput.},
 issue_date = {January 2005},
 volume = {9},
 number = {1},
 month = jan,
 year = {2005},
 issn = {1617-4909},
 pages = {46--65},
 numpages = {20},
 doi = {10.1007/s00779-004-0291-x},
 acmid = {1045122},
 publisher = {Springer-Verlag},
 address = {London, UK, UK},
 keywords = {Information management, Personal information spaces, Visualisation},
 abstract = {Users’ personal information spaces are characterized by their content, organisation, and ongoing user interaction with them. They are fluid entities, evolving over time, and supporting multiple user activities that may require different perspectives of the same underlying information structure. Increasing storage capacity of computing devices and ready access to networked resources puts users at risk of information overload, and presents increasing challenges in organising and accessing their information. The hierarchical model of information organisation currently dominates personal computing, and is realised for the user in interfaces that help to manage and access filestore hierarchies. Such a model provides limited inherent support for what users do—carry out a range of interleaved activities over time. In this paper, we describe the TimeSpace system, which provides perspectives on a user’s information resources based on activities and temporal attributes of the information. TimeSpace can be used alongside, or in place of, existing systems and models (such as the Microsoft Windows hierarchical file model). User interaction with an information space is non-intrusively observed and then represented automatically in TimeSpace. Visualisations provide overviews of user activity on multiple projects and detailed views of activity within particular projects, allowing navigation forward and backward in time. An observational study of use of the system revealed positive user views of the utility of temporal, activity-oriented workspaces in real world contexts alongside existing tools. Participants appreciated being offered a different perspective on their electronic information collection, one that visually shows the composition and development of their information space. They were interested in using the system for current and long-term work as well as for archiving information, as the visualisations provide a context for their work and give an overview of all their work in progress. The ideas embodied by the system and its visualisations show promise and raise a number of issues for further exploration. In future work, these ideas will be adapted and extended to support users in managing their information spaces across multiple personal devices, locations and time.}
}
@article{Chittaro:2006:VIM:1128587.1128639,
 author = {Chittaro, Luca},
 title = {Visualizing Information on Mobile Devices},
 journal = {Computer},
 issue_date = {March 2006},
 volume = {39},
 number = {3},
 month = mar,
 year = {2006},
 issn = {0018-9162},
 pages = {40--45},
 numpages = {6},
 doi = {10.1109/MC.2006.109},
 acmid = {1128639},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
 keywords = {Mobile display technology, Mobile display technology, Mobile visualizations, Mobile visualizations},
 abstract = {Visualization can make a wide range of mobile applications more intuitive and productive. The mobility context and technical limitations such as small screen size make it impossible to simply port visualization applications from desktop computers to mobile devices, but researchers are starting to address these challenges.}
}
@inproceedings{Burigat:2006:VLO:1152215.1152266,
 author = {Burigat, Stefano and Chittaro, Luca and Gabrielli, Silvia},
 title = {Visualizing locations of off-screen objects on mobile devices: a comparative evaluation of three approaches},
 booktitle = {Proceedings of the 8th conference on Human-computer interaction with mobile devices and services},
 series = {MobileHCI '06},
 year = {2006},
 isbn = {1-59593-390-5},
 location = {Helsinki, Finland},
 pages = {239--246},
 numpages = {8},
 doi = {10.1145/1152215.1152266},
 acmid = {1152266},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {maps, mobile devices, off-screen locations, visualization},
 abstract = {Browsing large information spaces such as maps on the limited screen of mobile devices often requires people to perform panning and zooming operations that move relevant display content off-screen. This makes it difficult to perform spatial tasks such as finding the location of Points Of Interest (POIs) in a city. Visualizing the location of off-screen objects can mitigate this problem: in this paper, we present a user study comparing the Halo [2] approach with two other techniques based on arrows. Halo surrounds off-screen objects with circles that reach the display window, so that users can derive the location and distance of objects by observing the visible portion of the corresponding circles. In the two arrow-based techniques, arrows point at objects and their size and body length, respectively, inform about the distance of objects. Our study involved four tasks requiring users to identify and compare off-screen objects locations, and also investigated the effectiveness of the three techniques with respect to the number of off-screen objects. Arrows allowed users to order off-screen objects faster and more accurately according to their distance, while Halo allowed users to better identify the correct location of off-screen objects. Implications of these results for mobile map-based applications are also discussed.}
}

@article{Aaltonen:2005:RVR:1102913.1102919,
 author = {Aaltonen, Antti and Lehikoinen, Juha},
 title = {Refining visualization reference model for context information},
 journal = {Personal Ubiquitous Comput.},
 issue_date = {November 2005},
 volume = {9},
 number = {6},
 month = nov,
 year = {2005},
 issn = {1617-4909},
 pages = {381--394},
 numpages = {14},
 doi = {10.1007/s00779-005-0349-4},
 acmid = {1102919},
 publisher = {Springer-Verlag},
 address = {London, UK, UK},
 keywords = {Context awareness, Hand-held devices, Information visualization, Mobile phones, Visualization reference model},
 abstract = {Context-awareness can be used to decrease the need for interaction with a mobile device. This is increasingly important since the functionality of mobile devices and personal digital assistants gets more and more complex while the input and output capabilities remain restricted. An important aspect of context-awareness is to present the current context to the user. We propose a model for visualizing contextual information on the mobile terminal screen. The model is a refinement of a well-known visualization reference model; it takes into account the specific characteristics of mobile use and context information. We present the design of the model in detail, and discuss its applicability for a variety of contexts and tasks by providing a full-fledged use case.}
}
@inproceedings{Fallman:2005:DCI:1138235.1138283,
 author = {Fallman, Daniel and Kruzeniski, Mike and Andersson, Mattias},
 title = {Designing for a collaborative industrial environment: the case of the ABB Powerwall},
 booktitle = {Proceedings of the 2005 conference on Designing for User eXperience},
 series = {DUX '05},
 year = {2005},
 isbn = {1-59593-250-X},
 location = {San Francisco, California},
 articleno = {41},
 acmid = {1138283},
 publisher = {AIGA: American Institute of Graphic Arts},
 address = {New York, NY, USA},
 keywords = {collaboration, collaborative work, human-computer interaction, industrial environment, interaction design, mobile devices, prototyping, user experience},
 abstract = {This paper presents the design of a collaborative interface for highly automated, industrial environments. The resulting system, the ABB Powerwall, consists of large, shared interactive displays and several personal mobile information technology devices. On-site service technicians can seamlessly move information back and forth from their mobile devices to the shared display. The system supports various kinds of collaborative work, including making annotations; browsing for information; and visualizing blueprints and three-dimensional representations of products and torrents.The design vision has been to provide end users with an unobtrusive way of sharing information, discussing problems and issues with others in front of a large collaborative screen, and the chance of socializing and learning from each other. Located strategically in the specific environment for which it has been designed, the ABB Powerwall is intended to become a natural gathering point that increases interaction, afford gathering, discussions, collaboration, small talk, socializing, and community-making.}
}
@inproceedings{Jurmu:2008:SRD:1594978.1595017,
 author = {Jurmu, Marko and Boring, Sebastian and Riekki, Jukka},
 title = {ScreenSpot resource discovery for smart spaces and mobilevue media sharing application},
 booktitle = {Proceedings of the 5th Annual International Conference on Mobile and Ubiquitous Systems: Computing, Networking, and Services},
 series = {Mobiquitous '08},
 year = {2008},
 isbn = {978-963-9799-27-1},
 location = {Dublin, Ireland},
 pages = {30:1--30:2},
 articleno = {30},
 numpages = {2},
 doi = {10.4108/ICST.MOBIQUITOUS2008.4095},
 acmid = {1595017},
 publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
 address = {ICST, Brussels, Belgium, Belgium},
 keywords = {3D sensor input, media sharing, mobile phones, resource leasing, ubiquitous computing},
 abstract = {This paper documents the demonstration showcasing the ScreenSpot resource discovery framework and the Mobile-Vue social media sharing application. The key points of the demonstration include: requesting multidimensional resource availability information from a smart space and visualizing this information to the user on a personal device, leasing the selected resource for a distributed application launch and utilizing the leased resource to deploy an application for personal media viewing, manipulating and sharing. This application then allows users a 3D sensor-based interaction between their mobile phone and a large public display.}
}
@phdthesis{Lee:2003:DDU:979055,
 author = {Lee, Kwang Bok},
 title = {The design and development of user interfaces for small screen computers},
 year = {2003},
 note = {AAI3098862},
 publisher = {Rensselaer Polytechnic Institute},
 address = {Troy, NY, USA},
 abstract = {The increasing availability of small size computers, such as Personal Digital Assistants (PDAs), Palm pilots or handheld devices, with the ability to transmit information over wireless networks has enormously enhanced opportunities for researchers. However, these devices have difficulty displaying information because of their hardware constraints, such as small screens, small storage, low speed, and low power. This thesis introduces two methods for solving these problems. First, providing zoomable user interfaces (ZUI) introduces many zooming applications such as a file zoom, a focus zoom, and a search zoom which are based on geometric and semantic zooming methods. The file zooming applications use dynamic zoom-in and zoom-out functions for visualizing large amounts of information on the PDA screen. The focus zooming applications are based on a magnifying glass lens that is a 2D visualization for large rectangular presentations that allows a user to quickly focus on a part of the PDA screen. Finally, the thesis describes the search zooming applications for easy recognition and comparison of the content of files on the screen.  With the proliferation of PDAs, people are using such small devices to access the web; however, the web is not accommodating such access. For small device users, we introduce adaptive user interfaces (AUI) based on an efficient method for extracting readable documents from XML-based files, which will be used for information streams for mobile Internet access. We design a selector for handling information streams to extract the customized information based on the user request for the small devices. The selector's attributes can be adapted from the XML documents, and then works on translating information streams into the new file that will be displayed on the devices. Also, the selector has visual menu interfaces so that users can easily choose each attribute according to their preferences. This is developed to devise an efficient method for the small devices' problems.  Furthermore, we prepare usability testing for the applications in order to find usability problems, and then we offer suggestions for improving the usability of the applications. The prototypes and implementations of these approaches will be also provided in this thesis}
}
 @article{Burigat:2008:NTS:1322575.1322754,
 author = {Burigat, Stefano and Chittaro, Luca and Gabrielli, Silvia},
 title = {Navigation techniques for small-screen devices: An evaluation on maps and web pages},
 journal = {Int. J. Hum.-Comput. Stud.},
 issue_date = {February, 2008},
 volume = {66},
 number = {2},
 month = feb,
 year = {2008},
 issn = {1071-5819},
 pages = {78--97},
 numpages = {20},
 doi = {10.1016/j.ijhcs.2007.08.006},
 acmid = {1322754},
 publisher = {Academic Press, Inc.},
 address = {Duluth, MN, USA},
 keywords = {Mobile interaction, Navigation techniques, Small-screen devices, User study},
 abstract = {Several techniques have been proposed to support user navigation of large information spaces (e.g., maps or web pages) on small-screen devices such as PDAs and Smartphones. In this paper, we present the results of an evaluation that compared three of these techniques to determine how they might affect performance and satisfaction of users. Two of the techniques are quite common on mobile devices: the first one (DoubleScrollbar) is the standard combination of two scrollbars for separate horizontal and vertical scrolling with zoom buttons to change the scale of the information space, the second one (Grab&Drag) enables users to navigate the information space by directly dragging its currently displayed portion, while zooming is handled through a slider control. The last technique (Zoom-Enhanced Navigator or ZEN) is an extension and adaptation to mobile screens of Overview&Detail approaches, which are based on displaying an overview of the information space together with a detail view of a portion of that space. In these approaches, navigation is usually supported by (i) highlighting in the overview which portion of space is displayed in the detail view, and (ii) allowing users to move the highlight within the overview area to change the corresponding portion of space in the detail area. Our experimental evaluation concerned tasks involving maps as well as web page navigation. The paper analyzes in detail the obtained results in terms of task completion times, number and duration of user interface actions, accuracy of the gained spatial knowledge, and subjective preferences.}
}
@inproceedings{vanTonder:2008:UAI:1456659.1456689,
 author = {van Tonder, Bradley and Wesson, Janet},
 title = {Using adaptive interfaces to improve mobile map-based visualisation},
 booktitle = {Proceedings of the 2008 annual research conference of the South African Institute of Computer Scientists and Information Technologists on IT research in developing countries: riding the wave of technology},
 series = {SAICSIT '08},
 year = {2008},
 isbn = {978-1-60558-286-3},
 location = {Wilderness, South Africa},
 pages = {257--266},
 numpages = {10},
 doi = {10.1145/1456659.1456689},
 acmid = {1456689},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {adaptive user interfaces, map-based visualisation, mobile visualisation},
 abstract = {Visualising map-based data on mobile devices presents many challenges. Small displays, comparatively slow hardware and awkward interaction techniques all combine to make mobile map-based visualisations difficult to design and often frustrating to use. Existing mobile visualisation techniques do not adequately address these problems. Adaptive user interfaces, which adapt to the individual characteristics of the user, are proposed as an alternative approach to improve mobile map-based visualisation (MMV) systems. A model is presented which incorporates an adaptive user interface into the design of MMV systems. A prototype MMV system, called MediaMaps, is then described, demonstrating the successful implementation of this model. The results of an evaluation of MediaMaps are then presented, showing its effectiveness in supporting user needs and requirements for MMV using an adaptive user interface.}
}
@inproceedings{Karkkainen:2002:DSD:572020.572052,
 author = {K\"{a}rkk\"{a}inen, Lari and Laarni, Jari},
 title = {Designing for small display screens},
 booktitle = {Proceedings of the second Nordic conference on Human-computer interaction},
 series = {NordiCHI '02},
 year = {2002},
 isbn = {1-58113-616-1},
 location = {Aarhus, Denmark},
 pages = {227--230},
 numpages = {4},
 doi = {10.1145/572020.572052},
 acmid = {572052},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {guidelines, personal digital assistant, world wide web},
 abstract = {Wireless access to the Internet via PDAs (personal digital assistants) provides Web type services in the mobile world. What we are lacking are design guidelines for such PDA services. For Web publishing, however, there are many resources to look for guidelines. The guidelines can be classified according to which aspect of the Web media they are related: software/hardware, content and its organization, or aesthetics and layout. In order to be applicable to PDA services, these guidelines have to be modified. In this paper we analyze the main characteristics of PDAs and their influence to the guidelines.}
}
 @inproceedings{Cronholm:2008:YNG:1517744.1517779,
 author = {Cronholm, Stefan and Bruno, Vince},
 title = {Do you need general principles or concrete heuristics?: a model for categorizing usability criteria},
 booktitle = {Proceedings of the 20th Australasian Conference on Computer-Human Interaction: Designing for Habitus and Habitat},
 series = {OZCHI '08},
 year = {2008},
 isbn = {0-9803063-4-5},
 location = {Cairns, Australia},
 pages = {105--111},
 numpages = {7},
 doi = {10.1145/1517744.1517779},
 acmid = {1517779},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {principles for design, usability criteria, usability guidelines},
 abstract = {This paper analyses the character of usability criteria found in lists, which are used for interface design and evaluation. In order to understand usability criteria and relations between different criteria, a categorization of six usability criteria lists has been performed. The analysis has shown that the formulations of criteria reside on different abstraction levels. The results consist of two knowledge contribution. The first contribution is a hierarchical categorization model. The role of this multilevel abstraction hierarchy is to support practical problem solving processes by enabling and supporting the explicit articulation of criteria for a given context. The second contribution is a categorization of usability criteria. The aim of this categorization is to support the understanding of how different usability criteria relate (e.g. overlap or complement) to each other and highlight possible gaps.}
}

 @article{Datta:2008:IRI:1348246.1348248,
 author = {Datta, Ritendra and Joshi, Dhiraj and Li, Jia and Wang, James Z.},
 title = {Image retrieval: Ideas, influences, and trends of the new age},
 journal = {ACM Comput. Surv.},
 issue_date = {April 2008},
 volume = {40},
 number = {2},
 month = may,
 year = {2008},
 issn = {0360-0300},
 pages = {5:1--5:60},
 articleno = {5},
 numpages = {60},
 doi = {10.1145/1348246.1348248},
 acmid = {1348248},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Content-based image retrieval, annotation, learning, modeling, tagging},
 abstract = {We have witnessed great interest and a wealth of promise in content-based image retrieval as an emerging technology. While the last decade laid foundation to such promise, it also paved the way for a large number of new techniques and systems, got many new people involved, and triggered stronger association of weakly related fields. In this article, we survey almost 300 key theoretical and empirical contributions in the current decade related to image retrieval and automatic image annotation, and in the process discuss the spawning of related subfields. We also discuss significant challenges involved in the adaptation of existing image retrieval techniques to build systems that can be useful in the real world. In retrospect of what has been achieved so far, we also conjecture what the future may hold for image retrieval research.}
}

@inproceedings{Baratto:2005:TVD:1095810.1095837,
 author = {Baratto, Ricardo A. and Kim, Leonard N. and Nieh, Jason},
 title = {THINC: a virtual display architecture for thin-client computing},
 booktitle = {Proceedings of the twentieth ACM symposium on Operating systems principles},
 series = {SOSP '05},
 year = {2005},
 isbn = {1-59593-079-5},
 location = {Brighton, United Kingdom},
 pages = {277--290},
 numpages = {14},
 doi = {10.1145/1095810.1095837},
 acmid = {1095837},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {mobility, remote display, thin-client computing, virtualization},
 abstract = {Rapid improvements in network bandwidth, cost, and ubiquity combined with the security hazards and high total cost of ownership of personal computers have created a growing market for thin-client computing. We introduce THINC, a virtual display architecture for high-performance thin-client computing in both LAN and WAN environments. THINC virtualizes the display at the device driver interface to transparently intercept application display commands and translate them into a few simple low-level commands that can be easily supported by widely used client hardware. THINC's translation mechanism efficiently leverages display semantic information through novel optimizations such as offscreen drawing awareness, native video support, and server-side screen scaling. This is integrated with an update delivery architecture that uses shortest command first scheduling and non-blocking operation. THINC leverages existing display system functionality and works seamlessly with unmodified applications, window systems, and operating systems.We have implemented THINC in an X/Linux environment and compared its performance against widely used commercial approaches, including Citrix MetaFrame, Microsoft RDP, GoToMyPC, X, NX, VNC, and Sun Ray. Our experimental results on web and audio/video applications demonstrate that THINC can provide up to 4.8 times faster web browsing performance and two orders of magnitude better audio/video performance. THINC is the only thin client capable of transparently playing full-screen video and audio at full frame rate in both LAN and WAN environments. Our results also show for the first time that thin clients can even provide good performance using remote clients located in other countries around the world.}
}

@inproceedings{Nacenta:2006:PCP:1124772.1124817,
 author = {Nacenta, Miguel A. and Sallam, Samer and Champoux, Bernard and Subramanian, Sriram and Gutwin, Carl},
 title = {Perspective cursor: perspective-based interaction for multi-display environments},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '06},
 year = {2006},
 isbn = {1-59593-372-7},
 location = {Montr\&\#233;al, Qu\&\#233;bec, Canada},
 pages = {289--298},
 numpages = {10},
 doi = {10.1145/1124772.1124817},
 acmid = {1124817},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {direct-manipulation interfaces, laser pointing, multi-display interaction techniques, multi-monitor environments},
 abstract = {Multi-display environments and smart meeting rooms are now becoming more common. These environments build a shared display space from variety of devices: tablets, projected surfaces, tabletops, and traditional monitors. Since the different display surfaces are usually not organized in a single plane, traditional schemes for stitching the displays together can cause problems for interaction. However, there is a more natural way to compose display space -- using perspective. In this paper, we develop interaction techniques for multi-display environments that are based on the user's perspective on the room. We designed the Perspective Cursor, a mapping of cursor to display space that appears natural and logical from wherever the user is located. We conducted an experiment to compare two perspective-based techniques, the Perspective Cursor and a beam-based technique, with traditional stitched displays. We found that both perspective techniques were significantly faster for targeting tasks than the traditional technique, and that Perspective Cursor was the most preferred method. Our results show that integrating perspective into the design of multi-display environments can substantially improve performance.}
}

@inproceedings{Findlater:2008:ISS:1357054.1357249,
 author = {Findlater, Leah and McGrenere, Joanna},
 title = {Impact of screen size on performance, awareness, and user satisfaction with adaptive graphical user interfaces},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '08},
 year = {2008},
 isbn = {978-1-60558-011-1},
 location = {Florence, Italy},
 pages = {1247--1256},
 numpages = {10},
 doi = {10.1145/1357054.1357249},
 acmid = {1357249},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {adaptive interfaces, interaction techniques, menu design, personalization, small screen devices, user study},
 abstract = {Adaptive personalization, where the system adapts the interface to a user's needs, has the potential for significant performance benefits on small screen devices. However, research on adaptive interfaces has almost exclusively focused on desktop displays. To explore how well previous findings generalize to small screen devices, we conducted a study with 36 subjects to compare adaptive interfaces for small and desktop-sized screens. Results show that high accuracy adaptive menus have an even larger positive impact on performance and satisfaction when screen real estate is constrained. The drawback of the high accuracy menus, however, is that they reduce the user's awareness of the full set of items in the interface, potentially making it more difficult for users to learn about new features.}
}

@article{Kuhn:1998:SDS:624624.625838,
 author = {Kuhn, Sarah},
 title = {The Software Design Studio: An Exploration},
 journal = {IEEE Softw.},
 issue_date = {March 1998},
 volume = {15},
 number = {2},
 month = mar,
 year = {1998},
 issn = {0740-7459},
 pages = {65--71},
 numpages = {7},
 doi = {10.1109/52.663788},
 acmid = {625838},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
 abstract = {Some software designers have recently turned to building architecture for inspiration in their efforts to improve professional practice. An attempt to apply the studio method of architectural training to software design education, reported in this article, reveals much about education and practice in both professions. Studio courses provoke creative reflection on how to improve current training practices and could provide a new way to develop software design expertise.}
}

@article{Piattini:1997:ALM:263244.263268,
 author = {Piattini, Mario G. and Tigr{\'e}at, Herv{\'e}},
 title = {Applying the \“STUDIO\” method to the interface design of an environmental software system},
 journal = {SIGSOFT Softw. Eng. Notes},
 issue_date = {July 1997},
 volume = {22},
 number = {4},
 month = jul,
 year = {1997},
 issn = {0163-5948},
 pages = {81--83},
 numpages = {3},
 doi = {10.1145/263244.263268},
 acmid = {263268},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {STUDIO, design method, interface-design},
 abstract = {This paper addresses the application of the STUDIO (STructured User-interface Design for Interaction Optimization) method to the user-interface development of an information system (called "HIMPPA") that allows the simulation of heavy-particle dispersion. This method has been proposed in 1994 by D.P. Browne. We have adapted and integrated it with an object-oriented design technique for the HIMPPA project (an ESPRIT-PASO Special Action).}
}

@article{Hazzan:2002:RPP:771439.771440,
 author = {Hazzan, Orit},
 title = {The reflective practitioner perspective in software engineering education},
 journal = {J. Syst. Softw.},
 issue_date = {15 September 2002},
 volume = {63},
 number = {3},
 month = sep,
 year = {2002},
 issn = {0164-1212},
 pages = {161--171},
 numpages = {11},
 doi = {10.1016/S0164-1212(02)00012-2},
 acmid = {771440},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
 abstract = {This paper focuses on the application of the reflective practitioner (RP) perspective to the profession of software engineering (SE). The RP perspective guides professional people to rethink their professional creations during and after the accomplishment of the creation process. Analysis of the field of SE supports the adoption of the RP perspective to SE in general and to SE education in particular. The RP perspective emphasizes the studio--the basic training method in architecture schools--as the educational environment for design studies. In such studios students develop projects with a close guidance of a tutor. Analysis of the kind of tasks that architecture students are working on and a comparison of these tasks to the problems that SE students are facing, suggest that the studio may be an appropriate teaching method in SE as well. The paper presents the main ideas of the RP perspective and examines its fitness to SE in general and to SE education in particular. The discussion is based on analysis of the RP perspective and of the SE profession, visits to architecture studios, and conversations with tutors in architecture studios and with computing science practitioners.}
}
@inproceedings{Yamazaki:2007:DTU:1772490.1772524,
 author = {Yamazaki, Kazuhiko and Furuta, Kazuo},
 title = {Design tools for user experience design},
 booktitle = {Proceedings of the 12th international conference on Human-computer interaction: interaction design and usability},
 series = {HCI'07},
 year = {2007},
 isbn = {978-3-540-73104-7},
 location = {Beijing, China},
 pages = {298--307},
 numpages = {10},
 acmid = {1772524},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 abstract = {The purpose of this study is to develop an approach to artifacts design based on information technology. To make interactive system easy to use, user centered design approach is utilized by many systems. For user centered design, it is important to consider total user experience. But it is not easy to consider total user experience because user experience is including many aspects. To approach total user experience, the author proposes the method of designing for user experience that consist of "User viewpoint", "Environment viewpoint" and "Lifecycle viewpoint". "User viewpoint" is including several user groups from universal design viewpoint, several user characters and several user emotions. "Environment viewpoint" is including hardware product, software, application, space, people who is communicating. "Lifecycle viewpoint" is including pre sales, after sales, support, upgrade, setup product and application.  To help this design approach, user experience design tool named "UED (User Experience Design) Studio" was proposed. Based on proposed three approaches, design tools were developed such as "The definition tool", "The evaluation tool" and "The visualization tool" for user experience design. To define user experience situation easily, "The definition tool" helps designer such selecting user group, selecting environment and input user tasks based on life cycle state. "The evaluation tool" is to evaluate defined user experience easily. And "The visualization tool" is to show the result of evaluation by 3 D graphics easy to understand complicated information.  To evaluate proposed tools, experiment to make prototype was conducted and the results indicate that the proposed approach has possibility to help designer and multi-disciplinary team to consider user experience for user centered design.}
}

@article{Bobick:1999:KPI:1246829.1246830,
 author = {Bobick, Aaron F. and Intille, Stephen S. and Davis, James W. and Baird, Freedom and Pinhanez, Claudio S. and Campbell, Lee W. and Ivanov, Yuri A. and Sch\"{u}tte, Arjan and Wilson, Andrew},
 title = {The KidsRoom: A Perceptually-Based Interactive and Immersive Story Environment},
 journal = {Presence: Teleoper. Virtual Environ.},
 issue_date = {August 1999},
 volume = {8},
 number = {4},
 month = aug,
 year = {1999},
 issn = {1054-7460},
 pages = {369--393},
 numpages = {25},
 doi = {10.1162/105474699566297},
 acmid = {1246830},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA}, 
 abstract = {The KidsRoom is a perceptually-based, interactive, narrative playspace for children. Images, music, narration, light, and sound effects are used to transform a normal child's bedroom into a fantasy land where children are guided through a reactive adventure story. The fully automated system was designed with the following goals: (1) to keep the focus of user action and interaction in the physical and not virtual space; (2) to permit multiple, collaborating people to simultaneously engage in an interactive experience combining both real and virtual objects; (3) to use computer-vision algorithms to identify activity in the space without requiring the participants to wear any special clothing or devices; (4) to use narrative to constrain the perceptual recognition, and to use perceptual recognition to allow participants to drive the narrative; and (5) to create a truly immersive and interactive room environment.  We believe the KidsRoom is the first multi-person, fully-automated, interactive, narrative environment ever constructed using non-encumbering sensors. This paper describes the KidsRoom, the technology that makes it work, and the issues that were raised during the system's development.<xref ref-type="fn" rid="fn1">1</xref>  A demonstration of the project, which complements the material presented here and includes videos, images, and sounds from each part of the story is available at somewhere.}
}

@inproceedings{Yatani:2005:TII:1056808.1057046,
 author = {Yatani, Koji and Tamura, Koiti and Hiroki, Keiichi and Sugimoto, Masanori and Hashizume, Hiromichi},
 title = {Toss-it: intuitive information transfer techniques for mobile devices},
 booktitle = {CHI '05 Extended Abstracts on Human Factors in Computing Systems},
 series = {CHI EA '05},
 year = {2005},
 isbn = {1-59593-002-7},
 location = {Portland, OR, USA},
 pages = {1881--1884},
 numpages = {4},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1056808.1057046},
 doi = {10.1145/1056808.1057046},
 acmid = {1057046},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {gesture recognition, information transfer, location recognition, mobile devices},
 abstract = {In recent years, mobile devices have rapidly penetrated into our daily lives. However, several drawbacks of mobile devices have been mentioned so far. The proposed system called Toss-It provides intuitive information transfer techniques for mobile devices, by fully utilizing their mobility. A user of Toss-It can send information from the user's PDA to other electronic devices with a toss or swing action, as the user would toss a ball or deal cards to others. This paper describes the current implementation of Toss-It and its user studies.}
} 
@article{Woods:1984:VMC:2292.2296,
 author = {Woods, David D.},
 title = {Visual momentum:  a concept to improve the cognitive coupling of person and computer},
 journal = {Int. J. Man-Mach. Stud.},
 issue_date = {Sept. 1984},
 volume = {21},
 number = {3},
 month = sep,
 year = {1984},
 issn = {0020-7373},
 pages = {229--244},
 numpages = {16},
 url = {http://dx.doi.org.prox.lib.ncsu.edu/10.1016/S0020-7373(84)80043-7},
 doi = {10.1016/S0020-7373(84)80043-7},
 acmid = {2296},
 publisher = {Academic Press Ltd.},
 address = {London, UK, UK},
 abstract = {Computer display system users must integrate data across successive displays. This problem of across-display processing is analogous to the question of how the visual system combines data across successive glances (fixations). Research from cognitive psychology on the latter question is used in order to formulate guidelines for the display designer. The result is a new principle of person-computer interaction, visual momentum, which captures knowledge about the mechanisms that support the identification of “relevant” data in human perception so that display system design can support an effective distribution of user attention. The negative consequences of low visual momentum on user performance are described, and display design techniques are presented to improve user across-display information extraction.}
} 
@article{Whittaker:2001:CVM:376929.376932,
 author = {Whittaker, Steve and Hirschberg, Julia},
 title = {The character, value, and management of personal paper archives},
 journal = {ACM Trans. Comput.-Hum. Interact.},
 issue_date = {June 2001},
 volume = {8},
 number = {2},
 month = jun,
 year = {2001},
 issn = {1073-0516},
 pages = {150--170},
 numpages = {21},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/376929.376932},
 doi = {10.1145/376929.376932},
 acmid = {376932},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {archiving, document management, filing, information retrieval, paper, personal information management},
 abstract = {We explored general issues concerning personal information management by investigating the characteristics of office workers' paper-based information, in an industrial research environment. we examined the reasons people collect paper, types of data they collect, problems encountered in handling paper, and strategies used for processing it. We tested three specific hypotheses in the course of an office move. The greater availability of public digital data along with changes in people's jobs or interests should lead to wholescale discarding of paper data, while preparing for the move. Instead we found workers kept large, highly valued papar archives. We also expected that the major part of people's personal archives would be unique documents. However, only 49% of people's archives were unique documents, the remainder being copies of publicly available data and unread information, and we explore reasons for this. We examined the effects of paper-processing strategies on archive structure. We discovered different paper-processing strategies (filing and piling)that were relatively independent of job type. We predicated that filers' attempted to evaluate and catergorize incoming documents would produce smaller archives that were accessed frequently. Contrary to our predictions, filers amassed more information, and accessed it less frequently than pilers. We argue that filers may engage in premature filing: to clear their workspace, they archives information that later turns out to be of low value. Given the effort involved in organzing data, they are also loath to discard filed information, even when its value is uncertain. We discuss the implications of this research for digital personal information management.}
} 
@inproceedings{Thorne:2004:MDI:1186562.1015740,
 author = {Thorne, Matthew and Burke, David and van de Panne, Michiel},
 title = {Motion doodles: an interface for sketching character motion},
 booktitle = {ACM SIGGRAPH 2004 Papers},
 series = {SIGGRAPH '04},
 year = {2004},
 location = {Los Angeles, California},
 pages = {424--431},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1186562.1015740},
 doi = {10.1145/1186562.1015740},
 acmid = {1015740},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Animation, Computer Puppetry, Gestural Interfaces, Sketching},
 abstract = {In this paper we present a novel system for sketching the motion of a character. The process begins by sketching a character to be animated. An animated motion is then created for the character by drawing a continuous sequence of lines, arcs, and loops. These are parsed and mapped to a parameterized set of output motions that further reflect the location and timing of the input sketch. The current system supports a repertoire of 18 different types of motions in 2D and a subset of these in 3D. The system is unique in its use of a cursive motion specification, its ability to allow for fast experimentation, and its ease of use for non-experts.}
} 
@inproceedings{Streitz:1999:IIL:302979.303010,
 author = {Streitz, Norbert A. and Gei\ssler, J\"{o}rg and Holmer, Torsten and Konomi, Shin'ichi and M\"{u}ller-Tomfelde, Christian and Reischl, Wolfgang and Rexroth, Petra and Seitz, Peter and Steinmetz, Ralf},
 title = {i-LAND: an interactive landscape for creativity and innovation},
 booktitle = {Proceedings of the SIGCHI conference on Human Factors in Computing Systems},
 series = {CHI '99},
 year = {1999},
 isbn = {0-201-48559-1},
 location = {Pittsburgh, Pennsylvania, USA},
 pages = {120--127},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/302979.303010},
 doi = {10.1145/302979.303010},
 acmid = {303010},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CSCW, architectural space, augmented reality, cooperative rooms, creativity support, dynmic team work, integrated design, interactive landscape, roomware, ubiquitous computing, virtual information space, workspaces of the future},
 abstract = {We describe the i-LAND environment which constitutes an example of our vision of the workspaces of the future, in this case supporting cooperative work of dynamic teams with changing needs. i-LAND requires and provides new forms of human-computer interaction and new forms of computer-supported cooperative work. Its design is based on an integration of information and architectural spaces, implications of new work practices and an empirical requirements study informing our design. i-LAND consists of several roomware components, i.e. computer-aug- mented objects integrating room elements with information technology. We present the current realization of i-LAND in terms of an interactive electronic wall, an interactive table, two computer-enhanced chairs, and two bridges for the Passage-mechanism. This is complemented by the description of the creativity support application and the technological infrastructure. The paper is accompanied by a video figure in the CHI99 video program.}
} 
@inproceedings{Sonnet:2004:IEA:989863.989871,
 author = {Sonnet, Henry and Carpendale, Sheelagh and Strothotte, Thomas},
 title = {Integrating expanding annotations with a 3D explosion probe},
 booktitle = {Proceedings of the working conference on Advanced visual interfaces},
 series = {AVI '04},
 year = {2004},
 isbn = {1-58113-867-9},
 location = {Gallipoli, Italy},
 pages = {63--70},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/989863.989871},
 doi = {10.1145/989863.989871},
 acmid = {989871},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3D model exploration, expanding annotations, explosion diagram, interaction design},
 abstract = {Understanding complex 3D virtual models can be difficult, especially when the model has interior components not initially visible and ancillary text. We describe new techniques for the interactive exploration of 3D models. Specifically, in addition to traditional viewing operations, we present new text extrusion techniques combined with techniques that create an interactive explosion diagram. In our approach, scrollable text annotations that are associated with the various parts of the model can be revealed dynamically, either in part or in full, by moving the mouse cursor within annotation trigger areas. Strong visual connections between model parts and the associated text are included in order to aid comprehension. Furthermore, the model parts can be separated, creating interactive explosion diagrams. Using a 3D probe, occluding objects can be interactively moved apart and then returned to their initial locations. Displayed annotations are kept readable despite model manipulations. Hence, our techniques provide textual context within the spatial context of the 3D model.}
} 
@book{Sellen:2003:MPO:778158,
 author = {Sellen, Abigail J. and Harper, Richard H.R.},
 title = {The Myth of the Paperless Office},
 year = {2003},
 isbn = {026269283X},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 
@inproceedings{Robertson:1991:CTA:108844.108883,
 author = {Robertson, George G. and Mackinlay, Jock D. and Card, Stuart K.},
 title = {Cone Trees: animated 3D visualizations of hierarchical information},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '91},
 year = {1991},
 isbn = {0-89791-383-3},
 location = {New Orleans, Louisiana, USA},
 pages = {189--194},
 numpages = {6},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/108844.108883},
 doi = {10.1145/108844.108883},
 acmid = {108883},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract = {The task of managing and accessing large information spaces is a problem in large scale cognition.  Emerging technologies for 3D visualization and interactive animation offer potential solutions to this problem, especially when the structure of the information can be visualized.  We describe one of tehse Information Visualization techniques, called the Cone Tree, which is used for visualizing hierarchical information structures.  The hierarchy is preseneted in 3D to meximize effective use of available screen space and enable visualization of the whole structure.  Interactive animation is used to shift some of the user's cognitive load to the human perceptual system.}
} 
@inproceedings{Robertson:2000:TGW:332040.332482,
 author = {Robertson, George and van Dantzich, Maarten and Robbins, Daniel and Czerwinski, Mary and Hinckley, Ken and Risden, Kirsten and Thiel, David and Gorokhovsky, Vadim},
 title = {The Task Gallery: a 3D window manager},
 booktitle = {Proceedings of the SIGCHI conference on Human Factors in Computing Systems},
 series = {CHI '00},
 year = {2000},
 isbn = {1-58113-216-6},
 location = {The Hague, The Netherlands},
 pages = {494--501},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/332040.332482},
 doi = {10.1145/332040.332482},
 acmid = {332482},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3D user interfaces, spatial cognition, spatial memory, window managers},
 abstract = {The Task Gallery is a window manager that uses interactive 3D graphics to provide direct support for task management and document comparison, lacking from many systems implementing the desktop metaphor. User tasks appear as artwork hung on the walls of a virtual art gallery, with the selected task on a stage. Multiple documents can be selected and displayed side-by-side using 3D space to provide uniform and intuitive scaling. The Task Gallery hosts any Windows application, using a novel redirection mechanism that routes input and output between the 3D environment and unmodified 2D Windows applications. User studies suggest that the Task Gallery helps with task management, is enjoyable to use, and that the 3D metaphor evokes spatial memory and cognition.}
} 
@inproceedings{Robertson:1998:DMU:288392.288596,
 author = {Robertson, George and Czerwinski, Mary and Larson, Kevin and Robbins, Daniel C. and Thiel, David and van Dantzich, Maarten},
 title = {Data mountain: using spatial memory for document management},
 booktitle = {Proceedings of the 11th annual ACM symposium on User interface software and technology},
 series = {UIST '98},
 year = {1998},
 isbn = {1-58113-034-1},
 location = {San Francisco, California, USA},
 pages = {153--162},
 numpages = {10},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/288392.288596},
 doi = {10.1145/288392.288596},
 acmid = {288596},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3D user interfaces, desktop VR, document mangement, information visualization, spatial cognition, spatial memory},
 abstract = {Effective management of documents on computers has been a central user interface problem for many years.  One common approach involves using 2D spatial layouts of icons representing the documents, particularly for information workspace tasks. This approach takes advantage of human 2D spatial cognition. More recently, several 3D spatial layouts have engaged 3D spatial cognition capabilities. Some have attempted to use spatial memory in 3D virtual environments. However, there has been no proof to date that spatial memory works the same way in 3D virtual environments as it does in the real world. We describe a new technique for document management called the Data Mountain, which allows users to place documents at arbitrary positions on an inclined plane in a 3D desktop virtual environment using a simple 2D interaction technique. We discuss how the design evolved in response to user feedback. We also describe a user study that shows that the Data Mountain does take advantage of spatial memory. Our study shows that the Data Mountain has statistically reliable advantages over the Microsoft Internet Explorer Favorites mechanism for managing documents of interest in an information workspace.}
} 
@inproceedings{Ramos:2004:PW:985692.985754,
 author = {Ramos, Gonzalo and Boulos, Matthew and Balakrishnan, Ravin},
 title = {Pressure widgets},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '04},
 year = {2004},
 isbn = {1-58113-702-8},
 location = {Vienna, Austria},
 pages = {487--494},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/985692.985754},
 doi = {10.1145/985692.985754},
 acmid = {985754},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {isometric input, pen-based interfaces, pressure input, pressure widgets},
 abstract = {Current user interface widgets typically assume that the input device can only provide x-y position and binary button press information. Other inputs such as the continuous pressure data provided by styluses on tablets are rarely used. We explore the design space of using the continuous pressure sensing capabilities of styluses to operate multi-state widgets. We present the results of a controlled experiment that investigates human ability to perform discrete target selection tasks by varying a stylus' pressure, with full or partial visual feedback. The experiment also considers different techniques for confirming selection once the target is acquired. Based on the experimental results, we discuss implications for the design of pressure sensitive widgets. A taxonomy of pressure widgets is presented, along with a set of initial concept sketches of various pressure widget designs.}
} 
@inproceedings{Pook:2000:CME:633292.633446,
 author = {Pook, Stuart and Lecolinet, Eric and Vaysseix, Guy and Barillot, Emmanuel},
 title = {Control menus: excecution and control in a single interactor},
 booktitle = {CHI '00 Extended Abstracts on Human Factors in Computing Systems},
 series = {CHI EA '00},
 year = {2000},
 isbn = {1-58113-248-4},
 location = {The Hague, The Netherlands},
 pages = {263--264},
 numpages = {2},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/633292.633446},
 doi = {10.1145/633292.633446},
 acmid = {633446},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {gestures, interaction, interactors, marking menus, menu access, user interface design, zoomable user interfaces},
 abstract = {We propose a new type of contextual pop-up menu called a control menu. These menus combine the selection of an operation and the control of this operation. They integrate up to two scroll bars or spin-boxes and thus allow users to keep their attention focused on the menu during the operation. Control menus can have sub-menus, and also retain the novice and expert modes of use found in marking menus. We describe control menus and how they are useful in different types of user interfaces. A program incorporating our control menus can be tested at http://www.infobiogen.fr/services/zomit/.}
} 
@inproceedings{Miller:2005:CSC:1121987.1122115,
 author = {Miller, Lynn},
 title = {Case Study of Customer Input For a Successful Product},
 booktitle = {Proceedings of the Agile Development Conference},
 series = {ADC '05},
 year = {2005},
 isbn = {0-7695-2487-7},
 pages = {225--234},
 numpages = {10},
 url = {http://dx.doi.org.prox.lib.ncsu.edu/10.1109/ADC.2005.16},
 doi = {10.1109/ADC.2005.16},
 acmid = {1122115},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 abstract = {Both agile development and User Centered Design stress collaboration between customers and product teams, but getting these methodologies to work well together is not easy. This paper describes one company's efforts to merge these processes by creating interconnected parallel design and development tracks. The benefits of this approach are demonstrated by showing how, when and why customer input was incorporated during the release of a successful software product.}
} 
@inproceedings{Mander:1992:LMS:142750.143055,
 author = {Mander, Richard and Salomon, Gitta and Wong, Yin Yin},
 title = {A \“pile\” metaphor for supporting casual organization of information},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '92},
 year = {1992},
 isbn = {0-89791-513-5},
 location = {Monterey, California, USA},
 pages = {627--634},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/142750.143055},
 doi = {10.1145/142750.143055},
 acmid = {143055},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {design process, desktop metaphor, end-user programming, information organization, information visualization, interactive systems, interface design, interface metaphors, pile metaphor, user observation},
 abstract = {A user study was conducted to investigate how people deal with the flow of information in their workspaces. Subjects reported that, in an attempt to quickly and informally manage their information, they created piles of documents. Piles were seen as complementary to the folder filing system, which was used for more formal archiving. A new desktop interface element–the pile– was developed and prototyped through an iterative process. The design includes direct manipulation techniques and support for browsing, and goes beyond physical world functionality by providing system assistance for automatic pile construction and reorganization. Preliminary user tests indicate the design is promising and raise issues that will be addressed in future work.}
} 
@article{Malone:1983:POD:357423.357430,
 author = {Malone, Thomas W.},
 title = {How do people organize their desks?: Implications for the design of office information systems},
 journal = {ACM Trans. Inf. Syst.},
 issue_date = {Jan. 1983},
 volume = {1},
 number = {1},
 month = jan,
 year = {1983},
 issn = {1046-8188},
 pages = {99--112},
 numpages = {14},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/357423.357430},
 doi = {10.1145/357423.357430},
 acmid = {357430},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract = {This paper describes a series of interviews focusing on the way professional and clerical office workers organize the information in their desks and offices. A number of implications for designing &quot;natural&quot; and convenient computer-based information systems are discussed. Two principal claims are made: (1) A very important function of desk organization is to remind the user of things to do, not just to help the user find desired information. Failing to support this function may seriously impair the usefulness of electronic office systems, and explicitly facilitating it may provide an important advantage for automated office systems over their nonautomated predecessors. (2) The cognitive difficulty of categorizing information is an important factor in explaining how people organize their desks. Computer-based systems may help with this difficulty by (a) doing as much automatic classification as possible (e.g., based on access dates}, and (b) including untitled &quot;piles &quot; of information arranged by physical location as well as explicitly titled and logically arranged &quot;files.&quot; Several other implications for the design of electronic office systems are discussed, and some differences in how people organize their desks are described. Categories and Subject Descriptors: H.1.2 [Models and Principles]: User/Machine Systems--}
} 
@inproceedings{Kurtenbach:1991:ICM:120782.120797,
 author = {Kurtenbach, Gordon and Buxton, William},
 title = {Issues in combining marking and direct manipulation techniques},
 booktitle = {Proceedings of the 4th annual ACM symposium on User interface software and technology},
 series = {UIST '91},
 year = {1991},
 isbn = {0-89791-451-1},
 location = {Hilton Head, South Carolina, USA},
 pages = {137--144},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/120782.120797},
 doi = {10.1145/120782.120797},
 acmid = {120797},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract = {The direct manipulation paradigm has been effective in helping designers create easy to use mouse and keyboard based interfaces. The development of flat display surfaces and transparent tablets are now making possible interfaces where a user can write directly on the screen using a special stylus. The intention of these types of interfaces is to exploit user’s existing handwriting, mark-up and drawing skills while also providing the benefits of direct manipulation. This paper reports on a test bed program which we are using for exploring hand-marking types of interactions and their integration with direct manipulation interactions. } 
} 
@inproceedings{Hinckley:2005:DAD:1054972.1055035,
 author = {Hinckley, Ken and Baudisch, Patrick and Ramos, Gonzalo and Guimbretiere, Francois},
 title = {Design and analysis of delimiters for selection-action pen gesture phrases in scriboli},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '05},
 year = {2005},
 isbn = {1-58113-998-5},
 location = {Portland, Oregon, USA},
 pages = {451--460},
 numpages = {10},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1054972.1055035},
 doi = {10.1145/1054972.1055035},
 acmid = {1055035},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {delimiters, gestures, marking, pen input, tablets},
 abstract = {We present a quantitative analysis of delimiters for pen gestures. A delimiter is "something different" in the input stream that a computer can use to determine the structure of input phrases. We study four techniques for delimiting a selection-action gesture phrase consisting of lasso selection plus marking-menu-based command activation. Pigtail is a new technique that uses a small loop to delimit lasso selection from marking (Fig. 1). Handle adds a box to the end of the lasso, from which the user makes a second stroke for marking. Timeout uses dwelling with the pen to delimit the lasso from the mark. Button uses a button press to signal when to delimit the gesture. We describe the role of delimiters in our Scriboli pen interaction testbed, and show how Pigtail supports scope selection, command activation, and direct manipulation all in a single fluid pen gesture.}
} 
@inproceedings{Herndon:1992:IS:142621.142622,
 author = {Herndon, Kenneth P. and Zeleznik, Robert C. and Robbins, Daniel C. and Conner, D. Brookshire and Snibbe, Scott S. and van Dam, Andries},
 title = {Interactive shadows},
 booktitle = {Proceedings of the 5th annual ACM symposium on User interface software and technology},
 series = {UIST '92},
 year = {1992},
 isbn = {0-89791-549-6},
 location = {Monteray, California, USA},
 pages = {1--6},
 numpages = {6},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/142621.142622},
 doi = {10.1145/142621.142622},
 acmid = {142622},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3D widgets, direct manipulation, interactive systems},
 abstract = {It is often difficult in computer graphics applications to understand spatial relationships between objects in a 3D scene or effect changes to those objects without specialized visualization and manipulation techniques. We present a set of three-dimensional tools (widgets) called “shadows” that not only provide valuable perceptual cues about the spatial relationships between objects, but also provide a direct manipulation interface to constrained transformation techniques. These shadow widgets provide two advances over previous techniques. First, they provide high correlation between their own geometric feedback and their effects on the objects they control. Second, unlike some other 3D widgets, they do not obscure the objects they control.}
} 
@inproceedings{Grossman:2001:ITM:364338.364341,
 author = {Grossman, Tovi and Balakrishnan, Ravin and Kurtenbach, Gordon and Fitzmaurice, George and Khan, Azam and Buxton, Bill},
 title = {Interaction techniques for 3D modeling on large displays},
 booktitle = {Proceedings of the 2001 symposium on Interactive 3D graphics},
 series = {I3D '01},
 year = {2001},
 isbn = {1-58113-292-1},
 pages = {17--23},
 numpages = {7},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/364338.364341},
 doi = {10.1145/364338.364341},
 acmid = {364341},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3D modeling, interaction techniques, large scale displays, tape drawing, two-handed input},
 abstract = {We present an alternate interface for 3D modeling for use on large scale displays. The interface integrates several concepts specifically selected and enhanced for large scale interaction. These include 2D construction planes spatially integrated in a 3D volume, enhanced orthographic views, smooth transitions between 2D and 3D views, tape drawing as the primary curve and line creation technique, visual viewpoint markers, and continuous twohanded interaction.}
} 
@inproceedings{Gonzalez:1996:AUI:238386.238396,
 author = {Gonzalez, Cleotilde},
 title = {Does animation in user interfaces improve decision making?},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '96},
 year = {1996},
 isbn = {0-89791-777-4},
 location = {Vancouver, British Columbia, Canada},
 pages = {27--34},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/238386.238396},
 doi = {10.1145/238386.238396},
 acmid = {238396},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {animation, decision making},
 abstract = {This paper reports a laboratory experiment that investigated the relative effects of images, transitions, and interactivity styles used in animated interfaces in two decision making domains. Interfaces used either realistic or abstract images, smooth or abrupt transitions, and parallel or sequential interactivity. Results suggest that decision making performance is influenced by the task domain, the user experience, the image, transition, and interactivity styles used in animated interfaces. Subjects performed better with animated interfaces based on realistic rather than abstract images. Subjects were more accurate with smooth rather than abrupt animation. Subjects were more accurate and enjoyed more the animation with parallel rather than sequential interactivity. Implications on the design of animated interfaces for decision making are provided.} 
 } 
@inproceedings{Forlines:2005:GNI:1056808.1056920,
 author = {Forlines, Clifton and Shen, Chia and Buxton, Bill},
 title = {Glimpse: a novel input model for multi-level devices},
 booktitle = {CHI '05 Extended Abstracts on Human Factors in Computing Systems},
 series = {CHI EA '05},
 year = {2005},
 isbn = {1-59593-002-7},
 location = {Portland, OR, USA},
 pages = {1375--1378},
 numpages = {4},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1056808.1056920},
 doi = {10.1145/1056808.1056920},
 acmid = {1056920},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {direct manipulation, navigation, pressure sensitive input, stylus, three-state input, touch screens, undo},
 abstract = {We describe a technique that supports the previewing of navigation, exploration, and editing operations by providing convenient Undo for unsuccessful and/or undesirable actions on multi-level input devices such as touch screens and pen-based computers. By adding a Glimpse state to traditional three-state pressure sensitive input devices, users are able to preview the effects of their editing without committing to them. From this Glimpse state, users can undo their action as easily as they can commit to it, making Glimpse most appropriate for systems in which the user is likely to try out many variations of an edit before finding the right one. Exploration is encouraged as the cumbersome returning to a menu or keyboard to issue an Undo command is eliminated. Glimpse has the added benefits that the negative effects of inconsistencies in the Undo feature within an application are reduced.}
} 
@inproceedings{Fitzmaurice:2003:TM:964696.964704,
 author = {Fitzmaurice, George and Khan, Azam and Piek{\'e}, Robert and Buxton, Bill and Kurtenbach, Gordon},
 title = {Tracking menus},
 booktitle = {Proceedings of the 16th annual ACM symposium on User interface software and technology},
 series = {UIST '03},
 year = {2003},
 isbn = {1-58113-636-6},
 location = {Vancouver, Canada},
 pages = {71--79},
 numpages = {9},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/964696.964704},
 doi = {10.1145/964696.964704},
 acmid = {964704},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {floating palette, graphical user interface, menu system, pen based user interfaces, tablet PC},
 abstract = {We describe a new type of graphical user interface widget, known as a "tracking menu." A tracking menu consists of a cluster of graphical buttons, and as with traditional menus, the cursor can be moved within the menu to select and interact with items. However, unlike traditional menus, when the cursor hits the edge of the menu, the menu moves to continue tracking the cursor. Thus, the menu always stays under the cursor and close at hand.In this paper we define the behavior of tracking menus, show unique affordances of the widget, present a variety of examples, and discuss design characteristics. We examine one tracking menu design in detail, reporting on usability studies and our experience integrating the technique into a commercial application for the Tablet PC. While user interface issues on the Tablet PC, such as preventing round trips to tool palettes with the pen, inspired tracking menus, the design also works well with a standard mouse and keyboard configuration.}
} 
@inproceedings{Dragicevic:2004:CCP:1029632.1029667,
 author = {Dragicevic, Pierre},
 title = {Combining crossing-based and paper-based interaction paradigms for dragging and dropping between overlapping windows},
 booktitle = {Proceedings of the 17th annual ACM symposium on User interface software and technology},
 series = {UIST '04},
 year = {2004},
 isbn = {1-58113-957-8},
 location = {Santa Fe, NM, USA},
 pages = {193--196},
 numpages = {4},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1029632.1029667},
 doi = {10.1145/1029632.1029667},
 acmid = {1029667},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {crossing-based interfaces, drag-and-drop, gestural interaction, paper-based metaphors},
 abstract = {Despite novel interaction techniques proposed for virtual desktops, common yet challenging tasks remain to be investigated. Dragging and dropping between overlapping windows is one of them. The fold-and-drop technique presented here offers a natural and efficient way of performing those tasks. We show how this technique successfully builds upon several interaction paradigms previously described, while shedding new light on them.}
} 
@inproceedings{DiGioia:2005:SNM:1073001.1073011,
 author = {DiGioia, Paul and Dourish, Paul},
 title = {Social navigation as a model for usable security},
 booktitle = {Proceedings of the 2005 symposium on Usable privacy and security},
 series = {SOUPS '05},
 year = {2005},
 isbn = {1-59593-178-3},
 location = {Pittsburgh, Pennsylvania},
 pages = {101--108},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1073001.1073011},
 doi = {10.1145/1073001.1073011},
 acmid = {1073011},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collaborative interfaces, peer-to-peer filesharing, social navigation, visualization},
 abstract = {As interest in usable security spreads, the use of visual approaches in which the functioning of a distributed system is made visually available to end users is an approach that a number of researchers have examined. In this paper, we discuss the use of the social navigation paradigm as a way of organizing visual displays of system action. Drawing on a previous study of security in the Kazaa peer to peer system, we present some examples of the ways in which social navigation can be incorporated in support of usable security.}
} 
@inproceedings{Denoue:2003:FIP:964696.964715,
 author = {Denoue, Laurent and Nelson, Les and Churchill, Elizabeth},
 title = {A fast, interactive 3D paper-flier metaphor for digital bulletin boards},
 booktitle = {Proceedings of the 16th annual ACM symposium on User interface software and technology},
 series = {UIST '03},
 year = {2003},
 isbn = {1-58113-636-6},
 location = {Vancouver, Canada},
 pages = {169--172},
 numpages = {4},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/964696.964715},
 doi = {10.1145/964696.964715},
 acmid = {964715},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {real-time animated user interfaces, 3D simulation of paper fliers, digital bulletin boards}
 abstract = {We describe a novel interface for presenting interactive content on public digital bulletin boards.  Inspired by paper fliers on physical bulletin boards, bosted content is displayed using 3D virtual fliers attached to a virtual corkboard by virtual corkboard by virtual pushpins.  Fliers appear in different orientations, creating an attractive informal look, and have autonomous behaviours like fluttering in the wind.  Passers-by can rotate, move and fold fliers; they can also interact with fliers' live content.  Flier content is streamed from a server and represented by the system on large screen displays using a real-time cloth simulation algorithm.  We describe our prototype and offer the results of an initial evaluative user study.}
} 
@inproceedings{Chang:1993:ACU:168642.168647,
 author = {Chang, Bay-Wei and Ungar, David},
 title = {Animation: from cartoons to the user interface},
 booktitle = {Proceedings of the 6th annual ACM symposium on User interface software and technology},
 series = {UIST '93},
 year = {1993},
 isbn = {0-89791-628-X},
 location = {Atlanta, Georgia, USA},
 pages = {45--55},
 numpages = {11},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/168642.168647},
 doi = {10.1145/168642.168647},
 acmid = {168647},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Self, animation, cartoons, motion blur, user interfaces},
 abstract = {User interfaces are often based on static presentations, a model ill suited for conveying change. Consequently, events on the screen frequently startle and confuse users. Cartoon animation, in contrast, is exceedingly successful at engaging its audience; even the most bizarre events are easily comprehended. The Self user interface has served as a testbed for the application of cartoon animation techniques as a means of making the interface easier to understand and more pleasant to use. Attention to timing and transient detail allows Self objects to move solidly. Use of cartoon-style motion blur allows Self objects to move quickly and still maintain their comprehensibility. Self objects arrive and depart smoothly, without sudden materializations and disappearances, and they rise to the front of overlapping objects smoothly through the use of dissolve. Anticipating motion with a small contrary motion and pacing the middle of transitions faster than the endpoints results in smoother and clearer movements. Despite the differences between user interfaces and cartoons --cartoons are frivolous, passive entertainment and user interfaces are serious, interactive tools -- cartoon animation has much to lend to user interfaces to realize both affective and cognitive benefits. *This work was originally supported by Sun Microsystems Laboratories, an NSF Graduate Fellowship, National Science Foundation Presidential Young Investigator Grant #CCR-8657631, IBM Powell Foundation, Apple Computer, Inc., Cray Laboratories, Tandem, NCR Corporation, Texas Instruments, Inc., and Digital Equipment Corporation.}
} 
@inproceedings{Carpendale:2001:FUP:502348.502358,
 author = {Carpendale, M. S. T. and Montagnese, Catherine},
 title = {A framework for unifying presentation space},
 booktitle = {Proceedings of the 14th annual ACM symposium on User interface software and technology},
 series = {UIST '01},
 year = {2001},
 isbn = {1-58113-438-X},
 location = {Orlando, Florida},
 pages = {61--70},
 numpages = {10},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/502348.502358},
 doi = {10.1145/502348.502358},
 acmid = {502358},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3D interactions, Distortion viewing, information visualization, interface design issues, interface metaphors, screen layout},
 abstract = {Making effective use of the available display space has long been a fundamental issue in user interface design. We live in a time of rapid advances in available CPU power and memory. However, the common sizes of our computational display spaces have only minimally increased or in some cases, such as hand held devices, actually decreased. In addition, the size and scope of the information spaces we wish to explore are also expanding. Representing vast amounts of information on our relatively small screens has become increasingly problematic and has been associated with problems in navigation, interpretation and recognition. User interface research has proposed several differing presentation approaches to address these problems. These methods create displays that vary considerably, visually and algorithmically. We present a unified framework that provides a way of relating seemingly distinct methods, facilitating the inclusion of more than one presentation method in a single interface. Furthermore, it supports extrapolation between the presentation methods it describes. Of particular interest are the presentation possibilities that exist in the ranges between various distortion presentations, magnified insets and detail-in-context presentations, and between detail-in-context presentations and a full-zooming environment. This unified framework offers a geometric presentation library in which presentation variations are available independently of the mode of graphic representation. The intention is to promote the ease of exploration and experimentation into the use of varied presentation combinations.}
} 
@inproceedings{Bell:2001:VMV:502348.502363,
 author = {Bell, Blaine and Feiner, Steven and H\"{o}llerer, Tobias},
 title = {View management for virtual and augmented reality},
 booktitle = {Proceedings of the 14th annual ACM symposium on User interface software and technology},
 series = {UIST '01},
 year = {2001},
 isbn = {1-58113-438-X},
 location = {Orlando, Florida},
 pages = {101--110},
 numpages = {10},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/502348.502363},
 doi = {10.1145/502348.502363},
 acmid = {502363},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {annotation, augmented reality, environment management, labeling, view management, virtual environments, wearable computing},
 abstract = {We describe a view-management component for interactive 3D user interfaces. By view management, we mean maintaining visual constraints on the projections of objects on the view plane, such as locating related objects near each other, or preventing objects from occluding each other. Our view-management component accomplishes this by modifying selected object properties, including position, size, and transparency, which are tagged to indicate their constraints. For example, some objects may have geometric properties that are determined entirely by a physical simulation and which cannot be modified, while other objects may be annotations whose position and size are flexible.We introduce algorithms that use upright rectangular extents to represent on the view plane a dynamic and efficient approximation of the occupied space containing the projections of visible portions of 3D objects, as well as the unoccupied space in which objects can be placed to avoid occlusion. Layout decisions from previous frames are taken into account to reduce visual discontinuities. We present augmented reality and virtual reality examples to which we have applied our approach, including a dynamically labeled and annotated environment.}
} 
@inproceedings{Bederson:1994:PZG:192426.192435,
 author = {Bederson, Benjamin B. and Hollan, James D.},
 title = {Pad++: a zooming graphical interface for exploring alternate interface physics},
 booktitle = {Proceedings of the 7th annual ACM symposium on User interface software and technology},
 series = {UIST '94},
 year = {1994},
 isbn = {0-89791-657-3},
 location = {Marina del Rey, California, USA},
 pages = {17--26},
 numpages = {10},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/192426.192435},
 doi = {10.1145/192426.192435},
 acmid = {192435},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {authoring, hypertext, information navigation, information physics, information visualization, interactive user interfaces, multiscale interfaces, zooming interfaces},
 abstract = {We describe the current status of Pad++, a zooming graphical interface that we are exploring as an alternative to traditional window and icon-based approaches to interface design. We discuss the motivation for Pad++, describe the implementation, and present prototype applications. In addition, we introduce an informational physics strategy for interface design and briefly compare it with metaphor-based design strategies.}
} 
@inproceedings{Beaudouin-Lafon:2001:NIT:502348.502371,
 author = {Beaudouin-Lafon, Michel},
 title = {Novel interaction techniques for overlapping windows},
 booktitle = {Proceedings of the 14th annual ACM symposium on User interface software and technology},
 series = {UIST '01},
 year = {2001},
 isbn = {1-58113-438-X},
 location = {Orlando, Florida},
 pages = {153--154},
 numpages = {2},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/502348.502371},
 doi = {10.1145/502348.502371},
 acmid = {502371},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {interaction technique, window management},
 abstract = {This note presents several techniques to improve window management with overlapping windows: tabbed windows, turning and peeling back windows, and snapping and zipping windows.}
} 
@inproceedings{Bauer:2004:CPM:1032665.1034569,
 author = {Bauer, Dan and Fastrez, Pierre and Hollan, Jim},
 title = {Computationally-Enriched 'Piles' for Managing Digital Photo Collections},
 booktitle = {Proceedings of the 2004 IEEE Symposium on Visual Languages - Human Centric Computing},
 series = {VLHCC '04},
 year = {2004},
 isbn = {0-7803-8696-5},
 pages = {193--195},
 numpages = {3},
 url = {http://dx.doi.org.prox.lib.ncsu.edu/10.1109/VLHCC.2004.13},
 doi = {10.1109/VLHCC.2004.13},
 acmid = {1034569},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 abstract = {We explore and extend the metaphor of "piles" to include computationally-enriched piles, portable regions of automation in Dynapad, a multiscale workspace. We describe these collection-management tools and how their design was informed by observing people organizing collections of personal digital photographs.}
} 
@inproceedings{Apitz:2004:CCD:1029632.1029635,
 author = {Apitz, Georg and Guimbreti\`{e}re, Fran\c{c}ois},
 title = {CrossY: a crossing-based drawing application},
 booktitle = {Proceedings of the 17th annual ACM symposium on User interface software and technology},
 series = {UIST '04},
 year = {2004},
 isbn = {1-58113-957-8},
 location = {Santa Fe, NM, USA},
 pages = {3--12},
 numpages = {10},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1029632.1029635},
 doi = {10.1145/1029632.1029635},
 acmid = {1029635},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {command composition, crossing based interfaces, fluid interaction, pen-computing},
 abstract = {We introduce CrossY, a simple drawing application developed as a benchmark to demonstrate the feasibility of goal-crossing as the basis for a graphical user interface. While crossing was previously identified as a potential substitute for the classic point-and-click interaction, this work is the first to report on the practical aspects of implementing an interface solely based on goal-crossing.}
} 
@inproceedings{Accot:2002:MDF:503376.503390,
 author = {Accot, Johnny and Zhai, Shumin},
 title = {More than dotting the i's --- foundations for crossing-based interfaces},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '02},
 year = {2002},
 isbn = {1-58113-453-3},
 location = {Minneapolis, Minnesota, USA},
 pages = {73--80},
 numpages = {8},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/503376.503390},
 doi = {10.1145/503376.503390},
 acmid = {503390},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Fitts' law, events, goal crossing, goal passing, graphical user interfaces, input, input performance, interaction techniques, pointing, widgets},
 abstract = {Today's graphical interactive systems largely depend upon pointing actions, i.e. entering an object and selecting it. In this paper we explore whether an alternate paradigm --- crossing boundaries --- may substitute or complement pointing as another fundamental interaction method. We describe an experiment in which we systematically evaluate two target-pointing tasks and four goal-crossing tasks, which differ by the direction of the movement variability constraint (collinear vs. orthogonal) and by the nature of the action (pointing vs. crossing, discrete vs. continuous). We found that participants' temporal performance in each of the six tasks was dependent on the index of difficulty formulated in the same way as in Fitts' law, but that the parameters differ by task. We also found that goal crossing completion time was shorter or no longer than pointing performance under the same index of difficulty. These regularities, as well as qualitative characterizations of crossing actions and their application in HCI, lay the foundation for designing crossing-based user interfaces.}
} 

@inproceedings{Accot:2002:MDF:503376.503390,
 author = {Baraff, D., Witkin, A., Kass, M.},
 title = {An introduction to physically based modeling: particle system dynamics},
 booktitle = {SIGGRAPH Course Notes},
 series = {SIGGRAPH Course Notes '97},
 year = {1997},
 abstract = {Physically based modeling has become an important new approach to computer animation and computer graphics modeling. Although physically based modeling is inherently a mathematical subject, the math involved needn’t be any more difficult nor esoteric than the math that underlies many other areas of computer graphics, such as ray tracing or surface modeling. Many papers on the subject have presupposed a specialized mathematical background that many members of the computer graphics community lack. Consequently, many capable computer graphics practitioners, despite their interest in the subject, have simply been put off by the density of the math. This course addresses the need to make the principles and methods of physically based modeling accessible to a broader computer graphics audience—those who are familiar with mainstream computer graphics and have the usual basic computer graphics math, such as vector/matrix manipulations, but whose first year calculus course may be only dimly remem-bered. Course topics include modeling the dynamics of particle systems and rigid bodies, basic numerical methods for differential equations, simulation of deformable surfaces, collision detection, modeling energy functions and hard constraints, and the dynamics of collision and contact.} 
 }

@INPROCEEDINGS{638254, 
author={Bartram, L.}, 
booktitle={Systems, Man, and Cybernetics, 1997. Computational Cybernetics and Simulation., 1997 IEEE International Conference on}, 
title={Can motion increase user interface bandwidth in complex systems?}, 
year={1997}, 
volume={2}, 
pages={1686-1692 vol.2}, 
abstract={Current user interfaces to complex systems suffer from data displays which are increasingly cumbersome since the representation techniques exceed the human's perceptual capacity to efficiently interpret them. New display dimensions are required to support the user in integrating and relating information across displays and representations. Advances in technology have made animation a viable alternative. Motion holds promise as a perceptually rich and efficient display dimension but little is known about its properties for information display. We summarize types of movement characterization from diverse disciplines and proposes an initial taxonomy of motion properties and application to serve as a framework for further empirical investigation into motion as a useful display dimension}, 
keywords={computer animation;graphical user interfaces;human factors;animation;complex systems;data displays;display dimensions;information display;motion;movement characterization;perceptual capacity;user interface bandwidth;Animation;Bandwidth;Computer displays;Data visualization;Graphics;Laboratories;Large screen displays;Multimedia systems;Taxonomy;User interfaces}, 
doi={10.1109/ICSMC.1997.638254}, 
ISSN={1062-922X},
}

@MISC{Carpendale99thetardis:,
    author = {M. S. T. Carpendale and D.J. Cowperthwaite and M. Tigges and A. Fall and F. D. Fracchia},
    title = {The Tardis: A Visual Exploration Environment for Landscape Dynamics},
    year = {1999}
	keywords = { Multi-scale Views, Detail-in-Context, Viewing Algorithms, Information Visualization, Multi-dimensional Data }
	abstract = {This paper presents the creation of a a visual environment for exploring landscape patterns and changes to such patterns over time. Dynamic landscape patterns can involve both spatial and temporal complexity. Exploration of spatio-temporal landscape patterns should provide the ability to view information at dierent scales to permit navigation of a vast amount of information in a manner that facilitates comprehension rather than confusion. One way of achieving this goal is to support selection, navigation and comparison of progressively rened segments of time and space. We have entitled this system Tardis after the time machine of Dr. Who, to emphasize the exploration of time dependent data and because our use of elastic presentation has the eect of providing more internal space than the external volume suggests. Of special concern in this research is the extent of the data and its inter-relationships that need to be understood over multiple scales, and the challenge inherent in implementing viewing methods to facilitate understanding} 
}

@INPROCEEDINGS{Maarten99thecontribution,
    author = {Maarten and Mary P. Czerwinski and Maarten Van Dantzich and George Robertson and Hunter Hoffman},
    title = {The Contribution of Thumbnail Image, Mouse-over Text and Spatial Location Memory to Web Page Retrieval in 3D},
    booktitle = {},
    year = {1999},
    pages = {163--170},
    publisher = {Press}
	abstract = {We present an empirical evaluation of the contribution of pictorial image and spatial location information on the retrieval of previously stored web pages. Subjects were given 100 snapshots of web pages that they stored in spatial locations on an inclined plane in a desktop 3D environment (Data Mountain). We had them return and try to retrieve their pages again, using a variety of retrieval cues. Even though users had not seen their web page layout for several months, their retrieval times were not significantly slower. In addition, on half of the trials, stored pages were not presented as thumbnail images of the web pages but as blank icons. Taking the pictorial thumbnail images away initially led to a significant drop in subjects’ ability to find the pages, although within a short period of time subjects were able to find the pages equally fast without the thumbnail information. These results indicate that the use of 3D visualization techniques such as those described in this paper can lead to improved user memory for where favorite or frequently used information is stored in an electronic environment.} 
	keywords = {3D information visualization, information retrieval, thumbnail images, spatial location memory}
}
@inproceedings{Kurtenbach:1993:LEP:169059.169426,
 author = {Kurtenbach, Gordon and Buxton, William},
 title = {The limits of expert performance using hierarchic marking menus},
 booktitle = {Proceedings of the INTERACT '93 and CHI '93 Conference on Human Factors in Computing Systems},
 series = {CHI '93},
 year = {1993},
 isbn = {0-89791-575-5},
 location = {Amsterdam, The Netherlands},
 pages = {482--487},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/169059.169426},
 doi = {10.1145/169059.169426},
 acmid = {169426},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {accelerators, gestures, input devices, marking menus, pen based input, pie menus},
 abstract = {A marking menu allows a user to perform a menu selection by either popping-up a radial (or pie) menu, or by making a straight mark in the direction of the desired menu item without popping-up the menu. A hierarchic marking menu uses hierarchic radial menus and “zig-zag” marks to select from the hierarchy. This paper experimentally investigates the bounds on how many items can be in each level, and how deep the hierarchy can be, before using a marking to select an item becomes too slow or prone to errors.}
} 

@INPROCEEDINGS{Mcguffin02fastsliders:,
    author = {Michael Mcguffin and Nicolas Burtnyk and Gordon Kurtenbach and King Street},
    title = {FaST Sliders: Integrating marking menus and the adjustment of continuous values. Graphics Interface},
    booktitle = {GI 2002 Conference Proceedings},
    year = {2002},
    pages = {35--42}
	abstract = {We propose a technique, called FaST Sliders, for selecting and adjusting continuous values using a fast, transient interaction much like pop-up menus. FaST Sliders combine marking menus and graphical sliders in a design that allows operation with quick ballistic movements for selection and coarse adjustment. Furthermore, additional controls can be displayed within the same interaction, for fine adjustments or other functions. We describe the design of FaST Sliders and a user study comparing FaST Sliders to other transient techniques. The results of our user study indicate that FaST Sliders hold potential. We observed that users found FaST Slider easy to learn and made use of and preferred its affordances for ballistic movement and additional controls.}

}

@INPROCEEDINGS{1250400, 
author={McGuffin, M.J. and Tancau, L. and Balakrishnan, R.}, 
booktitle={Visualization, 2003. VIS 2003. IEEE}, 
title={Using deformations for browsing volumetric data}, 
year={2003}, 
pages={401-408}, 
abstract={Many traditional techniques for "looking inside" volumetric data involve removing portions of the data, for example using various cutting tools, to reveal the interior. This allows the user to see hidden parts of the data, but has the disadvantage of removing potentially important surrounding contextual information. We explore an alternate strategy for browsing that uses deformations, where the user can cut into and open up, spread apart, or peel away parts of the volume in real time, making the interior visible while still retaining surrounding context. We consider various deformation strategies and present a number of interaction techniques based on different metaphors. Our designs pay special attention to the semantic layers that might compose a volume (e.g. the skin, muscle, bone in a scan of a human). Users can apply deformations to only selected layers, or apply a given deformation to a different degree to each layer, making browsing more flexible and facilitating the visualization of relationships between layers. Our interaction techniques are controlled with direct, "in place" manipulation, using pop-up menus and 3D widgets, to avoid the divided attention and awkwardness that would come with panels of traditional widgets. Initial user feedback indicates that our techniques are valuable, especially for showing portions of the data spatially situated in context with surrounding data.}, 
keywords={data visualisation;graphical user interfaces;rendering (computer graphics);solid modelling;3D widgets;image deformation;interaction techniques;pop-up menu;semantic layers;spatial data;volumetric data browsing;Bones;Chromium;Computer graphics;Computer science;Cutting tools;Data visualization;Feedback;Humans;Muscles;Skin}, 
doi={10.1109/VISUAL.2003.1250400},
}

@inproceedings{Bharath:2008:FNH:1378773.1378814,
 author = {Bharath, A. and Madhvanath, Sriganesh},
 title = {FreePad: a novel handwriting-based text input for pen and touch interfaces},
 booktitle = {Proceedings of the 13th international conference on Intelligent user interfaces},
 series = {IUI '08},
 year = {2008},
 isbn = {978-1-59593-987-6},
 location = {Gran Canaria, Spain},
 pages = {297--300},
 numpages = {4},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1378773.1378814},
 doi = {10.1145/1378773.1378814},
 acmid = {1378814},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {handwriting recognition, pen and touch interfaces, text input},
 abstract = {The last decade has seen tremendous growth in mobile devices such as Pocket PCs, mobile phones, Tablet PCs and notebooks. Most of these devices enable interaction through a stylus or touch interface, powered by handwriting recognition (HWR) capability. In this paper, we propose a novel input method that addresses some of the issues that arise due to the constraints posed by these devices in accepting handwriting input. For instance, many of the devices have a small writing area making "continuous" input difficult if not impossible, and the process of handwriting input demands significant user attention. The proposed solution is inspired by touch-typing, and appreciably reduces user's effort in the interaction, and it is especially suited for very small writing areas. The approach has been demonstrated using a prototype system that recognizes handwritten English words, and its accuracy has been evaluated using a standard dataset of handwritten words. A preliminary user study has also been carried out to understand user acceptance of the proposed technique.}
}

@inproceedings{Kristensson:2008:IEM:1463160.1463227,
 author = {Kristensson, Per Ola and Arnell, Olof and Bj\"{o}rk, Annelie and Dahlb\"{a}ck, Nils and Pennerup, Joackim and Prytz, Erik and Wikman, Johan and \AAstr\"{o}m, Niclas},
 title = {InfoTouch: an explorative multi-touch visualization interface for tagged photo collections},
 booktitle = {Proceedings of the 5th Nordic conference on Human-computer interaction: building bridges},
 series = {NordiCHI '08},
 year = {2008},
 isbn = {978-1-59593-704-9},
 location = {Lund, Sweden},
 pages = {491--494},
 numpages = {4},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1463160.1463227},
 doi = {10.1145/1463160.1463227},
 acmid = {1463227},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {information visualization, interaction surfaces, multi-touch, photo browsing, photo collections, tag clouds, tagging, tags, visualization},
 abstract = {We report on a design exploration into how a large multi-touch tabletop display can be used for information visualization. We designed an interface where users explored a tagged photo collection by bi-manual manipulation of the collections' tag cloud. User feedback showed that despite the availability of multi-touch most of the actual interactions were single-touch. However, some particular natural actions, such as grabbing the tag cloud and partitioning it into two parts, were often carried with both hands. Thus our user study indicates that multi-touch can act as a useful complementary interaction method in information visualization interfaces.}
} 

@inproceedings{Poupyrev:2002:ATD:571985.571993,
 author = {Poupyrev, Ivan and Maruyama, Shigeaki and Rekimoto, Jun},
 title = {Ambient touch: designing tactile interfaces for handheld devices},
 booktitle = {Proceedings of the 15th annual ACM symposium on User interface software and technology},
 series = {UIST '02},
 year = {2002},
 isbn = {1-58113-488-6},
 location = {Paris, France},
 pages = {51--60},
 numpages = {10},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/571985.571993},
 doi = {10.1145/571985.571993},
 acmid = {571993},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {mobile devices and interfaces, tactile feedback},
 abstract = {This paper investigates the sense of touch as a channel for communicating with miniature handheld devices. We embedded a PDA with a TouchEngineTM --- a thin, miniature lower-power tactile actuator that we have designed specifically to use in mobile interfaces (Figure 1). Unlike previous tactile actuators, the TouchEngine is a universal tactile display that can produce a wide variety of tactile feelings from simple clicks to complex vibrotactile patterns. Using the TouchEngine, we began exploring the design space of interactive tactile feedback for handheld computers. Here, we investigated only a subset of this space: using touch as the ambient, background channel of interaction. We proposed a general approach to design such tactile interfaces and described several implemented prototypes. Finally, our user studies demonstrated 22% faster task completion when we enhanced handheld tilting interfaces with tactile feedback.}
} 

@inproceedings{Oehl:2007:CET:1766451.1766469,
 author = {Oehl, Michael and Sutter, Christine and Ziefle, Martina},
 title = {Considerations on efficient touch interfaces: how display size influences the performance in an applied pointing task},
 booktitle = {Proceedings of the 2007 conference on Human interface: Part I},
 year = {2007},
 isbn = {978-3-540-73344-7},
 location = {Beijing, China},
 pages = {136--143},
 numpages = {8},
 url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1766451.1766469},
 acmid = {1766469},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {display size, pointing performance, small screen device, task difficulty, touch input},
 abstract = {The limited screen space in small technical devices imposes considerable usability challenges. On the one hand objects displayed on small screens should be big enough to be hit successfully, but also small enough to house several objects on the screen at the same time. However, findings up to now show that single pointing is more effective in a large display compared to a smaller display. In the present experiment this was also confirmed for an applied multidirectional serial pointing task. Especially in more difficult tasks, results point at a shift of the speed-accuracy tradeoff. In large displays a fast and comparably accurate execution is chosen in contrast to a very inaccurate and time-consuming style in small displays. From an ergonomic point of view the outcomes recommend an optimized balance of task difficulty and display size in small screen devices.}
}  

@inproceedings{Vogt:2004:MST:1186223.1186268,
 author = {Vogt, Florian and Chen, Timothy and Hoskinson, Reynald and Fels, Sidney},
 title = {A malleable surface touch interface},
 booktitle = {ACM SIGGRAPH 2004 Sketches},
 series = {SIGGRAPH '04},
 year = {2004},
 isbn = {1-58113-896-2},
 location = {Los Angeles, California},
 pages = {36--},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1186223.1186268},
 doi = {10.1145/1186223.1186268},
 acmid = {1186268},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract = {Many conventional whole-hand input devices capture interaction by means of non-contact methods or through some physical medium. Such physical interfaces often involve contact of the hands and fingers with a hard, unyielding surface. In this sketch, we propose an input device that captures whole-hand input through a malleable medium. Its deformability and inherent feedback characteristics make it suitable for sculpting and molding applications.} 
}

  @inproceedings{Jin:2007:TSU:1766311.1766419,
 author = {Jin, Zhao Xia and Plocher, Tom and Kiff, Liana},
 title = {Touch screen user interfaces for older adults: button size and spacing},
 booktitle = {Proceedings of the 4th international conference on Universal access in human computer interaction: coping with diversity},
 series = {UAHCI'07},
 year = {2007},
 isbn = {978-3-540-73278-5},
 location = {Beijing, China},
 pages = {933--941},
 numpages = {9},
 url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1766311.1766419},
 acmid = {1766419},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {older adults, touch screen, usability, user interface design},
 abstract = {This study investigated the optimal button size and spacing for touch screen user interfaces intended for use by older adults. Current recommendations in the literature are aimed at general audiences and fail to consider the specific needs of older adults. Three independent variables, button size, button spacing, and manual dexterity were studied in two experiments that measured reaction time, accuracy and user preferences. Design recommendations for touch screen button size and spacing for older adults are stated based on these experiments. The paper also discusses the role of manual dexterity in designing appropriate touch screen interfaces for older adults.}
} 

@inproceedings{Shen:2007:CTE:1784297.1784317,
 author = {Shen, Chia},
 title = {From clicks to touches: enabling face-to-face shared social interface on multi-touch tabletops},
 booktitle = {Proceedings of the 2nd international conference on Online communities and social computing},
 series = {OCSC'07},
 year = {2007},
 isbn = {978-3-540-73256-3},
 location = {Beijing, China},
 pages = {169--175},
 numpages = {7},
 url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1784297.1784317},
 acmid = {1784317},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 abstract = {Making the interactions with a digital user interface disappears into and becomes a part of the human to human interaction and conversation is a challenge. Conventional metaphor and underlying interface infrastructure for single-user desktop systems have been traditionally geared towards single mouse and keyboard, click-and-type based, WIMP interface design. On the other hand, people usually meet in social context around a table, facing each other. A table setting provides a large interactive visual and tangible surface. It affords and encourages collaboration, coordination, serendipity, as well as simultaneous and parallel interaction among multiple people. In this paper, we examine and explore the opportunities, challenges, research issues, pitfalls, and plausible approaches for enabling direct touchable, shared social interactions on multi-touch multi-user tabletops.}
} 

@inproceedings{Motamedi:2007:KTT:1226969.1226974,
 author = {Motamedi, Nima},
 title = {Keep in touch: a tactile-vision intimate interface},
 booktitle = {Proceedings of the 1st international conference on Tangible and embedded interaction},
 series = {TEI '07},
 year = {2007},
 isbn = {978-1-59593-619-6},
 location = {Baton Rouge, Louisiana},
 pages = {21--22},
 numpages = {2},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1226969.1226974},
 doi = {10.1145/1226969.1226974},
 acmid = {1226974},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {intimacy, sensorial interfaces, sensory mapping, tactile},
 abstract = {We present an overview of Keep in Touch, a networked fabric touchscreen designed to support and maintain intimacy for couples in long distance relationships. To achieve this, a novel sensorial interface was created by combining the visual and tactile senses together. Each partner is presented with a blurred digital projection of their lover. When they touch their partner's body, the image comes into focus revealing their features. We describe how this sensory mapping creates an expressive and emotional interface allowing couples to communicate through touch, gestures, and body language.}
} 

@inproceedings{Matulic:2007:TST:1284420.1284448,
 author = {Matulic, Fabrice},
 title = {Touch scan-n-search: a touchscreen interface to retrieve online versions of scanned documents},
 booktitle = {Proceedings of the 2007 ACM symposium on Document engineering},
 series = {DocEng '07},
 year = {2007},
 isbn = {978-1-59593-776-6},
 location = {Winnipeg, Manitoba, Canada},
 pages = {97--98},
 numpages = {2},
 url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1284420.1284448},
 doi = {10.1145/1284420.1284448},
 acmid = {1284448},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {GUI, keyword extraction, online news retrieval, scanned document},
 abstract = {The system described in this paper attempts to tackle the problem of finding online content based on paper documents through an intuitive touchscreen interface designed for modern scanners and multifunction printers. Touch Scan-n-Search allows the user to select elements of a scanned document (e.g. a newspaper article) and to seamlessly connect to common web search services in order to retrieve the online version of the document along with related content. This is achieved by automatically extracting keyphrases from text elements in the document (obtained by OCR) and creating "tappable" GUI widgets to allow the user to control and fine-tune the search requests. The retrieved content can then be printed, sent, or used to compose new documents.}
} 

@INPROCEEDINGS{Maarten99thecontribution,
    author = {Maarten and Mary P. Czerwinski and Maarten Van Dantzich and George Robertson and Hunter Hoffman},
    title = {The Contribution of Thumbnail Image, Mouse-over Text and Spatial Location Memory to Web Page Retrieval in 3D},
    booktitle = {},
    year = {1999},
    pages = {163--170},
    publisher = {Press}
	abstract = {We present an empirical evaluation of the contribution of pictorial image and spatial location information on the retrieval of previously stored web pages. Subjects were given 100 snapshots of web pages that they stored in spatial locations on an inclined plane in a desktop 3D environment (Data Mountain). We had them return and try to retrieve their pages again, using a variety of retrieval cues. Even though users had not seen their web page layout for several months, their retrieval times were not significantly slower. In addition, on half of the trials, stored pages were not presented as thumbnail images of the web pages but as blank icons. Taking the pictorial thumbnail images away initially led to a significant drop in subjects’ ability to find the pages, although within a short period of time subjects were able to find the pages equally fast without the thumbnail information. These results indicate that the use of 3D visualization techniques such as those described in this paper can lead to improved user memory for where favorite or frequently used information is stored in an electronic environment.}
}
@article{,
	author = {C. Tristram}
	title = {{The Next Computer Interface}},
	journal = {MIT Technology Review Magazine},
	year = {2001}
	month = dec,
	pages = {52----61},
	url = {http://www.technologyreview.com/featuredstory/401304/the-next-computer-interface/},
	abstract = {“The desktop is dead,” declares David Gelernter. Gelernter is referring to the “desktop metaphor”-the term frequently used for the hierarchical system of files, folders and icons that we use to manage information stored on our home or office computers. At the annual gathering of technophiles at TechXNY/PC Expo 2001 in New York last June, he told the rapt crowd attending his keynote speech that the desktop metaphor is nothing more than virtual Tupperware. “Our electronic documents are scattered by the thousands in all sorts of little containers all over the place,” he said. “The more information and the more computers in our lives, the more of a nuisance this system becomes.”},
}
