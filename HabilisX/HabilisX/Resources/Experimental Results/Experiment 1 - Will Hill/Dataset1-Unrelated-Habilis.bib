@inproceedings{Apitz:2004:CCD:1029632.1029635,
abstract = {We introduce CrossY, a simple drawing application developed as a benchmark to demonstrate the feasibility of goal-crossing as the basis for a graphical user interface. While crossing was previously identified as a potential substitute for the classic point-and-click interaction, this work is the first to report on the practical aspects of implementing an interface solely based on goal-crossing.},
address = {New York, NY, USA},
author = {Apitz, Georg and Guimbreti\`{e}re, Fran\c{c}ois},
booktitle = {Proceedings of the 17th annual ACM symposium on User interface software and technology},
doi = {10.1145/1029632.1029635},
isbn = {1-58113-957-8},
keywords = { crossing based interfaces, fluid interaction, pen-computing,command composition},
pages = {3--12},
publisher = {ACM},
series = {UIST '04},
title = {{CrossY: a crossing-based drawing application}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1029632.1029635},
year = {2004}
}
@article{Hazzan:2002:RPP:771439.771440,
abstract = {This paper focuses on the application of the reflective practitioner (RP) perspective to the profession of software engineering (SE). The RP perspective guides professional people to rethink their professional creations during and after the accomplishment of the creation process. Analysis of the field of SE supports the adoption of the RP perspective to SE in general and to SE education in particular. The RP perspective emphasizes the studio--the basic training method in architecture schools--as the educational environment for design studies. In such studios students develop projects with a close guidance of a tutor. Analysis of the kind of tasks that architecture students are working on and a comparison of these tasks to the problems that SE students are facing, suggest that the studio may be an appropriate teaching method in SE as well. The paper presents the main ideas of the RP perspective and examines its fitness to SE in general and to SE education in particular. The discussion is based on analysis of the RP perspective and of the SE profession, visits to architecture studios, and conversations with tutors in architecture studios and with computing science practitioners.},
address = {New York, NY, USA},
author = {Hazzan, Orit},
doi = {10.1016/S0164-1212(02)00012-2},
issn = {0164-1212},
journal = {J. Syst. Softw.},
month = sep,
number = {3},
pages = {161--171},
publisher = {Elsevier Science Inc.},
title = {{The reflective practitioner perspective in software engineering education}},
volume = {63},
year = {2002}
}
@inproceedings{Motamedi:2007:KTT:1226969.1226974,
abstract = {We present an overview of Keep in Touch, a networked fabric touchscreen designed to support and maintain intimacy for couples in long distance relationships. To achieve this, a novel sensorial interface was created by combining the visual and tactile senses together. Each partner is presented with a blurred digital projection of their lover. When they touch their partner's body, the image comes into focus revealing their features. We describe how this sensory mapping creates an expressive and emotional interface allowing couples to communicate through touch, gestures, and body language.},
address = {New York, NY, USA},
author = {Motamedi, Nima},
booktitle = {Proceedings of the 1st international conference on Tangible and embedded interaction},
doi = {10.1145/1226969.1226974},
isbn = {978-1-59593-619-6},
keywords = { sensorial interfaces, sensory mapping, tactile,intimacy},
pages = {21--22},
publisher = {ACM},
series = {TEI '07},
title = {{Keep in touch: a tactile-vision intimate interface}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1226969.1226974},
year = {2007}
}
@inproceedings{Shen:2007:CTE:1784297.1784317,
abstract = {Making the interactions with a digital user interface disappears into and becomes a part of the human to human interaction and conversation is a challenge. Conventional metaphor and underlying interface infrastructure for single-user desktop systems have been traditionally geared towards single mouse and keyboard, click-and-type based, WIMP interface design. On the other hand, people usually meet in social context around a table, facing each other. A table setting provides a large interactive visual and tangible surface. It affords and encourages collaboration, coordination, serendipity, as well as simultaneous and parallel interaction among multiple people. In this paper, we examine and explore the opportunities, challenges, research issues, pitfalls, and plausible approaches for enabling direct touchable, shared social interactions on multi-touch multi-user tabletops.},
address = {Berlin, Heidelberg},
author = {Shen, Chia},
booktitle = {Proceedings of the 2nd international conference on Online communities and social computing},
isbn = {978-3-540-73256-3},
pages = {169--175},
publisher = {Springer-Verlag},
series = {OCSC'07},
title = {{From clicks to touches: enabling face-to-face shared social interface on multi-touch tabletops}},
url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1784297.1784317},
year = {2007}
}
@inproceedings{DiGioia:2005:SNM:1073001.1073011,
abstract = {As interest in usable security spreads, the use of visual approaches in which the functioning of a distributed system is made visually available to end users is an approach that a number of researchers have examined. In this paper, we discuss the use of the social navigation paradigm as a way of organizing visual displays of system action. Drawing on a previous study of security in the Kazaa peer to peer system, we present some examples of the ways in which social navigation can be incorporated in support of usable security.},
address = {New York, NY, USA},
author = {DiGioia, Paul and Dourish, Paul},
booktitle = {Proceedings of the 2005 symposium on Usable privacy and security},
doi = {10.1145/1073001.1073011},
isbn = {1-59593-178-3},
keywords = { peer-to-peer filesharing, social navigation, visualization,collaborative interfaces},
pages = {101--108},
publisher = {ACM},
series = {SOUPS '05},
title = {{Social navigation as a model for usable security}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1073001.1073011},
year = {2005}
}
@inproceedings{Thorne:2004:MDI:1186562.1015740,
abstract = {In this paper we present a novel system for sketching the motion of a character. The process begins by sketching a character to be animated. An animated motion is then created for the character by drawing a continuous sequence of lines, arcs, and loops. These are parsed and mapped to a parameterized set of output motions that further reflect the location and timing of the input sketch. The current system supports a repertoire of 18 different types of motions in 2D and a subset of these in 3D. The system is unique in its use of a cursive motion specification, its ability to allow for fast experimentation, and its ease of use for non-experts.},
address = {New York, NY, USA},
author = {Thorne, Matthew and Burke, David and van de Panne, Michiel},
booktitle = {ACM SIGGRAPH 2004 Papers},
doi = {10.1145/1186562.1015740},
keywords = { Computer Puppetry, Gestural Interfaces, Sketching,Animation},
pages = {424--431},
publisher = {ACM},
series = {SIGGRAPH '04},
title = {{Motion doodles: an interface for sketching character motion}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1186562.1015740},
year = {2004}
}
@inproceedings{Miller:2005:CSC:1121987.1122115,
abstract = {Both agile development and User Centered Design stress collaboration between customers and product teams, but getting these methodologies to work well together is not easy. This paper describes one company's efforts to merge these processes by creating interconnected parallel design and development tracks. The benefits of this approach are demonstrated by showing how, when and why customer input was incorporated during the release of a successful software product.},
address = {Washington, DC, USA},
author = {Miller, Lynn},
booktitle = {Proceedings of the Agile Development Conference},
doi = {10.1109/ADC.2005.16},
isbn = {0-7695-2487-7},
pages = {225--234},
publisher = {IEEE Computer Society},
series = {ADC '05},
title = {{Case Study of Customer Input For a Successful Product}},
url = {http://dx.doi.org.prox.lib.ncsu.edu/10.1109/ADC.2005.16},
year = {2005}
}
@inproceedings{Nacenta:2006:PCP:1124772.1124817,
abstract = {Multi-display environments and smart meeting rooms are now becoming more common. These environments build a shared display space from variety of devices: tablets, projected surfaces, tabletops, and traditional monitors. Since the different display surfaces are usually not organized in a single plane, traditional schemes for stitching the displays together can cause problems for interaction. However, there is a more natural way to compose display space -- using perspective. In this paper, we develop interaction techniques for multi-display environments that are based on the user's perspective on the room. We designed the Perspective Cursor, a mapping of cursor to display space that appears natural and logical from wherever the user is located. We conducted an experiment to compare two perspective-based techniques, the Perspective Cursor and a beam-based technique, with traditional stitched displays. We found that both perspective techniques were significantly faster for targeting tasks than the traditional technique, and that Perspective Cursor was the most preferred method. Our results show that integrating perspective into the design of multi-display environments can substantially improve performance.},
address = {New York, NY, USA},
author = {Nacenta, Miguel A and Sallam, Samer and Champoux, Bernard and Subramanian, Sriram and Gutwin, Carl},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1124772.1124817},
isbn = {1-59593-372-7},
keywords = { laser pointing, multi-display interaction techniques, multi-monitor environments,direct-manipulation interfaces},
pages = {289--298},
publisher = {ACM},
series = {CHI '06},
title = {{Perspective cursor: perspective-based interaction for multi-display environments}},
year = {2006}
}
@article{Kuhn:1998:SDS:624624.625838,
abstract = {Some software designers have recently turned to building architecture for inspiration in their efforts to improve professional practice. An attempt to apply the studio method of architectural training to software design education, reported in this article, reveals much about education and practice in both professions. Studio courses provoke creative reflection on how to improve current training practices and could provide a new way to develop software design expertise.},
address = {Los Alamitos, CA, USA},
author = {Kuhn, Sarah},
doi = {10.1109/52.663788},
issn = {0740-7459},
journal = {IEEE Softw.},
month = mar,
number = {2},
pages = {65--71},
publisher = {IEEE Computer Society Press},
title = {{The Software Design Studio: An Exploration}},
volume = {15},
year = {1998}
}
@inproceedings{Ramos:2004:PW:985692.985754,
abstract = {Current user interface widgets typically assume that the input device can only provide x-y position and binary button press information. Other inputs such as the continuous pressure data provided by styluses on tablets are rarely used. We explore the design space of using the continuous pressure sensing capabilities of styluses to operate multi-state widgets. We present the results of a controlled experiment that investigates human ability to perform discrete target selection tasks by varying a stylus' pressure, with full or partial visual feedback. The experiment also considers different techniques for confirming selection once the target is acquired. Based on the experimental results, we discuss implications for the design of pressure sensitive widgets. A taxonomy of pressure widgets is presented, along with a set of initial concept sketches of various pressure widget designs.},
address = {New York, NY, USA},
author = {Ramos, Gonzalo and Boulos, Matthew and Balakrishnan, Ravin},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/985692.985754},
isbn = {1-58113-702-8},
keywords = { pen-based interfaces, pressure input, pressure widgets,isometric input},
pages = {487--494},
publisher = {ACM},
series = {CHI '04},
title = {{Pressure widgets}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/985692.985754},
year = {2004}
}
@inproceedings{Jin:2007:TSU:1766311.1766419,
abstract = {This study investigated the optimal button size and spacing for touch screen user interfaces intended for use by older adults. Current recommendations in the literature are aimed at general audiences and fail to consider the specific needs of older adults. Three independent variables, button size, button spacing, and manual dexterity were studied in two experiments that measured reaction time, accuracy and user preferences. Design recommendations for touch screen button size and spacing for older adults are stated based on these experiments. The paper also discusses the role of manual dexterity in designing appropriate touch screen interfaces for older adults.},
address = {Berlin, Heidelberg},
author = {Jin, Zhao Xia and Plocher, Tom and Kiff, Liana},
booktitle = {Proceedings of the 4th international conference on Universal access in human computer interaction: coping with diversity},
isbn = {978-3-540-73278-5},
keywords = { touch screen, usability, user interface design,older adults},
pages = {933--941},
publisher = {Springer-Verlag},
series = {UAHCI'07},
title = {{Touch screen user interfaces for older adults: button size and spacing}},
url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1766311.1766419},
year = {2007}
}
@inproceedings{Herndon:1992:IS:142621.142622,
abstract = {It is often difficult in computer graphics applications to understand spatial relationships between objects in a 3D scene or effect changes to those objects without specialized visualization and manipulation techniques. We present a set of three-dimensional tools (widgets) called “shadows” that not only provide valuable perceptual cues about the spatial relationships between objects, but also provide a direct manipulation interface to constrained transformation techniques. These shadow widgets provide two advances over previous techniques. First, they provide high correlation between their own geometric feedback and their effects on the objects they control. Second, unlike some other 3D widgets, they do not obscure the objects they control.},
address = {New York, NY, USA},
author = {Herndon, Kenneth P and Zeleznik, Robert C and Robbins, Daniel C and Conner, D Brookshire and Snibbe, Scott S and van Dam, Andries},
booktitle = {Proceedings of the 5th annual ACM symposium on User interface software and technology},
doi = {10.1145/142621.142622},
isbn = {0-89791-549-6},
keywords = { direct manipulation, interactive systems,3D widgets},
pages = {1--6},
publisher = {ACM},
series = {UIST '92},
title = {{Interactive shadows}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/142621.142622},
year = {1992}
}
@inproceedings{Vogt:2004:MST:1186223.1186268,
abstract = {Many conventional whole-hand input devices capture interaction by means of non-contact methods or through some physical medium. Such physical interfaces often involve contact of the hands and fingers with a hard, unyielding surface. In this sketch, we propose an input device that captures whole-hand input through a malleable medium. Its deformability and inherent feedback characteristics make it suitable for sculpting and molding applications.},
address = {New York, NY, USA},
author = {Vogt, Florian and Chen, Timothy and Hoskinson, Reynald and Fels, Sidney},
booktitle = {ACM SIGGRAPH 2004 Sketches},
doi = {10.1145/1186223.1186268},
isbn = {1-58113-896-2},
pages = {36----},
publisher = {ACM},
series = {SIGGRAPH '04},
title = {{A malleable surface touch interface}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1186223.1186268},
year = {2004}
}
@inproceedings{Bharath:2008:FNH:1378773.1378814,
abstract = {The last decade has seen tremendous growth in mobile devices such as Pocket PCs, mobile phones, Tablet PCs and notebooks. Most of these devices enable interaction through a stylus or touch interface, powered by handwriting recognition (HWR) capability. In this paper, we propose a novel input method that addresses some of the issues that arise due to the constraints posed by these devices in accepting handwriting input. For instance, many of the devices have a small writing area making "continuous" input difficult if not impossible, and the process of handwriting input demands significant user attention. The proposed solution is inspired by touch-typing, and appreciably reduces user's effort in the interaction, and it is especially suited for very small writing areas. The approach has been demonstrated using a prototype system that recognizes handwritten English words, and its accuracy has been evaluated using a standard dataset of handwritten words. A preliminary user study has also been carried out to understand user acceptance of the proposed technique.},
address = {New York, NY, USA},
author = {Bharath, A and Madhvanath, Sriganesh},
booktitle = {Proceedings of the 13th international conference on Intelligent user interfaces},
doi = {10.1145/1378773.1378814},
isbn = {978-1-59593-987-6},
keywords = { pen and touch interfaces, text input,handwriting recognition},
pages = {297--300},
publisher = {ACM},
series = {IUI '08},
title = {{FreePad: a novel handwriting-based text input for pen and touch interfaces}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1378773.1378814},
year = {2008}
}
@inproceedings{Kurtenbach:1991:ICM:120782.120797,
abstract = {The direct manipulation paradigm has been effective in helping designers create easy to use mouse and keyboard based interfaces. The development of flat display surfaces and transparent tablets are now making possible interfaces where a user can write directly on the screen using a special stylus. The intention of these types of interfaces is to exploit user’s existing handwriting, mark-up and drawing skills while also providing the benefits of direct manipulation. This paper reports on a test bed program which we are using for exploring hand-marking types of interactions and their integration with direct manipulation interactions. },
address = {New York, NY, USA},
author = {Kurtenbach, Gordon and Buxton, William},
booktitle = {Proceedings of the 4th annual ACM symposium on User interface software and technology},
doi = {10.1145/120782.120797},
isbn = {0-89791-451-1},
pages = {137--144},
publisher = {ACM},
series = {UIST '91},
title = {{Issues in combining marking and direct manipulation techniques}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/120782.120797},
year = {1991}
}
@inproceedings{Poupyrev:2002:ATD:571985.571993,
abstract = {This paper investigates the sense of touch as a channel for communicating with miniature handheld devices. We embedded a PDA with a TouchEngineTM --- a thin, miniature lower-power tactile actuator that we have designed specifically to use in mobile interfaces (Figure 1). Unlike previous tactile actuators, the TouchEngine is a universal tactile display that can produce a wide variety of tactile feelings from simple clicks to complex vibrotactile patterns. Using the TouchEngine, we began exploring the design space of interactive tactile feedback for handheld computers. Here, we investigated only a subset of this space: using touch as the ambient, background channel of interaction. We proposed a general approach to design such tactile interfaces and described several implemented prototypes. Finally, our user studies demonstrated 22\% faster task completion when we enhanced handheld tilting interfaces with tactile feedback.},
address = {New York, NY, USA},
author = {Poupyrev, Ivan and Maruyama, Shigeaki and Rekimoto, Jun},
booktitle = {Proceedings of the 15th annual ACM symposium on User interface software and technology},
doi = {10.1145/571985.571993},
isbn = {1-58113-488-6},
keywords = { tactile feedback,mobile devices and interfaces},
pages = {51--60},
publisher = {ACM},
series = {UIST '02},
title = {{Ambient touch: designing tactile interfaces for handheld devices}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/571985.571993},
year = {2002}
}
@article{Bobick:1999:KPI:1246829.1246830,
abstract = {The KidsRoom is a perceptually-based, interactive, narrative playspace for children. Images, music, narration, light, and sound effects are used to transform a normal child's bedroom into a fantasy land where children are guided through a reactive adventure story. The fully automated system was designed with the following goals: (1) to keep the focus of user action and interaction in the physical and not virtual space; (2) to permit multiple, collaborating people to simultaneously engage in an interactive experience combining both real and virtual objects; (3) to use computer-vision algorithms to identify activity in the space without requiring the participants to wear any special clothing or devices; (4) to use narrative to constrain the perceptual recognition, and to use perceptual recognition to allow participants to drive the narrative; and (5) to create a truly immersive and interactive room environment. We believe the KidsRoom is the first multi-person, fully-automated, interactive, narrative environment ever constructed using non-encumbering sensors. This paper describes the KidsRoom, the technology that makes it work, and the issues that were raised during the system's development.<xref ref-type="fn" rid="fn1">1</xref> A demonstration of the project, which complements the material presented here and includes videos, images, and sounds from each part of the story is available at somewhere.},
address = {Cambridge, MA, USA},
author = {Bobick, Aaron F and Intille, Stephen S and Davis, James W and Baird, Freedom and Pinhanez, Claudio S and Campbell, Lee W and Ivanov, Yuri A and Sch\"{u}tte, Arjan and Wilson, Andrew},
doi = {10.1162/105474699566297},
issn = {1054-7460},
journal = {Presence: Teleoper. Virtual Environ.},
month = aug,
number = {4},
pages = {369--393},
publisher = {MIT Press},
title = {{The KidsRoom: A Perceptually-Based Interactive and Immersive Story Environment}},
volume = {8},
year = {1999}
}
@inproceedings{Forlines:2005:GNI:1056808.1056920,
abstract = {We describe a technique that supports the previewing of navigation, exploration, and editing operations by providing convenient Undo for unsuccessful and/or undesirable actions on multi-level input devices such as touch screens and pen-based computers. By adding a Glimpse state to traditional three-state pressure sensitive input devices, users are able to preview the effects of their editing without committing to them. From this Glimpse state, users can undo their action as easily as they can commit to it, making Glimpse most appropriate for systems in which the user is likely to try out many variations of an edit before finding the right one. Exploration is encouraged as the cumbersome returning to a menu or keyboard to issue an Undo command is eliminated. Glimpse has the added benefits that the negative effects of inconsistencies in the Undo feature within an application are reduced.},
address = {New York, NY, USA},
author = {Forlines, Clifton and Shen, Chia and Buxton, Bill},
booktitle = {CHI '05 Extended Abstracts on Human Factors in Computing Systems},
doi = {10.1145/1056808.1056920},
isbn = {1-59593-002-7},
keywords = { navigation, pressure sensitive input, stylus, three-state input, touch screens, undo,direct manipulation},
pages = {1375--1378},
publisher = {ACM},
series = {CHI EA '05},
title = {{Glimpse: a novel input model for multi-level devices}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1056808.1056920},
year = {2005}
}
@inproceedings{Hinckley:2005:DAD:1054972.1055035,
abstract = {We present a quantitative analysis of delimiters for pen gestures. A delimiter is "something different" in the input stream that a computer can use to determine the structure of input phrases. We study four techniques for delimiting a selection-action gesture phrase consisting of lasso selection plus marking-menu-based command activation. Pigtail is a new technique that uses a small loop to delimit lasso selection from marking (Fig. 1). Handle adds a box to the end of the lasso, from which the user makes a second stroke for marking. Timeout uses dwelling with the pen to delimit the lasso from the mark. Button uses a button press to signal when to delimit the gesture. We describe the role of delimiters in our Scriboli pen interaction testbed, and show how Pigtail supports scope selection, command activation, and direct manipulation all in a single fluid pen gesture.},
address = {New York, NY, USA},
author = {Hinckley, Ken and Baudisch, Patrick and Ramos, Gonzalo and Guimbretiere, Francois},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1054972.1055035},
isbn = {1-58113-998-5},
keywords = { gestures, marking, pen input, tablets,delimiters},
pages = {451--460},
publisher = {ACM},
series = {CHI '05},
title = {{Design and analysis of delimiters for selection-action pen gesture phrases in scriboli}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1054972.1055035},
year = {2005}
}
