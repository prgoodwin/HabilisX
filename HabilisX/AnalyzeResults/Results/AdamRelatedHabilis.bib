@inproceedings{Yamazaki:2007:DTU:1772490.1772524,
abstract = {The purpose of this study is to develop an approach to artifacts design based on information technology. To make interactive system easy to use, user centered design approach is utilized by many systems. For user centered design, it is important to consider total user experience. But it is not easy to consider total user experience because user experience is including many aspects. To approach total user experience, the author proposes the method of designing for user experience that consist of "User viewpoint", "Environment viewpoint" and "Lifecycle viewpoint". "User viewpoint" is including several user groups from universal design viewpoint, several user characters and several user emotions. "Environment viewpoint" is including hardware product, software, application, space, people who is communicating. "Lifecycle viewpoint" is including pre sales, after sales, support, upgrade, setup product and application. To help this design approach, user experience design tool named "UED (User Experience Design) Studio" was proposed. Based on proposed three approaches, design tools were developed such as "The definition tool", "The evaluation tool" and "The visualization tool" for user experience design. To define user experience situation easily, "The definition tool" helps designer such selecting user group, selecting environment and input user tasks based on life cycle state. "The evaluation tool" is to evaluate defined user experience easily. And "The visualization tool" is to show the result of evaluation by 3 D graphics easy to understand complicated information. To evaluate proposed tools, experiment to make prototype was conducted and the results indicate that the proposed approach has possibility to help designer and multi-disciplinary team to consider user experience for user centered design.},
address = {Berlin, Heidelberg},
author = {Yamazaki, Kazuhiko and Furuta, Kazuo},
booktitle = {Proceedings of the 12th international conference on Human-computer interaction: interaction design and usability},
isbn = {978-3-540-73104-7},
pages = {298--307},
publisher = {Springer-Verlag},
series = {HCI'07},
title = {{Design tools for user experience design}},
year = {2007}
}
@inproceedings{Vogt:2004:MST:1186223.1186268,
abstract = {Many conventional whole-hand input devices capture interaction by means of non-contact methods or through some physical medium. Such physical interfaces often involve contact of the hands and fingers with a hard, unyielding surface. In this sketch, we propose an input device that captures whole-hand input through a malleable medium. Its deformability and inherent feedback characteristics make it suitable for sculpting and molding applications.},
address = {New York, NY, USA},
author = {Vogt, Florian and Chen, Timothy and Hoskinson, Reynald and Fels, Sidney},
booktitle = {ACM SIGGRAPH 2004 Sketches},
doi = {10.1145/1186223.1186268},
isbn = {1-58113-896-2},
pages = {36----},
publisher = {ACM},
series = {SIGGRAPH '04},
title = {{A malleable surface touch interface}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1186223.1186268},
year = {2004}
}
@inproceedings{Shen:2007:CTE:1784297.1784317,
abstract = {Making the interactions with a digital user interface disappears into and becomes a part of the human to human interaction and conversation is a challenge. Conventional metaphor and underlying interface infrastructure for single-user desktop systems have been traditionally geared towards single mouse and keyboard, click-and-type based, WIMP interface design. On the other hand, people usually meet in social context around a table, facing each other. A table setting provides a large interactive visual and tangible surface. It affords and encourages collaboration, coordination, serendipity, as well as simultaneous and parallel interaction among multiple people. In this paper, we examine and explore the opportunities, challenges, research issues, pitfalls, and plausible approaches for enabling direct touchable, shared social interactions on multi-touch multi-user tabletops.},
address = {Berlin, Heidelberg},
author = {Shen, Chia},
booktitle = {Proceedings of the 2nd international conference on Online communities and social computing},
isbn = {978-3-540-73256-3},
pages = {169--175},
publisher = {Springer-Verlag},
series = {OCSC'07},
title = {{From clicks to touches: enabling face-to-face shared social interface on multi-touch tabletops}},
url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1784297.1784317},
year = {2007}
}
@inproceedings{Robertson:2000:TGW:332040.332482,
abstract = {The Task Gallery is a window manager that uses interactive 3D graphics to provide direct support for task management and document comparison, lacking from many systems implementing the desktop metaphor. User tasks appear as artwork hung on the walls of a virtual art gallery, with the selected task on a stage. Multiple documents can be selected and displayed side-by-side using 3D space to provide uniform and intuitive scaling. The Task Gallery hosts any Windows application, using a novel redirection mechanism that routes input and output between the 3D environment and unmodified 2D Windows applications. User studies suggest that the Task Gallery helps with task management, is enjoyable to use, and that the 3D metaphor evokes spatial memory and cognition.},
address = {New York, NY, USA},
author = {Robertson, George and van Dantzich, Maarten and Robbins, Daniel and Czerwinski, Mary and Hinckley, Ken and Risden, Kirsten and Thiel, David and Gorokhovsky, Vadim},
booktitle = {Proceedings of the SIGCHI conference on Human Factors in Computing Systems},
doi = {10.1145/332040.332482},
isbn = {1-58113-216-6},
keywords = { spatial cognition, spatial memory, window managers,3D user interfaces},
pages = {494--501},
publisher = {ACM},
series = {CHI '00},
title = {{The Task Gallery: a 3D window manager}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/332040.332482},
year = {2000}
}
@inproceedings{Robertson:1998:DMU:288392.288596,
abstract = {Effective management of documents on computers has been a central user interface problem for many years. One common approach involves using 2D spatial layouts of icons representing the documents, particularly for information workspace tasks. This approach takes advantage of human 2D spatial cognition. More recently, several 3D spatial layouts have engaged 3D spatial cognition capabilities. Some have attempted to use spatial memory in 3D virtual environments. However, there has been no proof to date that spatial memory works the same way in 3D virtual environments as it does in the real world. We describe a new technique for document management called the Data Mountain, which allows users to place documents at arbitrary positions on an inclined plane in a 3D desktop virtual environment using a simple 2D interaction technique. We discuss how the design evolved in response to user feedback. We also describe a user study that shows that the Data Mountain does take advantage of spatial memory. Our study shows that the Data Mountain has statistically reliable advantages over the Microsoft Internet Explorer Favorites mechanism for managing documents of interest in an information workspace.},
address = {New York, NY, USA},
author = {Robertson, George and Czerwinski, Mary and Larson, Kevin and Robbins, Daniel C and Thiel, David and van Dantzich, Maarten},
booktitle = {Proceedings of the 11th annual ACM symposium on User interface software and technology},
doi = {10.1145/288392.288596},
isbn = {1-58113-034-1},
keywords = { desktop VR, document mangement, information visualization, spatial cognition, spatial memory,3D user interfaces},
pages = {153--162},
publisher = {ACM},
series = {UIST '98},
title = {{Data mountain: using spatial memory for document management}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/288392.288596},
year = {1998}
}
@inproceedings{Ramos:2004:PW:985692.985754,
abstract = {Current user interface widgets typically assume that the input device can only provide x-y position and binary button press information. Other inputs such as the continuous pressure data provided by styluses on tablets are rarely used. We explore the design space of using the continuous pressure sensing capabilities of styluses to operate multi-state widgets. We present the results of a controlled experiment that investigates human ability to perform discrete target selection tasks by varying a stylus' pressure, with full or partial visual feedback. The experiment also considers different techniques for confirming selection once the target is acquired. Based on the experimental results, we discuss implications for the design of pressure sensitive widgets. A taxonomy of pressure widgets is presented, along with a set of initial concept sketches of various pressure widget designs.},
address = {New York, NY, USA},
author = {Ramos, Gonzalo and Boulos, Matthew and Balakrishnan, Ravin},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/985692.985754},
isbn = {1-58113-702-8},
keywords = { pen-based interfaces, pressure input, pressure widgets,isometric input},
pages = {487--494},
publisher = {ACM},
series = {CHI '04},
title = {{Pressure widgets}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/985692.985754},
year = {2004}
}
@article{Piattini:1997:ALM:263244.263268,
abstract = {This paper addresses the application of the STUDIO (STructured User-interface Design for Interaction Optimization) method to the user-interface development of an information system (called "HIMPPA") that allows the simulation of heavy-particle dispersion. This method has been proposed in 1994 by D.P. Browne. We have adapted and integrated it with an object-oriented design technique for the HIMPPA project (an ESPRIT-PASO Special Action).},
address = {New York, NY, USA},
author = {Piattini, Mario G and Tigr\'{e}at, Herv\'{e}},
doi = {10.1145/263244.263268},
issn = {0163-5948},
journal = {SIGSOFT Softw. Eng. Notes},
keywords = { design method, interface-design,STUDIO},
month = jul,
number = {4},
pages = {81--83},
publisher = {ACM},
title = {{Applying the 'STUDIO' method to the interface design of an environmental software system}},
volume = {22},
year = {1997}
}
@inproceedings{Oehl:2007:CET:1766451.1766469,
abstract = {The limited screen space in small technical devices imposes considerable usability challenges. On the one hand objects displayed on small screens should be big enough to be hit successfully, but also small enough to house several objects on the screen at the same time. However, findings up to now show that single pointing is more effective in a large display compared to a smaller display. In the present experiment this was also confirmed for an applied multidirectional serial pointing task. Especially in more difficult tasks, results point at a shift of the speed-accuracy tradeoff. In large displays a fast and comparably accurate execution is chosen in contrast to a very inaccurate and time-consuming style in small displays. From an ergonomic point of view the outcomes recommend an optimized balance of task difficulty and display size in small screen devices.},
address = {Berlin, Heidelberg},
author = {Oehl, Michael and Sutter, Christine and Ziefle, Martina},
booktitle = {Proceedings of the 2007 conference on Human interface: Part I},
isbn = {978-3-540-73344-7},
keywords = { pointing performance, small screen device, task difficulty, touch input,display size},
pages = {136--143},
publisher = {Springer-Verlag},
title = {{Considerations on efficient touch interfaces: how display size influences the performance in an applied pointing task}},
url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1766451.1766469},
year = {2007}
}
@inproceedings{Nacenta:2006:PCP:1124772.1124817,
abstract = {Multi-display environments and smart meeting rooms are now becoming more common. These environments build a shared display space from variety of devices: tablets, projected surfaces, tabletops, and traditional monitors. Since the different display surfaces are usually not organized in a single plane, traditional schemes for stitching the displays together can cause problems for interaction. However, there is a more natural way to compose display space -- using perspective. In this paper, we develop interaction techniques for multi-display environments that are based on the user's perspective on the room. We designed the Perspective Cursor, a mapping of cursor to display space that appears natural and logical from wherever the user is located. We conducted an experiment to compare two perspective-based techniques, the Perspective Cursor and a beam-based technique, with traditional stitched displays. We found that both perspective techniques were significantly faster for targeting tasks than the traditional technique, and that Perspective Cursor was the most preferred method. Our results show that integrating perspective into the design of multi-display environments can substantially improve performance.},
address = {New York, NY, USA},
author = {Nacenta, Miguel A and Sallam, Samer and Champoux, Bernard and Subramanian, Sriram and Gutwin, Carl},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1124772.1124817},
isbn = {1-59593-372-7},
keywords = { laser pointing, multi-display interaction techniques, multi-monitor environments,direct-manipulation interfaces},
pages = {289--298},
publisher = {ACM},
series = {CHI '06},
title = {{Perspective cursor: perspective-based interaction for multi-display environments}},
year = {2006}
}
@inproceedings{Motamedi:2007:KTT:1226969.1226974,
abstract = {We present an overview of Keep in Touch, a networked fabric touchscreen designed to support and maintain intimacy for couples in long distance relationships. To achieve this, a novel sensorial interface was created by combining the visual and tactile senses together. Each partner is presented with a blurred digital projection of their lover. When they touch their partner's body, the image comes into focus revealing their features. We describe how this sensory mapping creates an expressive and emotional interface allowing couples to communicate through touch, gestures, and body language.},
address = {New York, NY, USA},
author = {Motamedi, Nima},
booktitle = {Proceedings of the 1st international conference on Tangible and embedded interaction},
doi = {10.1145/1226969.1226974},
isbn = {978-1-59593-619-6},
keywords = { sensorial interfaces, sensory mapping, tactile,intimacy},
pages = {21--22},
publisher = {ACM},
series = {TEI '07},
title = {{Keep in touch: a tactile-vision intimate interface}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1226969.1226974},
year = {2007}
}
@inproceedings{Matulic:2007:TST:1284420.1284448,
abstract = {The system described in this paper attempts to tackle the problem of finding online content based on paper documents through an intuitive touchscreen interface designed for modern scanners and multifunction printers. Touch Scan-n-Search allows the user to select elements of a scanned document (e.g. a newspaper article) and to seamlessly connect to common web search services in order to retrieve the online version of the document along with related content. This is achieved by automatically extracting keyphrases from text elements in the document (obtained by OCR) and creating "tappable" GUI widgets to allow the user to control and fine-tune the search requests. The retrieved content can then be printed, sent, or used to compose new documents.},
address = {New York, NY, USA},
author = {Matulic, Fabrice},
booktitle = {Proceedings of the 2007 ACM symposium on Document engineering},
doi = {10.1145/1284420.1284448},
isbn = {978-1-59593-776-6},
keywords = { keyword extraction, online news retrieval, scanned document,GUI},
pages = {97--98},
publisher = {ACM},
series = {DocEng '07},
title = {{Touch scan-n-search: a touchscreen interface to retrieve online versions of scanned documents}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1284420.1284448},
year = {2007}
}
@inproceedings{Mander:1992:LMS:142750.143055,
abstract = {A user study was conducted to investigate how people deal with the flow of information in their workspaces. Subjects reported that, in an attempt to quickly and informally manage their information, they created piles of documents. Piles were seen as complementary to the folder filing system, which was used for more formal archiving. A new desktop interface element–the pile– was developed and prototyped through an iterative process. The design includes direct manipulation techniques and support for browsing, and goes beyond physical world functionality by providing system assistance for automatic pile construction and reorganization. Preliminary user tests indicate the design is promising and raise issues that will be addressed in future work.},
address = {New York, NY, USA},
author = {Mander, Richard and Salomon, Gitta and Wong, Yin Yin},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/142750.143055},
isbn = {0-89791-513-5},
keywords = { desktop metaphor, end-user programming, information organization, information visualization, interactive systems, interface design, interface metaphors, pile metaphor, user observation,design process},
pages = {627--634},
publisher = {ACM},
series = {CHI '92},
title = {{A 'pile' metaphor for supporting casual organization of information}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/142750.143055},
year = {1992}
}
@article{Malone:1983:POD:357423.357430,
abstract = {This paper describes a series of interviews focusing on the way professional and clerical office workers organize the information in their desks and offices. A number of implications for designing \&quot;natural\&quot; and convenient computer-based information systems are discussed. Two principal claims are made: (1) A very important function of desk organization is to remind the user of things to do, not just to help the user find desired information. Failing to support this function may seriously impair the usefulness of electronic office systems, and explicitly facilitating it may provide an important advantage for automated office systems over their nonautomated predecessors. (2) The cognitive difficulty of categorizing information is an important factor in explaining how people organize their desks. Computer-based systems may help with this difficulty by (a) doing as much automatic classification as possible (e.g., based on access dates},
address = {New York, NY, USA},
author = {Malone, Thomas W},
doi = {10.1145/357423.357430},
issn = {1046-8188},
journal = {ACM Trans. Inf. Syst.},
month = jan,
number = {1},
pages = {99--112},
publisher = {ACM},
title = {{How do people organize their desks?: Implications for the design of office information systems}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/357423.357430},
volume = {1},
year = {1983}
}
@inproceedings{Kristensson:2008:IEM:1463160.1463227,
abstract = {We report on a design exploration into how a large multi-touch tabletop display can be used for information visualization. We designed an interface where users explored a tagged photo collection by bi-manual manipulation of the collections' tag cloud. User feedback showed that despite the availability of multi-touch most of the actual interactions were single-touch. However, some particular natural actions, such as grabbing the tag cloud and partitioning it into two parts, were often carried with both hands. Thus our user study indicates that multi-touch can act as a useful complementary interaction method in information visualization interfaces.},
address = {New York, NY, USA},
author = {Kristensson, Per Ola and Arnell, Olof and Bj\"{o}rk, Annelie and Dahlb\"{a}ck, Nils and Pennerup, Joackim and Prytz, Erik and Wikman, Johan and $\backslash$AAstr\"{o}m, Niclas},
booktitle = {Proceedings of the 5th Nordic conference on Human-computer interaction: building bridges},
doi = {10.1145/1463160.1463227},
isbn = {978-1-59593-704-9},
keywords = { interaction surfaces, multi-touch, photo browsing, photo collections, tag clouds, tagging, tags, visualization,information visualization},
pages = {491--494},
publisher = {ACM},
series = {NordiCHI '08},
title = {{InfoTouch: an explorative multi-touch visualization interface for tagged photo collections}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1463160.1463227},
year = {2008}
}
@inproceedings{Jin:2007:TSU:1766311.1766419,
abstract = {This study investigated the optimal button size and spacing for touch screen user interfaces intended for use by older adults. Current recommendations in the literature are aimed at general audiences and fail to consider the specific needs of older adults. Three independent variables, button size, button spacing, and manual dexterity were studied in two experiments that measured reaction time, accuracy and user preferences. Design recommendations for touch screen button size and spacing for older adults are stated based on these experiments. The paper also discusses the role of manual dexterity in designing appropriate touch screen interfaces for older adults.},
address = {Berlin, Heidelberg},
author = {Jin, Zhao Xia and Plocher, Tom and Kiff, Liana},
booktitle = {Proceedings of the 4th international conference on Universal access in human computer interaction: coping with diversity},
isbn = {978-3-540-73278-5},
keywords = { touch screen, usability, user interface design,older adults},
pages = {933--941},
publisher = {Springer-Verlag},
series = {UAHCI'07},
title = {{Touch screen user interfaces for older adults: button size and spacing}},
url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1766311.1766419},
year = {2007}
}
@inproceedings{Hinckley:2005:DAD:1054972.1055035,
abstract = {We present a quantitative analysis of delimiters for pen gestures. A delimiter is "something different" in the input stream that a computer can use to determine the structure of input phrases. We study four techniques for delimiting a selection-action gesture phrase consisting of lasso selection plus marking-menu-based command activation. Pigtail is a new technique that uses a small loop to delimit lasso selection from marking (Fig. 1). Handle adds a box to the end of the lasso, from which the user makes a second stroke for marking. Timeout uses dwelling with the pen to delimit the lasso from the mark. Button uses a button press to signal when to delimit the gesture. We describe the role of delimiters in our Scriboli pen interaction testbed, and show how Pigtail supports scope selection, command activation, and direct manipulation all in a single fluid pen gesture.},
address = {New York, NY, USA},
author = {Hinckley, Ken and Baudisch, Patrick and Ramos, Gonzalo and Guimbretiere, Francois},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1054972.1055035},
isbn = {1-58113-998-5},
keywords = { gestures, marking, pen input, tablets,delimiters},
pages = {451--460},
publisher = {ACM},
series = {CHI '05},
title = {{Design and analysis of delimiters for selection-action pen gesture phrases in scriboli}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1054972.1055035},
year = {2005}
}
@inproceedings{Herndon:1992:IS:142621.142622,
abstract = {It is often difficult in computer graphics applications to understand spatial relationships between objects in a 3D scene or effect changes to those objects without specialized visualization and manipulation techniques. We present a set of three-dimensional tools (widgets) called “shadows” that not only provide valuable perceptual cues about the spatial relationships between objects, but also provide a direct manipulation interface to constrained transformation techniques. These shadow widgets provide two advances over previous techniques. First, they provide high correlation between their own geometric feedback and their effects on the objects they control. Second, unlike some other 3D widgets, they do not obscure the objects they control.},
address = {New York, NY, USA},
author = {Herndon, Kenneth P and Zeleznik, Robert C and Robbins, Daniel C and Conner, D Brookshire and Snibbe, Scott S and van Dam, Andries},
booktitle = {Proceedings of the 5th annual ACM symposium on User interface software and technology},
doi = {10.1145/142621.142622},
isbn = {0-89791-549-6},
keywords = { direct manipulation, interactive systems,3D widgets},
pages = {1--6},
publisher = {ACM},
series = {UIST '92},
title = {{Interactive shadows}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/142621.142622},
year = {1992}
}
@inproceedings{Fitzmaurice:2003:TM:964696.964704,
abstract = {We describe a new type of graphical user interface widget, known as a "tracking menu." A tracking menu consists of a cluster of graphical buttons, and as with traditional menus, the cursor can be moved within the menu to select and interact with items. However, unlike traditional menus, when the cursor hits the edge of the menu, the menu moves to continue tracking the cursor. Thus, the menu always stays under the cursor and close at hand.In this paper we define the behavior of tracking menus, show unique affordances of the widget, present a variety of examples, and discuss design characteristics. We examine one tracking menu design in detail, reporting on usability studies and our experience integrating the technique into a commercial application for the Tablet PC. While user interface issues on the Tablet PC, such as preventing round trips to tool palettes with the pen, inspired tracking menus, the design also works well with a standard mouse and keyboard configuration.},
address = {New York, NY, USA},
author = {Fitzmaurice, George and Khan, Azam and Piek\'{e}, Robert and Buxton, Bill and Kurtenbach, Gordon},
booktitle = {Proceedings of the 16th annual ACM symposium on User interface software and technology},
doi = {10.1145/964696.964704},
isbn = {1-58113-636-6},
keywords = { graphical user interface, menu system, pen based user interfaces, tablet PC,floating palette},
pages = {71--79},
publisher = {ACM},
series = {UIST '03},
title = {{Tracking menus}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/964696.964704},
year = {2003}
}
@inproceedings{Findlater:2008:ISS:1357054.1357249,
abstract = {Adaptive personalization, where the system adapts the interface to a user's needs, has the potential for significant performance benefits on small screen devices. However, research on adaptive interfaces has almost exclusively focused on desktop displays. To explore how well previous findings generalize to small screen devices, we conducted a study with 36 subjects to compare adaptive interfaces for small and desktop-sized screens. Results show that high accuracy adaptive menus have an even larger positive impact on performance and satisfaction when screen real estate is constrained. The drawback of the high accuracy menus, however, is that they reduce the user's awareness of the full set of items in the interface, potentially making it more difficult for users to learn about new features.},
address = {New York, NY, USA},
author = {Findlater, Leah and McGrenere, Joanna},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1357054.1357249},
isbn = {978-1-60558-011-1},
keywords = { interaction techniques, menu design, personalization, small screen devices, user study,adaptive interfaces},
pages = {1247--1256},
publisher = {ACM},
series = {CHI '08},
title = {{Impact of screen size on performance, awareness, and user satisfaction with adaptive graphical user interfaces}},
year = {2008}
}
@misc{CzerwinskiMaryP.;DantzichMaartenvan;RobertsonGeorge;Hoffman1999,
abstract = {We present an empirical evaluation of the contribution of pictorial image and spatial location information on the retrieval of previously stored web pages. Subjects were given 100 snapshots of web pages that they stored in spatial locations on an inclined plane in a desktop 3D environment (Data Mountain). We had them return and try to retrieve their pages again, using a variety of retrieval cues. Even though users had not seen their web page layout for several months, their retrieval times were not significantly slower. In addition, on half of the trials, stored pages were not presented as thumbnail images of the web pages but as blank icons. Taking the pictorial thumbnail images away initially led to a significant drop in subjects’ ability to find the pages, although within a short period of time subjects were able to find the pages equally fast without the thumbnail information. These results indicate that the use of 3D visualization techniques such as those described in this paper can lead to improved user memory for where favorite or frequently used information is stored in an electronic environment.},
author = {{Czerwinski, Mary P.; Dantzich, Maarten van; Robertson, George; Hoffman}, Hunter},
booktitle = {Press},
keywords = {3D information visualization,information retrieva,information retrieval,spatial location memory,thumbnail images},
pages = {163--170},
title = {{The Contribution of Thumbnail Image, Mouse-over Text and Spatial Location Memory to Web Page Retrieval in 3D}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=94E9B4093AC910B2FD215A3EA65E04D8?doi=10.1.1.33.774\&rep=rep1\&type=pdf},
year = {1999}
}
@inproceedings{Bharath:2008:FNH:1378773.1378814,
abstract = {The last decade has seen tremendous growth in mobile devices such as Pocket PCs, mobile phones, Tablet PCs and notebooks. Most of these devices enable interaction through a stylus or touch interface, powered by handwriting recognition (HWR) capability. In this paper, we propose a novel input method that addresses some of the issues that arise due to the constraints posed by these devices in accepting handwriting input. For instance, many of the devices have a small writing area making "continuous" input difficult if not impossible, and the process of handwriting input demands significant user attention. The proposed solution is inspired by touch-typing, and appreciably reduces user's effort in the interaction, and it is especially suited for very small writing areas. The approach has been demonstrated using a prototype system that recognizes handwritten English words, and its accuracy has been evaluated using a standard dataset of handwritten words. A preliminary user study has also been carried out to understand user acceptance of the proposed technique.},
address = {New York, NY, USA},
author = {Bharath, A and Madhvanath, Sriganesh},
booktitle = {Proceedings of the 13th international conference on Intelligent user interfaces},
doi = {10.1145/1378773.1378814},
isbn = {978-1-59593-987-6},
keywords = { pen and touch interfaces, text input,handwriting recognition},
pages = {297--300},
publisher = {ACM},
series = {IUI '08},
title = {{FreePad: a novel handwriting-based text input for pen and touch interfaces}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1378773.1378814},
year = {2008}
}
@inproceedings{Bederson:1994:PZG:192426.192435,
abstract = {We describe the current status of Pad++, a zooming graphical interface that we are exploring as an alternative to traditional window and icon-based approaches to interface design. We discuss the motivation for Pad++, describe the implementation, and present prototype applications. In addition, we introduce an informational physics strategy for interface design and briefly compare it with metaphor-based design strategies.},
address = {New York, NY, USA},
author = {Bederson, Benjamin B and Hollan, James D},
booktitle = {Proceedings of the 7th annual ACM symposium on User interface software and technology},
doi = {10.1145/192426.192435},
isbn = {0-89791-657-3},
keywords = { hypertext, information navigation, information physics, information visualization, interactive user interfaces, multiscale interfaces, zooming interfaces,authoring},
pages = {17--26},
publisher = {ACM},
series = {UIST '94},
title = {{Pad++: a zooming graphical interface for exploring alternate interface physics}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/192426.192435},
year = {1994}
}
@inproceedings{Bauer:2004:CPM:1032665.1034569,
abstract = {We explore and extend the metaphor of "piles" to include computationally-enriched piles, portable regions of automation in Dynapad, a multiscale workspace. We describe these collection-management tools and how their design was informed by observing people organizing collections of personal digital photographs.},
address = {Washington, DC, USA},
author = {Bauer, Dan and Fastrez, Pierre and Hollan, Jim},
booktitle = {Proceedings of the 2004 IEEE Symposium on Visual Languages - Human Centric Computing},
doi = {10.1109/VLHCC.2004.13},
isbn = {0-7803-8696-5},
pages = {193--195},
publisher = {IEEE Computer Society},
series = {VLHCC '04},
title = {{Computationally-Enriched 'Piles' for Managing Digital Photo Collections}},
url = {http://dx.doi.org.prox.lib.ncsu.edu/10.1109/VLHCC.2004.13},
year = {2004}
}
@inproceedings{Accot:2002:MDF:503376.503390,
abstract = {Today's graphical interactive systems largely depend upon pointing actions, i.e. entering an object and selecting it. In this paper we explore whether an alternate paradigm --- crossing boundaries --- may substitute or complement pointing as another fundamental interaction method. We describe an experiment in which we systematically evaluate two target-pointing tasks and four goal-crossing tasks, which differ by the direction of the movement variability constraint (collinear vs. orthogonal) and by the nature of the action (pointing vs. crossing, discrete vs. continuous). We found that participants' temporal performance in each of the six tasks was dependent on the index of difficulty formulated in the same way as in Fitts' law, but that the parameters differ by task. We also found that goal crossing completion time was shorter or no longer than pointing performance under the same index of difficulty. These regularities, as well as qualitative characterizations of crossing actions and their application in HCI, lay the foundation for designing crossing-based user interfaces.},
address = {New York, NY, USA},
author = {Accot, Johnny and Zhai, Shumin},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/503376.503390},
isbn = {1-58113-453-3},
keywords = { events, goal crossing, goal passing, graphical user interfaces, input, input performance, interaction techniques, pointing, widgets,Fitts' law},
pages = {73--80},
publisher = {ACM},
series = {CHI '02},
title = {{More than dotting the i's --- foundations for crossing-based interfaces}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/503376.503390},
year = {2002}
}
