@inproceedings{Accot:2002:MDF:503376.503390,
abstract = {Today's graphical interactive systems largely depend upon pointing actions, i.e. entering an object and selecting it. In this paper we explore whether an alternate paradigm --- crossing boundaries --- may substitute or complement pointing as another fundamental interaction method. We describe an experiment in which we systematically evaluate two target-pointing tasks and four goal-crossing tasks, which differ by the direction of the movement variability constraint (collinear vs. orthogonal) and by the nature of the action (pointing vs. crossing, discrete vs. continuous). We found that participants' temporal performance in each of the six tasks was dependent on the index of difficulty formulated in the same way as in Fitts' law, but that the parameters differ by task. We also found that goal crossing completion time was shorter or no longer than pointing performance under the same index of difficulty. These regularities, as well as qualitative characterizations of crossing actions and their application in HCI, lay the foundation for designing crossing-based user interfaces.},
address = {New York, NY, USA},
author = {Accot, Johnny and Zhai, Shumin},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/503376.503390},
isbn = {1-58113-453-3},
keywords = { events, goal crossing, goal passing, graphical user interfaces, input, input performance, interaction techniques, pointing, widgets,Fitts' law},
pages = {73--80},
publisher = {ACM},
series = {CHI '02},
title = {{More than dotting the i's --- foundations for crossing-based interfaces}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/503376.503390},
year = {2002}
}
@inproceedings{Bederson:1994:PZG:192426.192435,
abstract = {We describe the current status of Pad++, a zooming graphical interface that we are exploring as an alternative to traditional window and icon-based approaches to interface design. We discuss the motivation for Pad++, describe the implementation, and present prototype applications. In addition, we introduce an informational physics strategy for interface design and briefly compare it with metaphor-based design strategies.},
address = {New York, NY, USA},
author = {Bederson, Benjamin B and Hollan, James D},
booktitle = {Proceedings of the 7th annual ACM symposium on User interface software and technology},
doi = {10.1145/192426.192435},
isbn = {0-89791-657-3},
keywords = { hypertext, information navigation, information physics, information visualization, interactive user interfaces, multiscale interfaces, zooming interfaces,authoring},
pages = {17--26},
publisher = {ACM},
series = {UIST '94},
title = {{Pad++: a zooming graphical interface for exploring alternate interface physics}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/192426.192435},
year = {1994}
}
@inproceedings{Bell:2001:VMV:502348.502363,
abstract = {We describe a view-management component for interactive 3D user interfaces. By view management, we mean maintaining visual constraints on the projections of objects on the view plane, such as locating related objects near each other, or preventing objects from occluding each other. Our view-management component accomplishes this by modifying selected object properties, including position, size, and transparency, which are tagged to indicate their constraints. For example, some objects may have geometric properties that are determined entirely by a physical simulation and which cannot be modified, while other objects may be annotations whose position and size are flexible.We introduce algorithms that use upright rectangular extents to represent on the view plane a dynamic and efficient approximation of the occupied space containing the projections of visible portions of 3D objects, as well as the unoccupied space in which objects can be placed to avoid occlusion. Layout decisions from previous frames are taken into account to reduce visual discontinuities. We present augmented reality and virtual reality examples to which we have applied our approach, including a dynamically labeled and annotated environment.},
address = {New York, NY, USA},
author = {Bell, Blaine and Feiner, Steven and H\"{o}llerer, Tobias},
booktitle = {Proceedings of the 14th annual ACM symposium on User interface software and technology},
doi = {10.1145/502348.502363},
isbn = {1-58113-438-X},
keywords = { augmented reality, environment management, labeling, view management, virtual environments, wearable computing,annotation},
pages = {101--110},
publisher = {ACM},
series = {UIST '01},
title = {{View management for virtual and augmented reality}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/502348.502363},
year = {2001}
}
@inproceedings{Bharath:2008:FNH:1378773.1378814,
abstract = {The last decade has seen tremendous growth in mobile devices such as Pocket PCs, mobile phones, Tablet PCs and notebooks. Most of these devices enable interaction through a stylus or touch interface, powered by handwriting recognition (HWR) capability. In this paper, we propose a novel input method that addresses some of the issues that arise due to the constraints posed by these devices in accepting handwriting input. For instance, many of the devices have a small writing area making "continuous" input difficult if not impossible, and the process of handwriting input demands significant user attention. The proposed solution is inspired by touch-typing, and appreciably reduces user's effort in the interaction, and it is especially suited for very small writing areas. The approach has been demonstrated using a prototype system that recognizes handwritten English words, and its accuracy has been evaluated using a standard dataset of handwritten words. A preliminary user study has also been carried out to understand user acceptance of the proposed technique.},
address = {New York, NY, USA},
author = {Bharath, A and Madhvanath, Sriganesh},
booktitle = {Proceedings of the 13th international conference on Intelligent user interfaces},
doi = {10.1145/1378773.1378814},
isbn = {978-1-59593-987-6},
keywords = { pen and touch interfaces, text input,handwriting recognition},
pages = {297--300},
publisher = {ACM},
series = {IUI '08},
title = {{FreePad: a novel handwriting-based text input for pen and touch interfaces}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1378773.1378814},
year = {2008}
}
@misc{CzerwinskiMaryP.;DantzichMaartenvan;RobertsonGeorge;Hoffman1999,
abstract = {We present an empirical evaluation of the contribution of pictorial image and spatial location information on the retrieval of previously stored web pages. Subjects were given 100 snapshots of web pages that they stored in spatial locations on an inclined plane in a desktop 3D environment (Data Mountain). We had them return and try to retrieve their pages again, using a variety of retrieval cues. Even though users had not seen their web page layout for several months, their retrieval times were not significantly slower. In addition, on half of the trials, stored pages were not presented as thumbnail images of the web pages but as blank icons. Taking the pictorial thumbnail images away initially led to a significant drop in subjects’ ability to find the pages, although within a short period of time subjects were able to find the pages equally fast without the thumbnail information. These results indicate that the use of 3D visualization techniques such as those described in this paper can lead to improved user memory for where favorite or frequently used information is stored in an electronic environment.},
author = {{Czerwinski, Mary P.; Dantzich, Maarten van; Robertson, George; Hoffman}, Hunter},
booktitle = {Press},
keywords = {3D information visualization,information retrieva,information retrieval,spatial location memory,thumbnail images},
pages = {163--170},
title = {{The Contribution of Thumbnail Image, Mouse-over Text and Spatial Location Memory to Web Page Retrieval in 3D}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=94E9B4093AC910B2FD215A3EA65E04D8?doi=10.1.1.33.774\&rep=rep1\&type=pdf},
year = {1999}
}
@inproceedings{Findlater:2008:ISS:1357054.1357249,
abstract = {Adaptive personalization, where the system adapts the interface to a user's needs, has the potential for significant performance benefits on small screen devices. However, research on adaptive interfaces has almost exclusively focused on desktop displays. To explore how well previous findings generalize to small screen devices, we conducted a study with 36 subjects to compare adaptive interfaces for small and desktop-sized screens. Results show that high accuracy adaptive menus have an even larger positive impact on performance and satisfaction when screen real estate is constrained. The drawback of the high accuracy menus, however, is that they reduce the user's awareness of the full set of items in the interface, potentially making it more difficult for users to learn about new features.},
address = {New York, NY, USA},
author = {Findlater, Leah and McGrenere, Joanna},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1357054.1357249},
isbn = {978-1-60558-011-1},
keywords = { interaction techniques, menu design, personalization, small screen devices, user study,adaptive interfaces},
pages = {1247--1256},
publisher = {ACM},
series = {CHI '08},
title = {{Impact of screen size on performance, awareness, and user satisfaction with adaptive graphical user interfaces}},
year = {2008}
}
@inproceedings{Fitzmaurice:2003:TM:964696.964704,
abstract = {We describe a new type of graphical user interface widget, known as a "tracking menu." A tracking menu consists of a cluster of graphical buttons, and as with traditional menus, the cursor can be moved within the menu to select and interact with items. However, unlike traditional menus, when the cursor hits the edge of the menu, the menu moves to continue tracking the cursor. Thus, the menu always stays under the cursor and close at hand.In this paper we define the behavior of tracking menus, show unique affordances of the widget, present a variety of examples, and discuss design characteristics. We examine one tracking menu design in detail, reporting on usability studies and our experience integrating the technique into a commercial application for the Tablet PC. While user interface issues on the Tablet PC, such as preventing round trips to tool palettes with the pen, inspired tracking menus, the design also works well with a standard mouse and keyboard configuration.},
address = {New York, NY, USA},
author = {Fitzmaurice, George and Khan, Azam and Piek\'{e}, Robert and Buxton, Bill and Kurtenbach, Gordon},
booktitle = {Proceedings of the 16th annual ACM symposium on User interface software and technology},
doi = {10.1145/964696.964704},
isbn = {1-58113-636-6},
keywords = { graphical user interface, menu system, pen based user interfaces, tablet PC,floating palette},
pages = {71--79},
publisher = {ACM},
series = {UIST '03},
title = {{Tracking menus}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/964696.964704},
year = {2003}
}
@inproceedings{Hinckley:2005:DAD:1054972.1055035,
abstract = {We present a quantitative analysis of delimiters for pen gestures. A delimiter is "something different" in the input stream that a computer can use to determine the structure of input phrases. We study four techniques for delimiting a selection-action gesture phrase consisting of lasso selection plus marking-menu-based command activation. Pigtail is a new technique that uses a small loop to delimit lasso selection from marking (Fig. 1). Handle adds a box to the end of the lasso, from which the user makes a second stroke for marking. Timeout uses dwelling with the pen to delimit the lasso from the mark. Button uses a button press to signal when to delimit the gesture. We describe the role of delimiters in our Scriboli pen interaction testbed, and show how Pigtail supports scope selection, command activation, and direct manipulation all in a single fluid pen gesture.},
address = {New York, NY, USA},
author = {Hinckley, Ken and Baudisch, Patrick and Ramos, Gonzalo and Guimbretiere, Francois},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1054972.1055035},
isbn = {1-58113-998-5},
keywords = { gestures, marking, pen input, tablets,delimiters},
pages = {451--460},
publisher = {ACM},
series = {CHI '05},
title = {{Design and analysis of delimiters for selection-action pen gesture phrases in scriboli}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1054972.1055035},
year = {2005}
}
@inproceedings{Jin:2007:TSU:1766311.1766419,
abstract = {This study investigated the optimal button size and spacing for touch screen user interfaces intended for use by older adults. Current recommendations in the literature are aimed at general audiences and fail to consider the specific needs of older adults. Three independent variables, button size, button spacing, and manual dexterity were studied in two experiments that measured reaction time, accuracy and user preferences. Design recommendations for touch screen button size and spacing for older adults are stated based on these experiments. The paper also discusses the role of manual dexterity in designing appropriate touch screen interfaces for older adults.},
address = {Berlin, Heidelberg},
author = {Jin, Zhao Xia and Plocher, Tom and Kiff, Liana},
booktitle = {Proceedings of the 4th international conference on Universal access in human computer interaction: coping with diversity},
isbn = {978-3-540-73278-5},
keywords = { touch screen, usability, user interface design,older adults},
pages = {933--941},
publisher = {Springer-Verlag},
series = {UAHCI'07},
title = {{Touch screen user interfaces for older adults: button size and spacing}},
url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1766311.1766419},
year = {2007}
}
@inproceedings{Kristensson:2008:IEM:1463160.1463227,
abstract = {We report on a design exploration into how a large multi-touch tabletop display can be used for information visualization. We designed an interface where users explored a tagged photo collection by bi-manual manipulation of the collections' tag cloud. User feedback showed that despite the availability of multi-touch most of the actual interactions were single-touch. However, some particular natural actions, such as grabbing the tag cloud and partitioning it into two parts, were often carried with both hands. Thus our user study indicates that multi-touch can act as a useful complementary interaction method in information visualization interfaces.},
address = {New York, NY, USA},
author = {Kristensson, Per Ola and Arnell, Olof and Bj\"{o}rk, Annelie and Dahlb\"{a}ck, Nils and Pennerup, Joackim and Prytz, Erik and Wikman, Johan and $\backslash$AAstr\"{o}m, Niclas},
booktitle = {Proceedings of the 5th Nordic conference on Human-computer interaction: building bridges},
doi = {10.1145/1463160.1463227},
isbn = {978-1-59593-704-9},
keywords = { interaction surfaces, multi-touch, photo browsing, photo collections, tag clouds, tagging, tags, visualization,information visualization},
pages = {491--494},
publisher = {ACM},
series = {NordiCHI '08},
title = {{InfoTouch: an explorative multi-touch visualization interface for tagged photo collections}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1463160.1463227},
year = {2008}
}
@inproceedings{Kurtenbach:1991:ICM:120782.120797,
abstract = {The direct manipulation paradigm has been effective in helping designers create easy to use mouse and keyboard based interfaces. The development of flat display surfaces and transparent tablets are now making possible interfaces where a user can write directly on the screen using a special stylus. The intention of these types of interfaces is to exploit user’s existing handwriting, mark-up and drawing skills while also providing the benefits of direct manipulation. This paper reports on a test bed program which we are using for exploring hand-marking types of interactions and their integration with direct manipulation interactions. },
address = {New York, NY, USA},
author = {Kurtenbach, Gordon and Buxton, William},
booktitle = {Proceedings of the 4th annual ACM symposium on User interface software and technology},
doi = {10.1145/120782.120797},
isbn = {0-89791-451-1},
pages = {137--144},
publisher = {ACM},
series = {UIST '91},
title = {{Issues in combining marking and direct manipulation techniques}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/120782.120797},
year = {1991}
}
@article{Malone:1983:POD:357423.357430,
abstract = {This paper describes a series of interviews focusing on the way professional and clerical office workers organize the information in their desks and offices. A number of implications for designing \&quot;natural\&quot; and convenient computer-based information systems are discussed. Two principal claims are made: (1) A very important function of desk organization is to remind the user of things to do, not just to help the user find desired information. Failing to support this function may seriously impair the usefulness of electronic office systems, and explicitly facilitating it may provide an important advantage for automated office systems over their nonautomated predecessors. (2) The cognitive difficulty of categorizing information is an important factor in explaining how people organize their desks. Computer-based systems may help with this difficulty by (a) doing as much automatic classification as possible (e.g., based on access dates},
address = {New York, NY, USA},
author = {Malone, Thomas W},
doi = {10.1145/357423.357430},
issn = {1046-8188},
journal = {ACM Trans. Inf. Syst.},
month = jan,
number = {1},
pages = {99--112},
publisher = {ACM},
title = {{How do people organize their desks?: Implications for the design of office information systems}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/357423.357430},
volume = {1},
year = {1983}
}
@inproceedings{Mander:1992:LMS:142750.143055,
abstract = {A user study was conducted to investigate how people deal with the flow of information in their workspaces. Subjects reported that, in an attempt to quickly and informally manage their information, they created piles of documents. Piles were seen as complementary to the folder filing system, which was used for more formal archiving. A new desktop interface element–the pile– was developed and prototyped through an iterative process. The design includes direct manipulation techniques and support for browsing, and goes beyond physical world functionality by providing system assistance for automatic pile construction and reorganization. Preliminary user tests indicate the design is promising and raise issues that will be addressed in future work.},
address = {New York, NY, USA},
author = {Mander, Richard and Salomon, Gitta and Wong, Yin Yin},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/142750.143055},
isbn = {0-89791-513-5},
keywords = { desktop metaphor, end-user programming, information organization, information visualization, interactive systems, interface design, interface metaphors, pile metaphor, user observation,design process},
pages = {627--634},
publisher = {ACM},
series = {CHI '92},
title = {{A $\backslash$“pile$\backslash$” metaphor for supporting casual organization of information}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/142750.143055},
year = {1992}
}
@inproceedings{Matulic:2007:TST:1284420.1284448,
abstract = {The system described in this paper attempts to tackle the problem of finding online content based on paper documents through an intuitive touchscreen interface designed for modern scanners and multifunction printers. Touch Scan-n-Search allows the user to select elements of a scanned document (e.g. a newspaper article) and to seamlessly connect to common web search services in order to retrieve the online version of the document along with related content. This is achieved by automatically extracting keyphrases from text elements in the document (obtained by OCR) and creating "tappable" GUI widgets to allow the user to control and fine-tune the search requests. The retrieved content can then be printed, sent, or used to compose new documents.},
address = {New York, NY, USA},
author = {Matulic, Fabrice},
booktitle = {Proceedings of the 2007 ACM symposium on Document engineering},
doi = {10.1145/1284420.1284448},
isbn = {978-1-59593-776-6},
keywords = { keyword extraction, online news retrieval, scanned document,GUI},
pages = {97--98},
publisher = {ACM},
series = {DocEng '07},
title = {{Touch scan-n-search: a touchscreen interface to retrieve online versions of scanned documents}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1284420.1284448},
year = {2007}
}
@inproceedings{Motamedi:2007:KTT:1226969.1226974,
abstract = {We present an overview of Keep in Touch, a networked fabric touchscreen designed to support and maintain intimacy for couples in long distance relationships. To achieve this, a novel sensorial interface was created by combining the visual and tactile senses together. Each partner is presented with a blurred digital projection of their lover. When they touch their partner's body, the image comes into focus revealing their features. We describe how this sensory mapping creates an expressive and emotional interface allowing couples to communicate through touch, gestures, and body language.},
address = {New York, NY, USA},
author = {Motamedi, Nima},
booktitle = {Proceedings of the 1st international conference on Tangible and embedded interaction},
doi = {10.1145/1226969.1226974},
isbn = {978-1-59593-619-6},
keywords = { sensorial interfaces, sensory mapping, tactile,intimacy},
pages = {21--22},
publisher = {ACM},
series = {TEI '07},
title = {{Keep in touch: a tactile-vision intimate interface}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1226969.1226974},
year = {2007}
}
@inproceedings{Nacenta:2006:PCP:1124772.1124817,
abstract = {Multi-display environments and smart meeting rooms are now becoming more common. These environments build a shared display space from variety of devices: tablets, projected surfaces, tabletops, and traditional monitors. Since the different display surfaces are usually not organized in a single plane, traditional schemes for stitching the displays together can cause problems for interaction. However, there is a more natural way to compose display space -- using perspective. In this paper, we develop interaction techniques for multi-display environments that are based on the user's perspective on the room. We designed the Perspective Cursor, a mapping of cursor to display space that appears natural and logical from wherever the user is located. We conducted an experiment to compare two perspective-based techniques, the Perspective Cursor and a beam-based technique, with traditional stitched displays. We found that both perspective techniques were significantly faster for targeting tasks than the traditional technique, and that Perspective Cursor was the most preferred method. Our results show that integrating perspective into the design of multi-display environments can substantially improve performance.},
address = {New York, NY, USA},
author = {Nacenta, Miguel A and Sallam, Samer and Champoux, Bernard and Subramanian, Sriram and Gutwin, Carl},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1124772.1124817},
isbn = {1-59593-372-7},
keywords = { laser pointing, multi-display interaction techniques, multi-monitor environments,direct-manipulation interfaces},
pages = {289--298},
publisher = {ACM},
series = {CHI '06},
title = {{Perspective cursor: perspective-based interaction for multi-display environments}},
year = {2006}
}
@inproceedings{Oehl:2007:CET:1766451.1766469,
abstract = {The limited screen space in small technical devices imposes considerable usability challenges. On the one hand objects displayed on small screens should be big enough to be hit successfully, but also small enough to house several objects on the screen at the same time. However, findings up to now show that single pointing is more effective in a large display compared to a smaller display. In the present experiment this was also confirmed for an applied multidirectional serial pointing task. Especially in more difficult tasks, results point at a shift of the speed-accuracy tradeoff. In large displays a fast and comparably accurate execution is chosen in contrast to a very inaccurate and time-consuming style in small displays. From an ergonomic point of view the outcomes recommend an optimized balance of task difficulty and display size in small screen devices.},
address = {Berlin, Heidelberg},
author = {Oehl, Michael and Sutter, Christine and Ziefle, Martina},
booktitle = {Proceedings of the 2007 conference on Human interface: Part I},
isbn = {978-3-540-73344-7},
keywords = { pointing performance, small screen device, task difficulty, touch input,display size},
pages = {136--143},
publisher = {Springer-Verlag},
title = {{Considerations on efficient touch interfaces: how display size influences the performance in an applied pointing task}},
url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1766451.1766469},
year = {2007}
}
@article{Piattini:1997:ALM:263244.263268,
abstract = {This paper addresses the application of the STUDIO (STructured User-interface Design for Interaction Optimization) method to the user-interface development of an information system (called "HIMPPA") that allows the simulation of heavy-particle dispersion. This method has been proposed in 1994 by D.P. Browne. We have adapted and integrated it with an object-oriented design technique for the HIMPPA project (an ESPRIT-PASO Special Action).},
address = {New York, NY, USA},
author = {Piattini, Mario G and Tigr\'{e}at, Herv\'{e}},
doi = {10.1145/263244.263268},
issn = {0163-5948},
journal = {SIGSOFT Softw. Eng. Notes},
keywords = { design method, interface-design,STUDIO},
month = jul,
number = {4},
pages = {81--83},
publisher = {ACM},
title = {{Applying the $\backslash$“STUDIO$\backslash$” method to the interface design of an environmental software system}},
volume = {22},
year = {1997}
}
@inproceedings{Poupyrev:2002:ATD:571985.571993,
abstract = {This paper investigates the sense of touch as a channel for communicating with miniature handheld devices. We embedded a PDA with a TouchEngineTM --- a thin, miniature lower-power tactile actuator that we have designed specifically to use in mobile interfaces (Figure 1). Unlike previous tactile actuators, the TouchEngine is a universal tactile display that can produce a wide variety of tactile feelings from simple clicks to complex vibrotactile patterns. Using the TouchEngine, we began exploring the design space of interactive tactile feedback for handheld computers. Here, we investigated only a subset of this space: using touch as the ambient, background channel of interaction. We proposed a general approach to design such tactile interfaces and described several implemented prototypes. Finally, our user studies demonstrated 22\% faster task completion when we enhanced handheld tilting interfaces with tactile feedback.},
address = {New York, NY, USA},
author = {Poupyrev, Ivan and Maruyama, Shigeaki and Rekimoto, Jun},
booktitle = {Proceedings of the 15th annual ACM symposium on User interface software and technology},
doi = {10.1145/571985.571993},
isbn = {1-58113-488-6},
keywords = { tactile feedback,mobile devices and interfaces},
pages = {51--60},
publisher = {ACM},
series = {UIST '02},
title = {{Ambient touch: designing tactile interfaces for handheld devices}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/571985.571993},
year = {2002}
}
@inproceedings{Ramos:2004:PW:985692.985754,
abstract = {Current user interface widgets typically assume that the input device can only provide x-y position and binary button press information. Other inputs such as the continuous pressure data provided by styluses on tablets are rarely used. We explore the design space of using the continuous pressure sensing capabilities of styluses to operate multi-state widgets. We present the results of a controlled experiment that investigates human ability to perform discrete target selection tasks by varying a stylus' pressure, with full or partial visual feedback. The experiment also considers different techniques for confirming selection once the target is acquired. Based on the experimental results, we discuss implications for the design of pressure sensitive widgets. A taxonomy of pressure widgets is presented, along with a set of initial concept sketches of various pressure widget designs.},
address = {New York, NY, USA},
author = {Ramos, Gonzalo and Boulos, Matthew and Balakrishnan, Ravin},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/985692.985754},
isbn = {1-58113-702-8},
keywords = { pen-based interfaces, pressure input, pressure widgets,isometric input},
pages = {487--494},
publisher = {ACM},
series = {CHI '04},
title = {{Pressure widgets}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/985692.985754},
year = {2004}
}
@inproceedings{Robertson:1998:DMU:288392.288596,
abstract = {Effective management of documents on computers has been a central user interface problem for many years. One common approach involves using 2D spatial layouts of icons representing the documents, particularly for information workspace tasks. This approach takes advantage of human 2D spatial cognition. More recently, several 3D spatial layouts have engaged 3D spatial cognition capabilities. Some have attempted to use spatial memory in 3D virtual environments. However, there has been no proof to date that spatial memory works the same way in 3D virtual environments as it does in the real world. We describe a new technique for document management called the Data Mountain, which allows users to place documents at arbitrary positions on an inclined plane in a 3D desktop virtual environment using a simple 2D interaction technique. We discuss how the design evolved in response to user feedback. We also describe a user study that shows that the Data Mountain does take advantage of spatial memory. Our study shows that the Data Mountain has statistically reliable advantages over the Microsoft Internet Explorer Favorites mechanism for managing documents of interest in an information workspace.},
address = {New York, NY, USA},
author = {Robertson, George and Czerwinski, Mary and Larson, Kevin and Robbins, Daniel C and Thiel, David and van Dantzich, Maarten},
booktitle = {Proceedings of the 11th annual ACM symposium on User interface software and technology},
doi = {10.1145/288392.288596},
isbn = {1-58113-034-1},
keywords = { desktop VR, document mangement, information visualization, spatial cognition, spatial memory,3D user interfaces},
pages = {153--162},
publisher = {ACM},
series = {UIST '98},
title = {{Data mountain: using spatial memory for document management}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/288392.288596},
year = {1998}
}
@book{Sellen:2003:MPO:778158,
address = {Cambridge, MA, USA},
author = {Sellen, Abigail J and Harper, Richard H R},
isbn = {026269283X},
publisher = {MIT Press},
title = {{The Myth of the Paperless Office}},
year = {2003}
}
@inproceedings{Shen:2007:CTE:1784297.1784317,
abstract = {Making the interactions with a digital user interface disappears into and becomes a part of the human to human interaction and conversation is a challenge. Conventional metaphor and underlying interface infrastructure for single-user desktop systems have been traditionally geared towards single mouse and keyboard, click-and-type based, WIMP interface design. On the other hand, people usually meet in social context around a table, facing each other. A table setting provides a large interactive visual and tangible surface. It affords and encourages collaboration, coordination, serendipity, as well as simultaneous and parallel interaction among multiple people. In this paper, we examine and explore the opportunities, challenges, research issues, pitfalls, and plausible approaches for enabling direct touchable, shared social interactions on multi-touch multi-user tabletops.},
address = {Berlin, Heidelberg},
author = {Shen, Chia},
booktitle = {Proceedings of the 2nd international conference on Online communities and social computing},
isbn = {978-3-540-73256-3},
pages = {169--175},
publisher = {Springer-Verlag},
series = {OCSC'07},
title = {{From clicks to touches: enabling face-to-face shared social interface on multi-touch tabletops}},
url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=1784297.1784317},
year = {2007}
}
@inproceedings{Thorne:2004:MDI:1186562.1015740,
abstract = {In this paper we present a novel system for sketching the motion of a character. The process begins by sketching a character to be animated. An animated motion is then created for the character by drawing a continuous sequence of lines, arcs, and loops. These are parsed and mapped to a parameterized set of output motions that further reflect the location and timing of the input sketch. The current system supports a repertoire of 18 different types of motions in 2D and a subset of these in 3D. The system is unique in its use of a cursive motion specification, its ability to allow for fast experimentation, and its ease of use for non-experts.},
address = {New York, NY, USA},
author = {Thorne, Matthew and Burke, David and van de Panne, Michiel},
booktitle = {ACM SIGGRAPH 2004 Papers},
doi = {10.1145/1186562.1015740},
keywords = { Computer Puppetry, Gestural Interfaces, Sketching,Animation},
pages = {424--431},
publisher = {ACM},
series = {SIGGRAPH '04},
title = {{Motion doodles: an interface for sketching character motion}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1186562.1015740},
year = {2004}
}
@inproceedings{Vogt:2004:MST:1186223.1186268,
abstract = {Many conventional whole-hand input devices capture interaction by means of non-contact methods or through some physical medium. Such physical interfaces often involve contact of the hands and fingers with a hard, unyielding surface. In this sketch, we propose an input device that captures whole-hand input through a malleable medium. Its deformability and inherent feedback characteristics make it suitable for sculpting and molding applications.},
address = {New York, NY, USA},
author = {Vogt, Florian and Chen, Timothy and Hoskinson, Reynald and Fels, Sidney},
booktitle = {ACM SIGGRAPH 2004 Sketches},
doi = {10.1145/1186223.1186268},
isbn = {1-58113-896-2},
pages = {36----},
publisher = {ACM},
series = {SIGGRAPH '04},
title = {{A malleable surface touch interface}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/1186223.1186268},
year = {2004}
}
@article{Whittaker:2001:CVM:376929.376932,
abstract = {We explored general issues concerning personal information management by investigating the characteristics of office workers' paper-based information, in an industrial research environment. we examined the reasons people collect paper, types of data they collect, problems encountered in handling paper, and strategies used for processing it. We tested three specific hypotheses in the course of an office move. The greater availability of public digital data along with changes in people's jobs or interests should lead to wholescale discarding of paper data, while preparing for the move. Instead we found workers kept large, highly valued papar archives. We also expected that the major part of people's personal archives would be unique documents. However, only 49\% of people's archives were unique documents, the remainder being copies of publicly available data and unread information, and we explore reasons for this. We examined the effects of paper-processing strategies on archive structure. We discovered different paper-processing strategies (filing and piling)that were relatively independent of job type. We predicated that filers' attempted to evaluate and catergorize incoming documents would produce smaller archives that were accessed frequently. Contrary to our predictions, filers amassed more information, and accessed it less frequently than pilers. We argue that filers may engage in premature filing: to clear their workspace, they archives information that later turns out to be of low value. Given the effort involved in organzing data, they are also loath to discard filed information, even when its value is uncertain. We discuss the implications of this research for digital personal information management.},
address = {New York, NY, USA},
author = {Whittaker, Steve and Hirschberg, Julia},
doi = {10.1145/376929.376932},
issn = {1073-0516},
journal = {ACM Trans. Comput.-Hum. Interact.},
keywords = { document management, filing, information retrieval, paper, personal information management,archiving},
month = jun,
number = {2},
pages = {150--170},
publisher = {ACM},
title = {{The character, value, and management of personal paper archives}},
url = {http://doi.acm.org.prox.lib.ncsu.edu/10.1145/376929.376932},
volume = {8},
year = {2001}
}
@inproceedings{Yamazaki:2007:DTU:1772490.1772524,
abstract = {The purpose of this study is to develop an approach to artifacts design based on information technology. To make interactive system easy to use, user centered design approach is utilized by many systems. For user centered design, it is important to consider total user experience. But it is not easy to consider total user experience because user experience is including many aspects. To approach total user experience, the author proposes the method of designing for user experience that consist of "User viewpoint", "Environment viewpoint" and "Lifecycle viewpoint". "User viewpoint" is including several user groups from universal design viewpoint, several user characters and several user emotions. "Environment viewpoint" is including hardware product, software, application, space, people who is communicating. "Lifecycle viewpoint" is including pre sales, after sales, support, upgrade, setup product and application. To help this design approach, user experience design tool named "UED (User Experience Design) Studio" was proposed. Based on proposed three approaches, design tools were developed such as "The definition tool", "The evaluation tool" and "The visualization tool" for user experience design. To define user experience situation easily, "The definition tool" helps designer such selecting user group, selecting environment and input user tasks based on life cycle state. "The evaluation tool" is to evaluate defined user experience easily. And "The visualization tool" is to show the result of evaluation by 3 D graphics easy to understand complicated information. To evaluate proposed tools, experiment to make prototype was conducted and the results indicate that the proposed approach has possibility to help designer and multi-disciplinary team to consider user experience for user centered design.},
address = {Berlin, Heidelberg},
author = {Yamazaki, Kazuhiko and Furuta, Kazuo},
booktitle = {Proceedings of the 12th international conference on Human-computer interaction: interaction design and usability},
isbn = {978-3-540-73104-7},
pages = {298--307},
publisher = {Springer-Verlag},
series = {HCI'07},
title = {{Design tools for user experience design}},
year = {2007}
}
